---
title: Notation avec des modèles R sur Azure par lot
description: Exécuter avec des modèles R à l’aide d’Azure Batch et un jeu de données selon les prévisions de vente de magasin de vente au détail de notation par lots.
author: njray
ms.date: 03/29/2019
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai
ms.openlocfilehash: 72769cf078596f0312a1f4293205dda5a086ef41
ms.sourcegitcommit: 579c39ff4b776704ead17a006bf24cd4cdc65edd
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 04/17/2019
ms.locfileid: "59639901"
---
# <a name="batch-scoring-of-r-machine-learning-models-on-azure"></a><span data-ttu-id="58691-103">Modèles de notation par lot de l’apprentissage de R sur Azure</span><span class="sxs-lookup"><span data-stu-id="58691-103">Batch scoring of R machine learning models on Azure</span></span>

<span data-ttu-id="58691-104">Cette architecture de référence montre comment effectuer des modèles R à l’aide d’Azure Batch de notation par lots.</span><span class="sxs-lookup"><span data-stu-id="58691-104">This reference architecture shows how to perform batch scoring with R models using Azure Batch.</span></span> <span data-ttu-id="58691-105">Le scénario est basé sur les prévisions de vente de magasin de vente au détail, mais cette architecture peut être étendue pour n’importe quel scénario nécessitant la génération de prédictions sur un grand scaler à l’aide des modèles R.</span><span class="sxs-lookup"><span data-stu-id="58691-105">The scenario is based on retail store sales forecasting, but this architecture can be generalized for any scenario requiring the generation of predictions on a large scaler using R models.</span></span> <span data-ttu-id="58691-106">Une implémentation de référence pour cette architecture est disponible sur [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="58691-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Diagramme de l’architecture][0]

<span data-ttu-id="58691-108">**Scénario** : Une chaîne de supermarchés doit prévoir les ventes de produits au cours du trimestre à venir.</span><span class="sxs-lookup"><span data-stu-id="58691-108">**Scenario**: A supermarket chain needs to forecast sales of products over the upcoming quarter.</span></span> <span data-ttu-id="58691-109">La prévision permet à mieux gérer sa chaîne d’approvisionnement et de vous assurer qu’il peut répondre à la demande pour les produits à chacune de ses magasins de l’entreprise.</span><span class="sxs-lookup"><span data-stu-id="58691-109">The forecast allows the company to manage its supply chain better and ensure it can meet demand for products at each of its stores.</span></span> <span data-ttu-id="58691-110">La société met à jour ses prévisions chaque semaine que de nouvelles données de ventes à partir de la semaine précédente devient disponibles et la commercialisation de stratégie pour le trimestre suivant du produit est défini.</span><span class="sxs-lookup"><span data-stu-id="58691-110">The company updates its forecasts every week as new sales data from the previous week becomes available and the product marketing strategy for next quarter is set.</span></span> <span data-ttu-id="58691-111">Prévisions de Quantile sont générées pour estimer l’incertitude des prévisions de ventes individuelles.</span><span class="sxs-lookup"><span data-stu-id="58691-111">Quantile forecasts are generated to estimate the uncertainty of the individual sales forecasts.</span></span>

<span data-ttu-id="58691-112">Le traitement est constitué des étapes suivantes :</span><span class="sxs-lookup"><span data-stu-id="58691-112">Processing involves the following steps:</span></span>

1. <span data-ttu-id="58691-113">Une application logique Azure déclenche le processus de génération de prévision une fois par semaine.</span><span class="sxs-lookup"><span data-stu-id="58691-113">An Azure Logic App triggers the forecast generation process once per week.</span></span>

1. <span data-ttu-id="58691-114">L’application logique démarre une Instance de conteneur Azure qui exécute le Planificateur de conteneur Docker, ce qui déclenche les travaux de calcul de score sur le cluster de traitement par lots.</span><span class="sxs-lookup"><span data-stu-id="58691-114">The logic app starts an Azure Container Instance running the scheduler Docker container, which triggers the scoring jobs on the Batch cluster.</span></span>

1. <span data-ttu-id="58691-115">Calcul de score exécutés en parallèle entre les nœuds du cluster de traitement par lots.</span><span class="sxs-lookup"><span data-stu-id="58691-115">Scoring jobs run in parallel across the nodes of the Batch cluster.</span></span> <span data-ttu-id="58691-116">Chaque nœud :</span><span class="sxs-lookup"><span data-stu-id="58691-116">Each node:</span></span>

    1. <span data-ttu-id="58691-117">Extrait le worker image Docker à partir de Docker Hub et démarre un conteneur.</span><span class="sxs-lookup"><span data-stu-id="58691-117">Pulls the worker Docker image from Docker Hub and starts a container.</span></span>

    1. <span data-ttu-id="58691-118">Lit les données d’entrée et préformés modèles R à partir du stockage d’objets Blob Azure.</span><span class="sxs-lookup"><span data-stu-id="58691-118">Reads input data and pre-trained R models from Azure Blob storage.</span></span>

    1. <span data-ttu-id="58691-119">Évalue les données pour produire les prévisions.</span><span class="sxs-lookup"><span data-stu-id="58691-119">Scores the data to produce the forecasts.</span></span>

    1. <span data-ttu-id="58691-120">Écrit les résultats de prévisions pour le stockage d’objets blob.</span><span class="sxs-lookup"><span data-stu-id="58691-120">Writes the forecast results to blob storage.</span></span>

<span data-ttu-id="58691-121">La figure ci-dessous illustre les prévisions de ventes pour les quatre produits (références SKU) dans un magasin.</span><span class="sxs-lookup"><span data-stu-id="58691-121">The figure below shows the forecasted sales for four products (SKUs) in one store.</span></span> <span data-ttu-id="58691-122">La ligne noire est l’historique des ventes, la ligne en pointillés est la valeur médiane (q50) de prévision, la bande rose représente les centiles vingt-cinq et soixante-quinze cinquième et la bande bleu représente les centiles cinquième et cinquième 90.</span><span class="sxs-lookup"><span data-stu-id="58691-122">The black line is the sales history, the dashed line is the median (q50) forecast, the pink band represents the twenty-fifth and seventy-fifth percentiles, and the blue band represents the fifth and ninety-fifth percentiles.</span></span>

![Prévisions de ventes][1]

## <a name="architecture"></a><span data-ttu-id="58691-124">Architecture</span><span class="sxs-lookup"><span data-stu-id="58691-124">Architecture</span></span>

<span data-ttu-id="58691-125">Cette architecture est constituée des composants suivants.</span><span class="sxs-lookup"><span data-stu-id="58691-125">This architecture consists of the following components.</span></span>

<span data-ttu-id="58691-126">[Azure Batch] [ batch] est utilisé pour exécuter des tâches de génération de prévision en parallèle sur un cluster de machines virtuelles.</span><span class="sxs-lookup"><span data-stu-id="58691-126">[Azure Batch][batch] is used to run forecast generation jobs in parallel on a cluster of virtual machines.</span></span> <span data-ttu-id="58691-127">Prédictions sont faites à l’aide de la machine PRÉFORMÉE implémentés dans R. Azure Batch des modèles d’apprentissage peuvent automatiquement mettre à l’échelle le nombre de machines virtuelles en fonction du nombre de travaux soumis au cluster.</span><span class="sxs-lookup"><span data-stu-id="58691-127">Predictions are made using pre-trained machine learning models implemented in R. Azure Batch can automatically scale the number of VMs based on the number of jobs submitted to the cluster.</span></span> <span data-ttu-id="58691-128">Sur chaque nœud, un script R s’exécute dans un conteneur Docker à noter les données et générer des prévisions.</span><span class="sxs-lookup"><span data-stu-id="58691-128">On each node, an R script runs within a Docker container to score data and generate forecasts.</span></span>

<span data-ttu-id="58691-129">[Stockage d’objets Blob Azure] [ blob] est utilisé pour stocker les données d’entrée, les modèles d’apprentissage automatique préformé et les résultats de prévision.</span><span class="sxs-lookup"><span data-stu-id="58691-129">[Azure Blob Storage][blob] is used to store the input data, the pre-trained machine learning models, and the forecast results.</span></span> <span data-ttu-id="58691-130">Il offre un stockage très économique pour les performances nécessitant cette charge de travail.</span><span class="sxs-lookup"><span data-stu-id="58691-130">It delivers very cost-effective storage for the performance that this workload requires.</span></span>

<span data-ttu-id="58691-131">[Azure Container Instances] [ aci] fournir le calcul sans serveur à la demande.</span><span class="sxs-lookup"><span data-stu-id="58691-131">[Azure Container Instances][aci] provide serverless compute on demand.</span></span> <span data-ttu-id="58691-132">Dans ce cas, une instance de conteneur est déployée selon une planification pour déclencher les tâches de traitement par lots qui génèrent les prévisions.</span><span class="sxs-lookup"><span data-stu-id="58691-132">In this case, a container instance is deployed on a schedule to trigger the Batch jobs that generate the forecasts.</span></span> <span data-ttu-id="58691-133">Les traitements par lots sont déclenchés à partir d’un script R à l’aide du [doAzureParallel][doAzureParallel] package.</span><span class="sxs-lookup"><span data-stu-id="58691-133">The Batch jobs are triggered from an R script using the [doAzureParallel][doAzureParallel] package.</span></span> <span data-ttu-id="58691-134">L’instance de conteneur s’arrête automatiquement une fois les travaux terminés.</span><span class="sxs-lookup"><span data-stu-id="58691-134">The container instance automatically shuts down once the jobs have finished.</span></span>

<span data-ttu-id="58691-135">[Azure Logic Apps] [ logic-apps] déclencher l’intégralité du workflow en déployant les instances de conteneur selon une planification.</span><span class="sxs-lookup"><span data-stu-id="58691-135">[Azure Logic Apps][logic-apps] trigger the entire workflow by deploying the container instances on a schedule.</span></span> <span data-ttu-id="58691-136">Un connecteur dans Logic Apps d’Azure Container Instances permet à une instance à être déployé sur une plage de déclencher des événements.</span><span class="sxs-lookup"><span data-stu-id="58691-136">An Azure Container Instances connector in Logic Apps allows an instance to be deployed upon a range of trigger events.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="58691-137">Considérations relatives aux performances</span><span class="sxs-lookup"><span data-stu-id="58691-137">Performance considerations</span></span>

### <a name="containerized-deployment"></a><span data-ttu-id="58691-138">Déploiement en conteneur</span><span class="sxs-lookup"><span data-stu-id="58691-138">Containerized deployment</span></span>

<span data-ttu-id="58691-139">Avec cette architecture, tous les scripts R s’exécutent dans [Docker](https://www.docker.com/) conteneurs.</span><span class="sxs-lookup"><span data-stu-id="58691-139">With this architecture, all R scripts run within [Docker](https://www.docker.com/) containers.</span></span> <span data-ttu-id="58691-140">Cela garantit que les scripts exécutés dans un environnement cohérent, avec la même version de R et les versions de packages, à chaque fois.</span><span class="sxs-lookup"><span data-stu-id="58691-140">This ensures that the scripts run in a consistent environment, with the same R version and packages versions, every time.</span></span> <span data-ttu-id="58691-141">Les images Docker distinctes sont utilisés pour les conteneurs du planificateur et de travail, car chacun possède un ensemble de dépendances de package R.</span><span class="sxs-lookup"><span data-stu-id="58691-141">Separate Docker images are used for the scheduler and worker containers, because each has a different set of R package dependencies.</span></span>

<span data-ttu-id="58691-142">Azure Container Instances fournit un environnement sans serveur pour exécuter le Planificateur de conteneur.</span><span class="sxs-lookup"><span data-stu-id="58691-142">Azure Container Instances provides a serverless environment to run the scheduler container.</span></span> <span data-ttu-id="58691-143">Le conteneur de planificateur exécute un script R qui déclenche les travaux de calcul de score individuels s’exécutant sur un cluster Azure Batch.</span><span class="sxs-lookup"><span data-stu-id="58691-143">The scheduler container runs an R script that triggers the individual scoring jobs running on an Azure Batch cluster.</span></span>

<span data-ttu-id="58691-144">Chaque nœud du cluster de traitement par lots s’exécute le conteneur de travail, qui exécute le script de notation.</span><span class="sxs-lookup"><span data-stu-id="58691-144">Each node of the Batch cluster runs the worker container, which executes the scoring script.</span></span>

### <a name="parallelizing-the-workload"></a><span data-ttu-id="58691-145">Parallélisation de la charge de travail</span><span class="sxs-lookup"><span data-stu-id="58691-145">Parallelizing the workload</span></span>

<span data-ttu-id="58691-146">Lorsque batch notation des données avec des modèles R, déterminez comment paralléliser la charge de travail.</span><span class="sxs-lookup"><span data-stu-id="58691-146">When batch scoring data with R models, consider how to parallelize the workload.</span></span> <span data-ttu-id="58691-147">Les données d’entrée doivent être partitionnées d’une certaine manière afin que l’opération d’évaluation peut être répartie sur les nœuds du cluster.</span><span class="sxs-lookup"><span data-stu-id="58691-147">The input data must be partitioned somehow so that the scoring operation can be distributed  across the cluster nodes.</span></span> <span data-ttu-id="58691-148">Expérimentez des approches différentes pour découvrir le meilleur choix pour la distribution de votre charge de travail.</span><span class="sxs-lookup"><span data-stu-id="58691-148">Try different approaches to discover the best choice for distributing your workload.</span></span> <span data-ttu-id="58691-149">Cas par cas, considérez les points suivants :</span><span class="sxs-lookup"><span data-stu-id="58691-149">On a case-by-case basis, consider the following:</span></span>

- <span data-ttu-id="58691-150">La quantité de données permettre être chargé et traité dans la mémoire d’un seul nœud.</span><span class="sxs-lookup"><span data-stu-id="58691-150">How much data can be loaded and processed in the memory of a single node.</span></span>
- <span data-ttu-id="58691-151">La surcharge de démarrage de chaque traitement par lots.</span><span class="sxs-lookup"><span data-stu-id="58691-151">The overhead of starting each batch job.</span></span>
- <span data-ttu-id="58691-152">La surcharge de chargement des modèles R.</span><span class="sxs-lookup"><span data-stu-id="58691-152">The overhead of loading the R models.</span></span>

<span data-ttu-id="58691-153">Dans le scénario utilisé pour cet exemple, les objets de modèle sont volumineux, et il prend quelques secondes seulement pour générer des prévisions pour les produits individuels.</span><span class="sxs-lookup"><span data-stu-id="58691-153">In the scenario used for this example, the model objects are large, and it takes only a few seconds to generate a forecast for individual products.</span></span> <span data-ttu-id="58691-154">Pour cette raison, vous pouvez regrouper les produits et exécuter un traitement par lots unique par nœud.</span><span class="sxs-lookup"><span data-stu-id="58691-154">For this reason, you can group the products and execute a single Batch job per node.</span></span> <span data-ttu-id="58691-155">Une boucle au sein de chaque tâche génère des prévisions pour les produits séquentiellement.</span><span class="sxs-lookup"><span data-stu-id="58691-155">A loop within each job generates forecasts for the products sequentially.</span></span> <span data-ttu-id="58691-156">Cette méthode s’avère pour être le moyen le plus efficace de paralléliser cette charge de travail particulier.</span><span class="sxs-lookup"><span data-stu-id="58691-156">This method turns out to be the most efficient way to parallelize this particular workload.</span></span> <span data-ttu-id="58691-157">Il permet d’éviter la surcharge liée à partir de nombreux traitements par lots plus petits et à plusieurs reprises le chargement des modèles R.</span><span class="sxs-lookup"><span data-stu-id="58691-157">It avoids the overhead of starting many smaller Batch jobs and repeatedly loading the R models.</span></span>

<span data-ttu-id="58691-158">Une autre approche consiste à déclencher un traitement par lots par produit.</span><span class="sxs-lookup"><span data-stu-id="58691-158">An alternative approach is to trigger one Batch job per product.</span></span> <span data-ttu-id="58691-159">Traitement par lots Azure constitue une file d’attente des travaux automatiquement et les soumet à exécuter sur le cluster comme nœuds deviennent disponibles.</span><span class="sxs-lookup"><span data-stu-id="58691-159">Azure Batch automatically forms a queue of jobs and submits them to be executed on the cluster as nodes become available.</span></span> <span data-ttu-id="58691-160">Utilisez [mise à l’échelle automatique] [ autoscale] pour ajuster le nombre de nœuds du cluster en fonction du nombre de travaux.</span><span class="sxs-lookup"><span data-stu-id="58691-160">Use [automatic scaling][autoscale] to adjust the number of nodes in the cluster depending on the number of jobs.</span></span> <span data-ttu-id="58691-161">Cette approche est plus judicieux de temps relativement long pour terminer chaque opération de calcul de score, justifiant la surcharge de démarrer les travaux et de recharger les objets de modèle.</span><span class="sxs-lookup"><span data-stu-id="58691-161">This approach makes more sense if it takes a relatively long time to complete each scoring operation, justifying the overhead of starting the jobs and reloading the model objects.</span></span> <span data-ttu-id="58691-162">Cette approche est également plus simple à implémenter et vous donne la possibilité d’utiliser la mise à l’échelle automatique, un facteur important si la taille de la charge de travail totale n’est pas connue à l’avance.</span><span class="sxs-lookup"><span data-stu-id="58691-162">This approach is also simpler to implement and gives you the flexibility to use automatic scaling—an important consideration if the size of the total workload is not known in advance.</span></span>

## <a name="monitoring-and-logging-considerations"></a><span data-ttu-id="58691-163">Supervision et enregistrement des considérations</span><span class="sxs-lookup"><span data-stu-id="58691-163">Monitoring and logging considerations</span></span>

### <a name="monitoring-azure-batch-jobs"></a><span data-ttu-id="58691-164">Surveillance des travaux Azure Batch</span><span class="sxs-lookup"><span data-stu-id="58691-164">Monitoring Azure Batch jobs</span></span>

<span data-ttu-id="58691-165">Surveiller et arrêter le traitement par lots à partir de la **travaux** volet du compte Batch dans le portail Azure.</span><span class="sxs-lookup"><span data-stu-id="58691-165">Monitor and terminate Batch jobs from the **Jobs** pane of the Batch account in the Azure portal.</span></span> <span data-ttu-id="58691-166">Surveiller le cluster de lot, y compris l’état des nœuds individuels, à partir de la **Pools** volet.</span><span class="sxs-lookup"><span data-stu-id="58691-166">Monitor the batch cluster, including the state of individual nodes, from the **Pools** pane.</span></span>

### <a name="logging-with-doazureparallel"></a><span data-ttu-id="58691-167">Journalisation avec doAzureParallel</span><span class="sxs-lookup"><span data-stu-id="58691-167">Logging with doAzureParallel</span></span>

<span data-ttu-id="58691-168">Le package doAzureParallel collecte automatiquement des journaux de tous les stdout/stderr pour chaque tâche envoyée sur Azure Batch.</span><span class="sxs-lookup"><span data-stu-id="58691-168">The doAzureParallel package automatically collects logs of all stdout/stderr for every job submitted on Azure Batch.</span></span> <span data-ttu-id="58691-169">Vous la trouverez dans le compte de stockage créé lors de l’installation.</span><span class="sxs-lookup"><span data-stu-id="58691-169">These can be found in the storage account created at setup.</span></span> <span data-ttu-id="58691-170">Pour les afficher, utilisez un outil de navigation de stockage comme [Azure Storage Explorer] [ storage-explorer] ou le portail Azure.</span><span class="sxs-lookup"><span data-stu-id="58691-170">To view them, use a storage navigation tool such as [Azure Storage Explorer][storage-explorer] or Azure portal.</span></span>

<span data-ttu-id="58691-171">Pour déboguer rapidement des traitements par lots pendant le développement, imprimer des journaux dans votre session R locale à l’aide du [getJobFiles][getJobFiles] de doAzureParallel (fonction).</span><span class="sxs-lookup"><span data-stu-id="58691-171">To quickly debug Batch jobs during development, print logs in your local R session using the [getJobFiles][getJobFiles] function of doAzureParallel.</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="58691-172">Considérations relatives au coût</span><span class="sxs-lookup"><span data-stu-id="58691-172">Cost considerations</span></span>

<span data-ttu-id="58691-173">Les ressources de calcul utilisées dans cette architecture de référence sont les composants plus coûteuses.</span><span class="sxs-lookup"><span data-stu-id="58691-173">The compute resources used in this reference architecture are the most costly components.</span></span> <span data-ttu-id="58691-174">Pour ce scénario, un cluster de taille fixe est créé chaque fois que la tâche est déclenchée, puis arrêtez une fois la tâche terminée.</span><span class="sxs-lookup"><span data-stu-id="58691-174">For this scenario, a cluster of fixed size is created whenever the job is triggered and then shut down after the job has completed.</span></span> <span data-ttu-id="58691-175">Des frais sont facturés uniquement pendant que les nœuds de cluster sont démarrage, en cours d’exécution ou en cours d’arrêt.</span><span class="sxs-lookup"><span data-stu-id="58691-175">Cost is incurred only while the cluster nodes are starting, running, or shutting down.</span></span> <span data-ttu-id="58691-176">Cette approche est appropriée pour un scénario où les ressources de calcul requises pour générer les prévisions demeurent relativement constants à partir d’un travail à un travail.</span><span class="sxs-lookup"><span data-stu-id="58691-176">This approach is suitable for a scenario where the compute resources required to generate the forecasts remain relatively constant from job to job.</span></span>

<span data-ttu-id="58691-177">Dans les scénarios où la quantité de calcul requis pour terminer la tâche n’est pas connue d’avance, il peut être plus judicieux d’utiliser la mise à l’échelle automatique.</span><span class="sxs-lookup"><span data-stu-id="58691-177">In scenarios where the amount of compute required to complete the job is not known in advance, it may be more suitable to use automatic scaling.</span></span> <span data-ttu-id="58691-178">Avec cette approche, la taille du cluster est mis à l’échelle vers le haut ou vers le bas en fonction de la taille de la tâche.</span><span class="sxs-lookup"><span data-stu-id="58691-178">With this approach, the size of the cluster is scaled up or down depending on the size of the job.</span></span> <span data-ttu-id="58691-179">Azure Batch prend en charge une plage de formules à l’échelle automatique que vous pouvez définir lors de la définition du cluster à l’aide de la [doAzureParallel][doAzureParallel] API.</span><span class="sxs-lookup"><span data-stu-id="58691-179">Azure Batch supports a range of auto-scale formulae which you can set when defining the cluster using the [doAzureParallel][doAzureParallel] API.</span></span>

<span data-ttu-id="58691-180">Dans certains scénarios, le temps entre les travaux peut être trop court pour arrêter et démarrer le cluster.</span><span class="sxs-lookup"><span data-stu-id="58691-180">For some scenarios, the time between jobs may be too short to shut down and start up the cluster.</span></span> <span data-ttu-id="58691-181">Dans ce cas, conserver le cluster en cours d’exécution entre les travaux si nécessaire.</span><span class="sxs-lookup"><span data-stu-id="58691-181">In these cases, keep the cluster running between jobs if appropriate.</span></span>

<span data-ttu-id="58691-182">Azure Batch et doAzureParallel prend en charge l’utilisation de machines virtuelles de faible priorité.</span><span class="sxs-lookup"><span data-stu-id="58691-182">Azure Batch and doAzureParallel support the use of low-priority VMs.</span></span> <span data-ttu-id="58691-183">Ces machines virtuelles sont fournis avec une remise significative, mais risque d’être affectés par les autres charges de travail de priorité plus élevées.</span><span class="sxs-lookup"><span data-stu-id="58691-183">These VMs come with a significant discount but risk being appropriated by other higher priority workloads.</span></span> <span data-ttu-id="58691-184">L’utilisation de ces machines virtuelles ne sont donc pas recommandé pour les charges de travail de production critiques.</span><span class="sxs-lookup"><span data-stu-id="58691-184">The use of these VMs are therefore not recommended for critical production workloads.</span></span> <span data-ttu-id="58691-185">Toutefois, elles sont très utiles pour expérimentales ou charges de travail de développement.</span><span class="sxs-lookup"><span data-stu-id="58691-185">However, they are very useful for experimental or development workloads.</span></span>

## <a name="deployment"></a><span data-ttu-id="58691-186">Déploiement</span><span class="sxs-lookup"><span data-stu-id="58691-186">Deployment</span></span>

<span data-ttu-id="58691-187">Pour déployer cette architecture de référence, suivez les étapes décrites dans le [GitHub][github] dépôt.</span><span class="sxs-lookup"><span data-stu-id="58691-187">To deploy this reference architecture, follow the steps described in the [GitHub][github] repo.</span></span>

[0]: ./_images/batch-scoring-r-models.png
[1]: ./_images/sales-forecasts.png
[aci]: /azure/container-instances/container-instances-overview
[autoscale]: /azure/batch/batch-automatic-scaling
[batch]: /azure/batch/batch-technical-overview
[blob]: /azure/storage/blobs/storage-blobs-introduction
[doAzureParallel]: https://github.com/Azure/doAzureParallel/blob/master/docs/32-autoscale.md
[getJobFiles]: /azure/machine-learning/service/how-to-train-ml-models
[github]: https://github.com/Azure/RBatchScoring
[logic-apps]: /azure/logic-apps/logic-apps-overview
[storage-explorer]: /azure/vs-azure-tools-storage-manage-with-storage-explorer?tabs=windows