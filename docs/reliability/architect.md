---
title: Conception d’applications Azure pour la résilience et disponibilité
description: Générer la résilience et disponibilité dans une application Azure
author: MikeWasson
ms.date: 04/10/2019
ms.topic: article
ms.service: architecture-center
ms.subservice: cloud-design-principles
ms.openlocfilehash: ee4bb5b4a85e48fe0ff017297c31823c93a48f04
ms.sourcegitcommit: 579c39ff4b776704ead17a006bf24cd4cdc65edd
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 04/17/2019
ms.locfileid: "59646565"
---
# <a name="architecting-azure-applications-for-resiliency-and-availability"></a>Conception d’applications Azure pour la résilience et disponibilité

Une fois que vous avez développé la configuration requise pour votre application, l’étape suivante consiste à intégrer la résilience et disponibilité. Ces qualités ne peut pas être ajoutées à la fin &mdash; vous devez les concevoir l’architecture.

## <a name="conduct-a-failure-mode-analysis"></a>Effectuer une analyse du mode d’échec

*Analyse du mode d’échec* (FMA) génère la résilience dans un système en identifiant les points de défaillance possibles et en définissant la façon dont l’application répond à ces défaillances. La FMA doit faire partie des phases de conception et l’architecture, afin de la récupération après défaillance est intégrée au système à partir du début. Les objectifs d’une analyse FMA sont de :

- Déterminer les types d’échecs qu’une application peut rencontrer et comment l’application détecte ces échecs.
- Capturer les effets de chaque type de défaillance potentiels et déterminer comment l’application répond.
- Planifier pour la journalisation et surveillance de l’échec et identifier les stratégies de récupération.

Voici quelques exemples de modes d’échec et les stratégies de détection pour un point de défaillance spécifique &mdash; un appel à un service web externe :

| Mode d’échec           | Stratégie de détection           |
|------------------------|------------------------------|
| Le service est indisponible | HTTP 5xx                     |
| Limitation             | HTTP 429 (Trop de demandes) |
| Authentication         | HTTP 401 (Non autorisé)      |
| Temps de réponse lent          | Délai d’expiration de la requête            |

Pour plus d’informations sur le processus FMA, avec des recommandations spécifiques pour Azure, consultez [analyse du mode d’échec](../resiliency/failure-mode-analysis.md).

## <a name="plan-for-redundancy"></a>Plan pour la redondance

Échecs de varient dans la portée de l’impact. Certaines défaillances matérielles, telles que d’un disque défectueux, affectent un seul ordinateur hôte. Un commutateur réseau défaillant peut affecter un rack de serveur entier. Échecs moins courants, tels que la perte de puissance, interrompent un centre de données entier. Exceptionnellement, une région entière deviendrait indisponible.

Redondance est une façon de rendre une application résiliente. Le niveau de redondance dépend des besoins de votre entreprise &mdash; pas chaque application a besoin de redondance entre les régions pour vous prémunir contre une panne régionale. En règle générale, il existe un compromis entre redondance et la fiabilité par rapport aux coûts plus élevée et la complexité.

### <a name="review-azure-redundancy-features"></a>Passez en revue les fonctionnalités de redondance Azure

Azure propose plusieurs fonctionnalités de redondance à tous les niveaux de défaillance, à partir d’une machine virtuelle (VM) individuelle dans une région entière.

- **Unique des machines virtuelles** ont un [contrat de niveau service (SLA)](https://azure.microsoft.com/support/legal/sla/virtual-machines) fournie par Azure. (La machine virtuelle doit utiliser le stockage premium pour tous les disques de système d’exploitation et disques de données). Bien que vous puissiez obtenir un contrat supérieur en exécutant deux machines virtuelles ou plus, une machine virtuelle unique peut présenter une fiabilité suffisante pour certaines charges de travail. Toutefois, pour les charges de travail de production, nous vous recommandons d’utiliser au moins deux machines virtuelles pour la redondance.
- **Groupes à haute disponibilité** protègent contre les défaillances matérielles localisées, telle qu’un disque ou réseau défaillant du commutateur. Machines virtuelles dans un groupe à haute disponibilité sont réparties entre jusqu'à trois *domaines d’erreur*. Des domaines d’erreur définit un groupe de machines virtuelles qui partagent un common power source et un commutateur réseau. Si une défaillance matérielle affecte un domaine d’erreur, le trafic réseau est acheminé vers les machines virtuelles dans les autres domaines d’erreur. Pour plus d’informations sur les groupes à haute disponibilité, consultez [gérer la disponibilité des machines virtuelles Windows Azure](/azure/virtual-machines/windows/manage-availability).
- **Zones de disponibilité** sont physiquement séparées des zones dans une région Azure. Chaque zone de disponibilité possède une source d’alimentation, un réseau et un système de refroidissement propres. Déploiement de machines virtuelles entre des Zones de disponibilité permet de protéger une application contre les défaillances de centre de données à l’échelle. Les régions ne prennent pas toutes en charge les zones de disponibilité. Pour obtenir la liste des régions et services pris en charge, consultez [Que sont les zones de disponibilité dans Azure ?](/azure/availability-zones/az-overview).

    Si vous envisagez d’utiliser des Zones de disponibilité dans votre déploiement, tout d’abord vérifier que votre architecture d’application et de la base de code prend en charge cette configuration. Si vous déployez des logiciels commerciaux, consulter le fournisseur de logiciels et les tester correctement avant de déployer en production. Une application doit maintenir l’état et éviter la perte de données en cas de panne dans la zone configurée. L’application doit prendre en charge en cours d’exécution dans une infrastructure élastique et distribuée sans composants d’infrastructure codées en dur.
- **Azure Site Recovery** a besoin de Machines virtuelles vers une autre région Azure pour la continuité d’activité (BC) et de récupération d’urgence (DR) réplique. Vous pouvez effectuer des exercices de récupération d’urgence pour vous assurer que les besoins de conformité. La machine virtuelle est répliquée avec les paramètres spécifiés dans la région sélectionnée afin que vous puissiez récupérer vos applications en cas de panne dans la région source. Pour plus d’informations, consultez [configurer la récupération d’urgence vers une région Azure secondaire pour une machine virtuelle Azure](/azure/site-recovery/azure-to-azure-quickstart/).

    Pendant le test, vérifiez que le *objectif de délai de récupération* (RTO) et *objectif de point de récupération* (RPO) répondent à vos besoins. RTO est la durée maximale, qu'une application n’est pas disponible après un incident et RPO est la durée maximale de perte de données lors d’un sinistre.
- **Régions jumelées** sont créés à l’aide d’Azure Traffic Manager pour répartir le trafic Internet à différentes régions, la protection d’une application contre une panne régionale. Chaque région Azure est jumelée à une autre région. Ensemble, ces régions forment un [ *paire régionale*](/azure/best-practices-availability-paired-regions). Pour satisfaire les exigences de résidence de données d’impôts et la loi jumelée mise en œuvre, les paires régionales sont situés dans la même zone géographique (à l’exception du sud du Brésil).

    Pour améliorer la résilience des applications, Azure sérialise les mises à jour de plateforme (maintenance planifiée) entre chaque paire de régions, pour qu’une seule région jumelée est mis à jour à la fois.
- Lorsque vous concevez une application multirégion, prenez en compte que la latence du réseau entre les régions est supérieure au sein d’une région. Par exemple, si vous répliquez une base de données pour permettre le basculement, utilisez réplication synchrone des données au sein d’une région, mais la réplication asynchrone des données dans différentes régions.

Le tableau suivant compare les facteurs de redondance entre plusieurs stratégies de résilience :

| &nbsp; | Groupe à haute disponibilité | Zone de disponibilité | Azure Site Recovery/Région jumelée |
|--------|------------------|-------------------|-----------------------------------|
| Étendue de la défaillance | Rack                  | Centre de données               | Région                               |
| Routage des requêtes  | Azure Load Balancer   | Équilibreur de charge entre les zones | Azure Traffic Manager                |
| Latence du réseau  | Très faible              | Faible                      | Moyenne à élevée                          |
| Réseau virtuel  | Réseau virtuel Azure | Réseau virtuel Azure          | Homologation de réseaux virtuels entre régions |

### <a name="complete-azure-redundancy-tasks"></a>Tâches de redondance Azure terminée

Pour répondre aux exigences de redondance, utilisez les tâches suivantes :

- **Déployez plusieurs instances des services.** Si votre application repose sur une seule instance unique d’un service, cela crée un point de défaillance unique. L’approvisionnement de plusieurs instances améliore à la fois la résilience et l’extensibilité. Pour [Azure App Service](/azure/app-service/app-service-value-prop-what-is/), sélectionnez un [plan App Service](/azure/app-service/azure-web-sites-web-hosting-plans-in-depth-overview/) qui offre plusieurs instances. Pour [Machines virtuelles](/azure/virtual-machines/virtual-machines-windows-about/?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json), assurez-vous que votre architecture possède plusieurs machines virtuelles et que chaque machine virtuelle est incluse dans un [à haute disponibilité](/azure/virtual-machines/virtual-machines-windows-manage-availability/).

- **Répliquez les machines virtuelles à l’aide d’Azure Site Recovery.** Lorsque vous répliquez des machines virtuelles Azure à l’aide de [Site Recovery](/azure/site-recovery/), tous les disques de machine virtuelle sont continuellement répliquées vers la région cible en mode asynchrone. Les points de récupération sont créés à intervalles de quelques minutes, ce qui donne un RPO de quelques minutes.

- **Envisagez de déployer votre application dans plusieurs régions.** Si votre application est déployée sur une seule région, et la région devient indisponible, votre application sera également pas disponible. Il se peut que cette situation soit inacceptable au regard des conditions du SLA de votre application. Si c’est le cas, envisagez de déployer votre application et ses services dans plusieurs régions. Un déploiement multirégion peut utiliser un *actif-actif* ou *actif / passif* configuration. Une configuration actif-actif distribue les demandes dans plusieurs régions actives. Une configuration actif / passif conserve des instances à chaud dans la région secondaire, mais n’envoie pas de trafic il, sauf si la région principale échoue. Pour les déploiements multirégion, nous vous recommandons de déployer vers les régions jumelées, décrites ci-dessus. Pour plus d’informations, consultez l’article [Continuité des activités et récupération d’urgence (BCDR) : régions jumelées d’Azure](/azure/best-practices-availability-paired-regions).

- **Utilisez Azure Traffic Manager pour acheminer le trafic de votre application vers des régions différentes.** [Azure Traffic Manager](/azure/traffic-manager/traffic-manager-overview/) effectue l’équilibrage de charge au niveau du DNS et achemine le trafic vers des régions différentes en fonction de la [le routage du trafic](/azure/traffic-manager/traffic-manager-routing-methods/) méthode et l’intégrité des points de terminaison de votre application. Sans Traffic Manager, vous êtes limité à une seule région pour votre déploiement, ce qui limite la mise à l’échelle, augmente la latence pour certains utilisateurs et provoque l’interruption de l’application, en cas d’interruption de service à l’échelle de la région.

- **Configurer Azure Application Gateway pour utiliser plusieurs instances.** Selon les exigences de votre application, une passerelle [Azure Application Gateway](/azure/application-gateway/application-gateway-introduction/) peut être mieux adaptée pour distribuer les requêtes aux services de votre application. Toutefois, les instances uniques du service de passerelle d’Application ne sont pas garanties par un contrat SLA, il est donc possible que votre application échoue en cas d’échec de l’instance de la passerelle d’Application. Configurer plusieurs instances de taille moyenne ou grande pour garantir la disponibilité du service selon les termes de la [SLA de passerelle d’Application](https://azure.microsoft.com/support/legal/sla/application-gateway/).

## <a name="design-for-scalability"></a>Conception dans l’optique de la scalabilité

*Évolutivité* est la capacité d’un système à traiter une charge accrue et fait partie de la [piliers de la qualité logicielle](../guide/pillars.md). Tâches d’évolutivité pendant la phase de conception sont les suivantes :

- **Charges de travail de partition.** Concevez les parties du processus pour qu’elles soient distinctes et décomposables. Réduire la taille de chaque partie. Ainsi, les parties du composant à être distribuée d’une manière qui optimise l’utilisation de chaque unité de calcul. Cela facilite également la mise à l’échelle de l’application grâce à l’ajout d’instances de ressources spécifiques. Pour les domaines complexes, envisagez d’adopter une [architecture de microservices](../guide/architecture-styles/microservices.md).
- **Conception pour la mise à l’échelle.** Mise à l’échelle permet aux applications réagir à charge variable en augmentant et en diminuant le nombre d’instances de rôles, de files d’attente et d’autres services. L’application doit toutefois être conçue en ce sens. Par exemple, l’application et les services qu’il utilise doivent être sans état pour autoriser les demandes d’être acheminé vers n’importe quelle instance. Avoir des services sans état signifie également qu’Ajout ou suppression d’une instance ne pas un impact négatif sur les utilisateurs actuels.
- **Planifier la croissance avec les unités d’échelle.** Pour chaque ressource, connaître les limites de l’échelle supérieure et utiliser le partitionnement ou décomposition d’aller au-delà de ces limites. Concevez l’application pour qu’elle puisse facilement être mise à l’échelle en ajoutant une ou plusieurs unités d’échelle. Déterminez les unités d’échelle pour le système en termes de jeux bien définis de ressources. Ainsi les opérations de montée en puissance application plus facile et moins sujette aux impact négatif dû à un manque de ressources dans une partie de l’ensemble du système. Par exemple, l’ajout *X* nombre de machines virtuelles frontales peut-être nécessiter *Y* nombre de files d’attente supplémentaires et *Z* nombre de comptes de stockage pour gérer la charge de travail supplémentaire. Pour une unité d’échelle peut consister à *X* des instances de machine virtuelle, *Y* files d’attente, et *Z* comptes de stockage.
- **Évitez l’affinité du client.** Si possible, assurez-vous que l’application ne nécessite pas d’affinité. Requêtes peuvent ensuite être acheminées vers n’importe quelle instance, et le nombre d’instances est sans importance. Cela élimine également la surcharge liée au stockage, à la récupération et à la maintenance des informations d’état pour chaque utilisateur.
- **Tirer parti des fonctionnalités de mise à l’échelle de plateforme.** Utiliser les fonctionnalités intégrées de mise à l’échelle lorsque cela est possible, plutôt que des mécanismes personnalisés ou tiers. Règles de mise à l’échelle utilisation planifiée, lorsque cela est possible, pour vous assurer que les ressources sont disponibles sans un délai de démarrage, mais ajouter à l’échelle automatique réactive aux règles, le cas échéant, pour faire face aux changements inattendus dans la demande. Pour plus d’informations, consultez [des conseils de mise à l’échelle](../best-practices/auto-scaling.md).  

  Si votre application n’est pas configurée pour monter en charge automatiquement en tant que la charge augmente, il est possible que les services de votre application échouera si sature les demandes utilisateur. Pour plus d’informations, consultez les articles suivants :

  - Général : [Liste de contrôle d’évolutivité](../checklist/scalability.md)
  - Azure App Service : [Mise à l’échelle manuelle ou automatique du nombre d’instances](/azure/monitoring-and-diagnostics/insights-how-to-scale/)
  - Services cloud : [Comment la mise à l’échelle un Service Cloud](/azure/cloud-services/cloud-services-how-to-scale/)
  - Machines virtuelles : [Mise à l’échelle automatique et des machines virtuelles identiques](/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-autoscale-overview/)

- **Décharger les tâches du processeur/e/s intensives en tant que tâches en arrière-plan.** Si une demande à un service est censée prendre beaucoup de temps pour exécuter ou peut absorbe des ressources considérables, déchargez le traitement vers une tâche distincte. Utiliser des tâches en arrière-plan pour exécuter ces tâches. Cette stratégie permet au service pour continuer à recevoir des demandes et de rester réactive. Pour plus d’informations, consultez le [Guide relatif aux travaux en arrière-plan](../best-practices/background-jobs.md).
- **Distribuer la charge de travail pour les tâches en arrière-plan.** S’il existe de nombreuses tâches en arrière-plan ou si les tâches nécessitent beaucoup de temps ou de ressources, répartissez le travail entre plusieurs unités de calcul. Le [modèle des Consommateurs concurrents](../patterns/competing-consumers.md) offre une solution possible.
- **Envisagez la migration vers un *partage* architecture.** Cette architecture utilise des nœuds indépendants et autonomes qui n’ont aucun point de contention (par exemple, les services partagés ou stockage). En théorie, un tel système peut être mis à l’échelle presque indéfiniment. Bien qu’une approche de moindre partage n’est généralement pas pratique, il peut fournir des opportunités de conception pour une meilleure extensibilité. Bon, un déplacement vers une architecture sans partage exemples de partitionnement des données et éviter l’utilisation de l’affinité client et état de session côté serveur.
- **Concevoir des exigences de stockage de votre application se trouve dans les objectifs de performance et de l’évolutivité du stockage Azure.** Stockage Azure est conçu pour fonctionner dans des objectifs d’extensibilité et de performances prédéfinis, vous devez concevoir votre application pour utiliser un stockage au sein de ces cibles. Si vous dépassez ces objectifs, votre application subira de limitation du stockage. Pour éviter cette situation, approvisionner des comptes de stockage supplémentaire. Si vous vous heurtez la limite de compte de stockage, approvisionner des abonnements Azure supplémentaires et puis des comptes de stockage supplémentaires. Pour plus d’informations, consultez [Objectifs d’extensibilité et de performances de stockage Azure](/azure/storage/storage-scalability-targets/).
- **Sélectionnez la taille de machine virtuelle appropriée pour votre application.** Mesurer le processeur, mémoire, disque et e/s de vos machines virtuelles de production réel et vérifiez que la taille de machine virtuelle que vous avez sélectionné est suffisante. Si ce n’est pas le cas, il se peut que votre application rencontre des problèmes de capacité quand les machines virtuelles sont proches de leurs limites. Les tailles de machine virtuelle sont décrites en détail dans [Tailles des machines virtuelles dans Azure](/azure/virtual-machines/virtual-machines-windows-sizes/?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).

## <a name="determine-subscription-and-service-requirements"></a>Déterminer les exigences de service et d’abonnement

Choisissez l’abonnement approprié et les fonctionnalités de service pour votre application en passant par ces tâches :

- **Évaluer les exigences par rapport aux [abonnement Azure et limites de service](/azure/azure-subscription-service-limits/).** *Abonnements Azure* présentent des limites pour certains types de ressources, comme le nombre de groupes de ressources, les noyaux et les comptes de stockage. Si les exigences de votre application dépassent les limites d’abonnement Azure, créez un autre abonnement Azure et approvisionnez des ressources suffisantes pour celui-ci. Les services Azure individuels présentent des limites en termes de consommation, telles que des limites sur le stockage, le débit, le nombre de connexions, les requêtes par seconde et d’autres mesures. Votre application échoue si elle tente d’utiliser des ressources au-delà de ces limites, ce qui entraîne une interruption de service possible et de limitation pour les utilisateurs affectés. Selon le service spécifique et les exigences de votre application, vous pouvez souvent éviter ces limites en montant en puissance (par exemple, le choix d’un autre niveau tarifaire) ou la montée en puissance (par exemple, en ajoutant de nouvelles instances).
- **Déterminez combien vous avez besoin de comptes de stockage.** Azure autorise un nombre spécifique de comptes de stockage par abonnement. Pour plus d’informations, consultez [Abonnement Azure et limites, quotas et contraintes de service](/azure/azure-subscription-service-limits/#storage-limits).
- **Sélectionnez le niveau de service approprié pour Azure SQL Database.** Si votre application utilise la base de données SQL Azure, sélectionnez le niveau de service approprié. Si le niveau ne peut pas gérer les besoins en unités (DTU) de transaction de base de données de votre application, votre utilisation de données est limitée. Pour plus d’informations sur la sélection du plan de service approprié, consultez [Options et performances de SQL Database : comprendre les éléments disponibles dans chaque niveau de service](/azure/sql-database/sql-database-service-tiers/).
- **Approvisionner des unités de requête (RU) suffisant dans Azure Cosmos DB**. Avec Azure Cosmos DB, vous payez pour le débit que vous provisionnez et le stockage que vous utilisez sur une base horaire. Le coût de toutes les opérations de base de données est normalisé en tant qu’unités de requête, qui extrait les ressources système telles que l’UC, e/s et la mémoire. Pour plus d’informations, voir [Unités de requête dans Azure Cosmos DB](/azure/cosmos-db/request-units).

## <a name="load-balance-as-needed"></a>Équilibrer la charge en fonction des besoins

Équilibrage de charge appropriée vous permet d’afin de répondre aux exigences de disponibilité et pour réduire les coûts liés à la disponibilité.

- **Utiliser l’équilibrage de charge pour distribuer les demandes.** L’équilibrage de charge distribue les demandes de votre application pour les instances de service intègres en supprimant des instances défectueuses de rotation. Si votre service utilise Azure App Service ou Azure Cloud Services, il est déjà équilibrée pour vous. Toutefois, si votre application utilise des machines virtuelles Azure, vous devez configurer un équilibreur de charge. Pour plus d’informations, consultez [What ' s Azure Load Balancer ?](/azure/load-balancer/load-balancer-overview/)

  Vous pouvez utiliser Azure Load Balancer pour :

  - L’équilibrage de charge Internet le trafic entrant vers vos machines virtuelles. Cette configuration est appelée un [ *équilibreur de charge public*](/azure/load-balancer/load-balancer-overview#publicloadbalancer).
  - équilibrer la charge du trafic entre les machines virtuelles à l’intérieur d’un réseau virtuel. Vous pouvez également communiquer avec un frontend d’équilibreur de charge à partir d’un réseau local dans le cadre d’un scénario hybride. Les deux scénarios utilisent une configuration qui est appelée un [ *équilibreur de charge interne*](/azure/load-balancer/load-balancer-overview#internalloadbalancer).
  - Réacheminer le trafic vers un port détaillé sur des machines virtuelles spécifiques avec des règles de traduction (NAT) d’adresse réseau entrant.
  - Fournir une [connectivité sortante](/azure/load-balancer/load-balancer-outbound-connections) aux machines virtuelles de votre réseau virtuel à l’aide d’un équilibreur de charge public.

- **Équilibrez les charges entre les régions avec un gestionnaire de trafic, notamment Azure Traffic Manager.** Pour équilibrer le trafic entre les régions nécessite une solution de gestion du trafic, ainsi que Azure [Traffic Manager](https://azure.microsoft.com/services/traffic-manager/). Vous pouvez également tirer parti des services de fournisseurs tiers qui offrent des capacités de gestion du trafic similaires.

## <a name="implement-resiliency-strategies"></a>Implémenter des stratégies de résilience

Cette section décrit quelques stratégies de résilience courantes. La plupart de ces stratégies n’est pas limitée à une technologie particulière. Les descriptions de résument l’idée derrière chaque technique et incluent des liens pour obtenir des informations supplémentaires.

- **Implémenter des modèles de résilience** pour les opérations à distance, le cas échéant. Si votre application dépend de la communication entre les services à distance, suivez [modèles de conception](../patterns/category/resiliency.md) pour la gestion des défaillances temporaires.

- **Relance des échecs temporaires.** Ces erreurs peuvent être dues à une perte momentanée de la connectivité réseau, une connexion de base de données supprimée ou un délai d’attente lorsqu’un service est occupé. Souvent, un échec temporaire peut être résolu en retentant la demande.

  - Pour de nombreux services Azure, le kit de développement de logiciel (SDK) client implémente de nouvelles tentatives automatiques de manière transparente à l’appelant. Consultez [des conseils pour des services spécifiques de nouvelle tentative](../best-practices/retry-service-specific.md).
  - Ou implémenter le [modèle nouvelle tentative](../patterns/retry.md) pour aider à l’application de gérer en toute transparence des défaillances temporaires anticipées quand elle tente de se connecter à une service ou une ressource réseau.

- **Utiliser un disjoncteur** pour gérer les erreurs qui peuvent prendre un certain temps à corriger. Le [modèle disjoncteur](../patterns/circuit-breaker.md) peut empêcher une application de tenter à plusieurs reprises une opération qui échouera peut. Le disjoncteur inclut dans un wrapper des appels vers un service et suit le nombre d’échecs récents. Si le nombre d’échec dépasse un seuil, le disjoncteur renvoie un code d’erreur sans avoir appelé le service. Cela donne le temps de service de récupération et permet d’éviter les défaillances en cascade.
- **Isoler les ressources critiques.** Échecs dans un sous-système peuvent parfois mettre en cascade, ce qui entraîne des défaillances dans d’autres parties de l’application. Cela peut se produire si une défaillance empêche les ressources telles que des threads ou des sockets d’être libérée, ce qui conduit à un épuisement des ressources. Pour éviter ce problème, vous pouvez partitionner un système en groupes isolés, afin qu’une défaillance dans une partition ne détériore pas l’ensemble du système.

    Voici quelques exemples de cette technique, parfois appelé le [modèle de cloisonnement](../patterns/bulkhead.md):

  - Partitionnez une base de données (par exemple, par le client) et affectez un pool distinct d’instances de serveur web pour chaque partition.
  - Utilisez des pools de threads distincts pour isoler différents services. Cela permet d’éviter les successions d’échecs en cas de défaillance d’un des services. Pour obtenir un exemple, consultez le Netflix [Hystrix bibliothèque](https://medium.com/netflix-techblog/introducing-hystrix-for-resiliency-engineering-13531c1ab362).
  - Utilisez [conteneurs](https://en.wikipedia.org/wiki/Operating-system-level_virtualization) pour limiter les ressources disponibles pour un sous-système spécifique.

      ![Diagramme du modèle de cloisonnement](_images/bulkhead.png)

- **Appliquer [ *des transactions de compensation*](../patterns/compensating-transaction.md)**. Une transaction de compensation est une transaction qui annule les effets d’une autre transaction terminée. Dans un système distribué, il peut être difficile d’obtenir une cohérence transactionnelle élevée. Transactions de compensation contribuer à garantir la cohérence à l’aide d’une série de transactions individuelles plus petites, qui peuvent être annulées à chaque étape. Par exemple, pour réserver un voyage, un client peut réserver une voiture, un hôtel et un vol. Si un de ces étapes échoue, l’opération entière échoue. Au lieu de tenter d’utiliser une unique transaction distribuée pour l’intégralité de l’opération, vous pouvez définir une transaction de compensation pour chaque étape.
- **Implémenter des opérations asynchrones, dès que possible.** Les opérations synchrones peuvent monopoliser les ressources et de bloquer les autres opérations pendant que l’appelant attend la fin du processus. Concevez chaque partie de votre application pour permettre des opérations asynchrones, dès que possible. Pour plus d’informations sur la façon d’implémenter la programmation asynchrone en C\#, consultez [programmation asynchrone](/dotnet/articles/csharp/async).

## <a name="ensure-that-availability-meets-slas"></a>Vérifiez que la disponibilité répond aux contrats SLA

*Disponibilité* est la proportion de temps un système est fonctionnel et opérationnel, et il fait partie de la [piliers de la qualité logicielle](../guide/pillars.md). Utilisez les tâches de cette section pour passer en revue l’architecture de votre application à partir d’un point de vue de disponibilité pour vous assurer que votre disponibilité répond à vos contrats SLA.

- **Évitez tout point de défaillance.**  L’ensemble des instances de composants, de services, de ressources et de calcul doivent être déployées en tant qu’instances multiples afin d’empêcher qu’un point de défaillance unique affecte la disponibilité du système. Mécanismes d’authentification peuvent également être un point de défaillance unique. Concevez l’application pour être configurable d’utiliser plusieurs instances et pour détecter les défaillances et de rediriger les demandes vers les instances non défaillantes, automatiquement si la plateforme ne fait pas cela automatiquement.
- **Décomposez les charges de travail par objectif de niveau de service.**  Si un service est composé de charges de travail critiques et moins critiques, gérez-les de manière distincte et définissez les fonctions de service et le nombre d’instances nécessaires à la satisfaction de leurs exigences de disponibilité.
- **Réduisez et comprenez les dépendances de services.** Réduisez le nombre de services utilisés, lorsque cela est possible. Assurez-vous que vous comprenez toutes les dépendances de fonctionnalité et de service qui existent dans le système. En particulier, comprendre l’impact global de défaillance ou de baisse de performances dans chaque dépendance.
- **Concevez des tâches et des messages *idempotent*, lorsque cela est possible.** Une opération est idempotente si elle peut être répétée plusieurs fois et produire le même résultat. Cela peut s’assurer que les demandes dupliquées ne provoquent des problèmes. Les consommateurs de messages et les opérations qu’ils exécutent doivent être idempotents, de manière que la réitération d’une opération exécutée auparavant n’invalide pas les résultats. Cela peut signifier la détection des messages dupliqués ou de garantir la cohérence à l’aide d’une approche optimiste pour gérer les conflits.
- **Configurez les délais d’expiration des requêtes.**  Les services et les ressources peuvent devenir indisponibles, ce qui provoque l’échec des requêtes. Assurez-vous que les délais d’expiration que vous appliquez sont adaptés à chaque service ou ressource, et pour le client qui y accède. Dans certains cas, vous pouvez prévoir un délai d’expiration plus long pour une instance de client donnée, selon le contexte et les autres actions que le client effectue. Des délais d’expiration court peut entraîner des opérations de nouvelle tentative excessive pour les services et ressources qui ont une latence importante. Délais d’expiration longue peut causer le blocage, si un grand nombre de demandes est en attente, en attente pour un service ou une ressource de répondre.
- **Utilisez un Service Broker de message qui implémente une haute disponibilité pour les transactions critiques.** De nombreuses applications de cloud utilisent la messagerie pour déclencher des tâches asynchrones. Pour garantir la remise des messages, le système de messagerie doit proposer une haute disponibilité. [Messagerie Azure Service Bus](/azure/service-bus-messaging) implémente *au moins une fois* sémantique, ce qui signifie qu’un message est garanti pour être remis au moins une fois. Messages en double peuvent être TRANSMISS dans certaines circonstances. Si le traitement des messages est idempotent (voir le point précédent), la remise répétée ne posera pas de problèmes.
- **Limiter les utilisateurs intensifs.** Parfois, un petit nombre d’utilisateurs crée une charge excessive. Cela peut avoir un impact sur les autres utilisateurs et peut réduire la disponibilité globale de votre application. Lorsqu’un seul client effectue un nombre excessif de demandes, l’application peut limiter le client pendant une période donnée. Pendant la période de limitation, l’application refuse certaines ou toutes les demandes à partir de ce client. Le seuil de limitation dépend souvent de niveau de service du client. Pour plus d’informations, consultez [modèle de limitation](../patterns/throttling.md).

    La limitation n’implique pas que le client agissait à des fins malveillantes &mdash; uniquement qu’il a dépassé son quota de service. Dans certains cas, un consommateur peut constamment dépasser son quota, ou bien mal se comporter. Dans ce cas, vous pouvez aller plus loin et bloquer l’utilisateur. En règle générale, cela se fait en bloquant une clé API ou une plage d’adresses IP.
- **Concevez des applications pour appliquer une dégradation normale.** La charge sur une application peut dépasser la capacité d’une ou de plusieurs portions, ce qui entraîne une réduction de la disponibilité et la mise en échec des connexions. Mise à l’échelle peut atténuer ce problème, mais elle peut atteindre une limite imposée par d’autres facteurs, tels que la disponibilité des ressources ou de coût. Lorsqu’une application atteint une limite de ressource, elle doit agir en conséquence pour minimiser l’impact de l’utilisateur. Par exemple, dans un système de commerce électronique, si le sous-système de traitement des commandes est sous contrainte ou échoue, il peut être temporairement désactivée tout en autorisant d’autres fonctionnalités, telles que la consultation du catalogue de produits. Il peut être approprié de reporter les demandes vers un sous-système défaillant &mdash; , par exemple, en permettant aux clients d’envoyer des commandes mais de les enregistrer pour un traitement ultérieur, lorsque le sous-système de commandes est à nouveau disponible.
- **Traitez de manière appropriée les événements de rafales rapides.** La plupart des applications doivent gérer des charges de travail variables au fil du temps. Mise à l’échelle peut aider à gérer la charge, mais il peut prendre un certain temps pour les instances supplémentaires en ligne et de gérer les demandes. Pour empêcher les pics d’activité de surcharger l’application, vous devez le concevoir aux demandes de file d’attente pour les services qu’elle utilise et se dégradent normalement lorsque les files d’attente sont presque saturé. Vérifiez il existe suffisamment de capacité et de performances disponibles sous des conditions normales, de vider les files d’attente et de gérer les demandes en attente. Pour plus d’informations, consultez [Modèle de nivellement de charge basé sur une file d’attente](../patterns/queue-based-load-leveling.md).
- **Composez ou effectuer une restauration sur plusieurs composants.** Concevoir des applications à utiliser plusieurs instances sans affecter les opérations et les connexions existantes, lorsque cela est possible. Pour optimiser la disponibilité, utilisez plusieurs instances et distribuer les demandes entre eux et détecter et éviter d’envoyer des demandes pour les instances ayant échoué.
- **Restaurer un service ou workflow différent.** Par exemple, si l’écriture dans la base de données SQL échoue, stocker temporairement les données dans le stockage Blob ou Cache Redis. Fournissez à SQL Database une fonctionnalité permettant de relire les écritures quand le service redevient disponible. Dans certains cas, une opération ayant échoué peut avoir une action alternative qui permet à l’application de continuer à fonctionner, même quand un composant ou service échoue. Si possible, de détecter les défaillances et de rediriger les demandes vers d’autres services pendant que le service principal est hors connexion.
- **Utiliser le nivellement de charge pour aplanir les pics de trafic.** Les applications peuvent rencontrer des pics soudains dans le trafic, ce qui peut surcharger les services sur le serveur principal. Si un service back-end ne peut pas répondre aux demandes assez rapidement, les demandes en attente peuvent s’accumuler, ou le service peut limiter l’application. Pour éviter ce problème, vous pouvez utiliser une file d’attente en tant que mémoire tampon. Lorsqu’il existe un nouvel élément de travail, au lieu d’appeler le service back-end immédiatement, l’application files d’attente un élément de travail à exécuter de façon asynchrone. La file d’attente agit comme une mémoire tampon qui lisse des pics de charge. Pour plus d’informations, consultez [modèle de nivellement de charge basé sur la file d’attente](../patterns/queue-based-load-leveling.md).

## <a name="manage-your-data"></a>Gérer vos données

Façon dont vous gérez vos données est lue directement dans le groupe de disponibilité de votre application. Les tâches de cette section peuvent vous aider à créer un plan de gestion afin de garantir la disponibilité.

- **Répliquer des données et comprendre les méthodes de réplication pour les magasins de données de votre application.** La réplication de données est une stratégie générale pour gérer les échecs non temporaires dans un magasin de données. Prendre en compte les deux chemins de lecture et d’écriture. Selon la technologie de stockage, vous pouvez avoir plusieurs réplicas accessibles en écriture, ou vous pouvez avoir un seul réplica accessible en écriture et plusieurs réplicas en lecture seule. Pour optimiser la disponibilité, les réplicas peuvent être placés dans plusieurs régions. Toutefois, cette approche augmente la latence lors de la réplication des données. En règle générale, la réplication entre les régions est effectuée de manière asynchrone, ce qui implique un modèle de cohérence éventuel et une perte de données potentielle si un réplica échoue.  

  Vous pouvez utiliser [Azure Site Recovery](/azure/site-recovery/azure-to-azure-quickstart/) pour répliquer des Machines virtuelles à partir d’une région à un autre. Site Recovery réplique les données en continu dans la région cible. En cas de défaillance sur votre site principal, vous basculez vers un emplacement secondaire.

- **Assurez-vous qu’aucun compte d’utilisateur n’a accès à la fois aux données de production et aux données de sauvegarde.** Si un même compte d’utilisateur est autorisé à écrire dans les sources de production et de sauvegarde, vos sauvegardes de données risquent d’être compromises. Un utilisateur malveillant pourrait supprimer volontairement toutes vos données, et un utilisateur normal pourrait les supprimer accidentellement. Concevez votre application afin de limiter les autorisations de chaque compte d’utilisateur. Uniquement accorder l’accès en écriture aux utilisateurs qui en ont besoin et accorder l’accès à la production ou de sauvegarde, mais pas les deux.
- **Documentez et testez de votre processus de basculement et la restauration de magasin de données.** Si un magasin de données échoue inopinée, un opérateur humain doit respecter un ensemble d’instructions documentées pour basculer vers une banque de données. Si les étapes documentées comportent des erreurs, un opérateur ne pourrez les suivre correctement et de basculer de la ressource. Testez régulièrement la procédure pour vérifier que les opérateurs qui suivant la documentation peuvent correctement basculer et restaurer.
- **Sauvegarder vos données et valider vos sauvegardes de données.** Exécuter régulièrement un script pour valider l’intégrité des données, schéma et les requêtes pour vous assurer que les données de sauvegarde sont ce que vous attendez. Consignez et signalez toute incohérence pour que le service de sauvegarde puisse être réparé.
- **Utilisez la sauvegarde périodique et la restauration de point-à-temps.** Automatiquement et régulièrement sauvegarder des données qui ne sont pas conservées ailleurs. Vérifiez que vous pouvez récupérer les données et l’application elle-même si l’échec se produit. Assurez-vous que les sauvegardes respectent votre RPO. Réplication des données n’est pas une fonctionnalité de sauvegarde, car des erreurs humaines ou des opérations nuisibles peuvent endommager les données sur tous les réplicas. Le processus de sauvegarde doit être sécurisé afin de protéger les données stockées et en transit. Bases de données peuvent généralement être récupérées à un point antérieur dans le temps à l’aide des journaux de transactions. Pour plus d’informations, consultez [récupérer suite à une altération des données ou une suppression accidentelle](../resiliency/recovery-data-corruption.md).
- **Envisagez d’utiliser un compte de stockage géo-redondant.** Les données stockées dans un compte Stockage Azure sont toujours répliquées localement. Toutefois, il existe plusieurs stratégies de réplication effectuent leur choix quand un compte de stockage est approvisionné. Pour protéger vos données d’application contre les rares cas lorsqu’une région entière deviendrait indisponible, activez [(RA-GRS) de stockage géo-redondant avec accès en lecture à Azure](/azure/storage/storage-redundancy/#read-access-geo-redundant-storage).  

    > [!NOTE]
    > Pour les machines virtuelles, ne vous appuyez pas sur la réplication RA-GRS pour restaurer les disques de machine virtuelle (fichiers VHD). À la place, utilisez le service [Sauvegarde Azure](/azure/backup).

- **Envisagez de déployer des données de référence dans plusieurs régions.** Les données de référence sont des données en lecture seule qui prennent en charge les fonctionnalités de l’application. Il généralement ne change pas souvent. Bien que la restauration à partir de la sauvegarde est un moyen d’éviter les interruptions de service à l’échelle de la région, le RTO est relativement long. Lorsque vous déployez l’application vers une région secondaire, certaines stratégies peuvent améliorer le RTO pour les données de référence.

    Étant donné que les modifications de données de référence de rares occasions, vous pouvez améliorer le RTO en conservant une copie permanente dans la région secondaire. Cela élimine le temps nécessaire pour restaurer des sauvegardes après un sinistre. Pour répondre aux exigences en matière de récupération d’urgence dans plusieurs régions, vous devez déployer l’application et les données de référence ensemble dans plusieurs régions.

- **Utiliser l’accès concurrentiel optimiste et la cohérence éventuelle.** Les transactions qui bloquent l’accès aux ressources par le biais de verrouillage (*d’accès concurrentiel pessimiste*) peut dégrader les performances et réduire la disponibilité. Ces problèmes peuvent se révéler particulièrement sérieux au sein des systèmes distribués. Dans de nombreux cas, une conception et techniques, telles que le partitionnement, peuvent réduire les risques de mises à jour en conflit qui se produisent. Si les données sont répliquées ou lire à partir d’un magasin mis à jour séparément, les données seront uniquement cohérentes. Mais les avantages généralement à compenser l’impact sur la disponibilité de l’utilisation de transactions pour garantir la cohérence immédiate.
- **Utilisez la géo-réplication active pour base de données SQL pour répliquer les modifications à une base de données secondaire.** Géo-réplication Active pour SQL Database réplique automatiquement les modifications de base de données aux bases de données secondaire dans la même région ou une autre région. Pour plus d’informations, consultez [création et à l’aide de la géo-réplication active](/azure/sql-database/sql-database-active-geo-replication).

  Ou bien, vous pouvez adopter une approche plus manuelle à l’aide de la **copie de base de données** commande pour créer une copie de sauvegarde de la base de données avec une cohérence transactionnelle. Vous pouvez également utiliser le service d’importation/exportation d’Azure SQL Database, qui prend en charge l’exportation des bases de données dans des fichiers BACPAC (fichiers compressés contenant votre schéma de base de données et les données associées) qui sont stockés dans le stockage Blob Azure. Stockage Azure crée deux réplicas du fichier de sauvegarde dans la même région. Toutefois, la fréquence du processus de sauvegarde détermine votre RPO, c'est-à-dire la quantité de données, que vous risquez de perdre dans les scénarios d’urgence. Par exemple, si vous sauvegardez des données de toutes les heures, et un incident survient deux minutes avant la sauvegarde, vous perdrez ainsi 58 minutes de données. En outre, pour vous protéger contre une interruption de service à l’échelle régionale, vous devez copier les fichiers BACPAC vers une autre région. Pour plus d’informations, consultez [vue d’ensemble de la continuité avec Azure SQL Database](/azure/sql-database/sql-database-business-continuity).

- **Utilisez géosauvegardes pour SQL Data Warehouse.** Pour SQL Data Warehouse, utilisez les [géosauvegardes](/azure/sql-data-warehouse/backup-and-restore) pour restaurer vers une région associée pour la récupération d’urgence. Ces sauvegardes sont effectuées toutes les 24 heures et peuvent être restaurées dans les 20 minutes dans la région jumelée. Cette fonctionnalité est activée par défaut pour toutes les instances de SQL Data Warehouse. Pour plus d’informations sur la façon de restaurer votre entrepôt de données, consultez [restaurer à partir d’une région géographique Azure à l’aide de PowerShell.](/azure/sql-data-warehouse/sql-data-warehouse-restore)

- **Répliquez des disques de machine virtuelle à l’aide d’Azure Site Recovery.** Lorsque vous répliquez des machines virtuelles Azure à l’aide de [Site Recovery](/azure/site-recovery/), tous les disques de machine virtuelle sont continuellement répliquées vers la région cible en mode asynchrone. Les points de récupération sont créés à intervalle de quelques minutes. Cela vous donne un RPO de quelques minutes.
- **Sauvegarder SQL Server s’exécutant sur des machines virtuelles ou configurer une session de l’envoi de journaux.** Pour SQL Server exécuté sur une machine virtuelle, il existe deux options : les sauvegardes traditionnelles et la copie des journaux de transaction. Les sauvegardes traditionnelles vous permettent de restaurer à un point spécifique dans le temps, mais le processus de récupération est lent. Restauration de sauvegardes traditionnelles nécessite que vous démarrez avec une sauvegarde complète initiale et puis appliquez toutes les sauvegardes effectuées ultérieurement. La deuxième option consiste à configurer une session de l’envoi de journaux pour retarder la restauration de sauvegardes de journaux (par exemple, de deux heures). Vous disposez ainsi d’une fenêtre permettant de récupérer des erreurs identifiées sur la sauvegarde primaire.
- **Utiliser un processus personnalisé ou un outil tiers pour la sauvegarde de stockage Azure.** Pour le stockage Azure, vous pouvez développer un processus de sauvegarde personnalisé ou utiliser un outil de sauvegarde tiers. La plupart des conceptions d’applications comportent des complexités supplémentaires, dans le stockage le ressources référencent mutuellement. Par exemple, considérez une base de données SQL avec une colonne qui accède à un objet blob dans stockage Azure. Si les sauvegardes ne sont pas effectuées simultanément, cela peut être dû à l’absence de sauvegarde du pointeur vers un objet blob de la base de données avant la défaillance. L’application ou le plan de récupération d’urgence doit implémenter des processus pour gérer cette incohérence une fois la récupération effectuée.
- **Utilisez la réplication native ou les fonctionnalités de capture instantanée pour d’autres plateformes de données hébergées sur des machines virtuelles.** Autres plateformes de données, telles que Elasticsearch ou MongoDB, ont leurs propres fonctionnalités et les considérations lors de la création d’une sauvegarde intégrée et le processus de restauration. Pour ces plateformes de données, la recommandation générale consiste à utiliser toute réplication basée sur l’intégration native ou disponible ou des fonctionnalités de capture instantanée. Si ces fonctionnalités n’existent pas ou ne conviennent pas, envisagez d’utiliser des captures instantanées de disque ou de sauvegarde Azure pour créer une copie de point-à-temps des données d’application. Dans tous les cas, il est important de déterminer comment effectuer des sauvegardes cohérentes, en particulier lorsque les données d’application s’étend sur plusieurs systèmes de fichiers ou de plusieurs lecteurs sont combinés en un seul système de fichiers.
- **Étudiez les méthodes de réplication pour les sources de données de votre application.** Vos données d’application seront stockées dans différentes sources de données et seront ont des exigences de disponibilité de divers. Évaluer les méthodes de réplication pour chaque type de stockage de données dans Azure, y compris [redondance du stockage Azure](/azure/storage/storage-redundancy/) et [géo-réplication active de la base de données SQL](/azure/sql-database/sql-database-geo-replication-overview/) pour vous assurer que votre application données exigences sont satisfaites. Si vous répliquez des machines virtuelles Azure à l’aide de [Site Recovery](/azure/site-recovery/), tous les disques de machine virtuelle sont continuellement répliquées vers la région cible en mode asynchrone. Les points de récupération sont créés à intervalle de quelques minutes.
- **Établir des stratégies de données pour la récupération d’urgence.** Gestion appropriée des données sont un aspect complexe de tout plan de récupération d’urgence. Pendant le processus de récupération, la restauration des données est ce qui prend généralement le plus de temps. Choix différents quant à la réduction des fonctionnalités entraîne des problèmes complexes de la récupération des données et la cohérence.

## <a name="next-steps"></a>Étapes suivantes

> [!div class="nextstepaction"]
> [Tester la résilience et disponibilité](./testing.md)
