---
title: Scoring par lots des modèles Python sur Azure
description: Créez une solution scalable pour le scoring par lots de modèles selon une planification en parallèle avec Azure Machine Learning Service.
author: njray
ms.date: 01/30/2019
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai, AI
ms.openlocfilehash: b7607984bcf2c4bd046421aeb6e9d52dd8e7c18e
ms.sourcegitcommit: 1a3cc91530d56731029ea091db1f15d41ac056af
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 04/03/2019
ms.locfileid: "58887741"
---
# <a name="batch-scoring-of-python-machine-learning-models-on-azure"></a><span data-ttu-id="8ab44-103">Modèles de notation par lot de l’apprentissage de Python sur Azure</span><span class="sxs-lookup"><span data-stu-id="8ab44-103">Batch scoring of Python machine learning models on Azure</span></span>

<span data-ttu-id="8ab44-104">Cette architecture de référence montre comment créer une solution scalable pour le scoring par lots d’un grand nombre de modèles selon une planification en parallèle avec Azure Machine Learning Service.</span><span class="sxs-lookup"><span data-stu-id="8ab44-104">This reference architecture shows how to build a scalable solution for batch scoring many models on a schedule in parallel using Azure Machine Learning Service.</span></span> <span data-ttu-id="8ab44-105">La solution peut être utilisée comme modèle et appliquée à différents problèmes.</span><span class="sxs-lookup"><span data-stu-id="8ab44-105">The solution can be used as a template and can generalize to different problems.</span></span>

<span data-ttu-id="8ab44-106">Une implémentation de référence pour cette architecture est disponible sur [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="8ab44-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Scoring par lots des modèles Python sur Azure](./_images/batch-scoring-python.png)

<span data-ttu-id="8ab44-108">**Scénario** : Cette solution supervise le fonctionnement d’un grand nombre d’appareils dans un paramètre IoT où chaque appareil envoie des lectures de capteurs en permanence.</span><span class="sxs-lookup"><span data-stu-id="8ab44-108">**Scenario**: This solution monitors the operation of a large number of devices in an IoT setting where each device sends sensor readings continuously.</span></span> <span data-ttu-id="8ab44-109">Chaque appareil est supposé être associé à des modèles de détection des anomalies préentraînés, qui doivent être utilisés pour prédire si une série de mesures, agrégées sur un intervalle de temps prédéfini, correspondent ou non à une anomalie.</span><span class="sxs-lookup"><span data-stu-id="8ab44-109">Each device is assumed to be associated with pretrained anomaly detection models that need to be used to predict whether a series of measurements, that are aggregated over a predefined time interval, correspond to an anomaly or not.</span></span> <span data-ttu-id="8ab44-110">Dans les scénarios réels, il peut s’agir d’un flux de lectures de capteurs qui doivent être filtrées et agrégées avant d’être utilisées dans l’entraînement ou le scoring en temps réel.</span><span class="sxs-lookup"><span data-stu-id="8ab44-110">In real-world scenarios, this could be a stream of sensor readings that need to be filtered and aggregated before being used in training or real-time scoring.</span></span> <span data-ttu-id="8ab44-111">Pour simplifier, cette solution utilise le même fichier de données lors de l’exécution des travaux de scoring.</span><span class="sxs-lookup"><span data-stu-id="8ab44-111">For simplicity, this solution uses the same data file when executing scoring jobs.</span></span>

<span data-ttu-id="8ab44-112">Cette architecture de référence est conçue pour des charges de travail déclenchées selon une planification.</span><span class="sxs-lookup"><span data-stu-id="8ab44-112">This reference architecture is designed for workloads that are triggered on a schedule.</span></span> <span data-ttu-id="8ab44-113">Le traitement est constitué des étapes suivantes :</span><span class="sxs-lookup"><span data-stu-id="8ab44-113">Processing involves the following steps:</span></span>
1.  <span data-ttu-id="8ab44-114">Envoyer des lectures de capteurs pour ingestion à Azure Event Hubs.</span><span class="sxs-lookup"><span data-stu-id="8ab44-114">Send sensor readings for ingestion to Azure Event Hubs.</span></span>
2.  <span data-ttu-id="8ab44-115">Effectuer le traitement des flux et stocker les données brutes.</span><span class="sxs-lookup"><span data-stu-id="8ab44-115">Perform stream processing and store the raw data.</span></span>
3.  <span data-ttu-id="8ab44-116">Envoyer les données à un cluster Machine Learning prêt à travailler.</span><span class="sxs-lookup"><span data-stu-id="8ab44-116">Send the data to a Machine Learning cluster that is ready to start taking work.</span></span> <span data-ttu-id="8ab44-117">Chaque nœud du cluster exécute un travail de scoring pour un capteur spécifique.</span><span class="sxs-lookup"><span data-stu-id="8ab44-117">Each node in the cluster runs a scoring job for a specific sensor.</span></span> 
4.  <span data-ttu-id="8ab44-118">Exécuter le pipeline de scoring, qui exécute les travaux de scoring en parallèle avec des scripts Python Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="8ab44-118">Execute the scoring pipeline, which runs the scoring jobs in parallel using Machine Learning Python scripts.</span></span> <span data-ttu-id="8ab44-119">Le pipeline est créé et publié, et son exécution est planifiée à un intervalle de temps prédéfini.</span><span class="sxs-lookup"><span data-stu-id="8ab44-119">The pipeline is created, published, and scheduled to run on a predefined interval of time.</span></span>
5.  <span data-ttu-id="8ab44-120">Générer des prédictions et les stocker dans Stockage Blob pour les utiliser plus tard.</span><span class="sxs-lookup"><span data-stu-id="8ab44-120">Generate predictions and store them in Blob storage for later consumption.</span></span>

## <a name="architecture"></a><span data-ttu-id="8ab44-121">Architecture</span><span class="sxs-lookup"><span data-stu-id="8ab44-121">Architecture</span></span>

<span data-ttu-id="8ab44-122">Cette architecture est constituée des composants suivants :</span><span class="sxs-lookup"><span data-stu-id="8ab44-122">This architecture consists of the following components:</span></span>

<span data-ttu-id="8ab44-123">[Azure Event Hubs][event-hubs].</span><span class="sxs-lookup"><span data-stu-id="8ab44-123">[Azure Event Hubs][event-hubs].</span></span> <span data-ttu-id="8ab44-124">Ce service d’ingestion de messages peut recevoir des millions de messages d’événement par seconde.</span><span class="sxs-lookup"><span data-stu-id="8ab44-124">This message ingestion service can ingest millions of event messages per second.</span></span> <span data-ttu-id="8ab44-125">Dans cette architecture, les capteurs envoient un flux de données au hub d’événements.</span><span class="sxs-lookup"><span data-stu-id="8ab44-125">In this architecture, sensors send a stream of data to the event hub.</span></span>

<span data-ttu-id="8ab44-126">[Azure Stream Analytics][stream-analytics].</span><span class="sxs-lookup"><span data-stu-id="8ab44-126">[Azure Stream Analytics][stream-analytics].</span></span> <span data-ttu-id="8ab44-127">Moteur de traitement des événements.</span><span class="sxs-lookup"><span data-stu-id="8ab44-127">An event-processing engine.</span></span> <span data-ttu-id="8ab44-128">Un travail Stream Analytics lit les flux de données provenant du hub d’événements et effectue le traitement des flux.</span><span class="sxs-lookup"><span data-stu-id="8ab44-128">A Stream Analytics job reads the data streams from the event hub and performs stream processing.</span></span>

<span data-ttu-id="8ab44-129">[Azure SQL Database][sql-database].</span><span class="sxs-lookup"><span data-stu-id="8ab44-129">[Azure SQL Database][sql-database].</span></span> <span data-ttu-id="8ab44-130">Les données des lectures des capteurs sont chargées dans SQL Database.</span><span class="sxs-lookup"><span data-stu-id="8ab44-130">Data from the sensor readings is loaded into SQL Database.</span></span> <span data-ttu-id="8ab44-131">SQL est un moyen bien connu de stocker les données en flux traitées (qui sont tabulaires et structurées), mais d’autres magasins de données peuvent être utilisés.</span><span class="sxs-lookup"><span data-stu-id="8ab44-131">SQL is a familiar way to store the processed, streamed data (which is tabular and structured), but other data stores can be used.</span></span>

<span data-ttu-id="8ab44-132">[Service Azure Machine Learning][amls].</span><span class="sxs-lookup"><span data-stu-id="8ab44-132">[Azure Machine Learning Service][amls].</span></span> <span data-ttu-id="8ab44-133">Machine Learning est un service cloud pour l’entraînement, le scoring, le déploiement et la gestion des modèles de machine learning à grande échelle.</span><span class="sxs-lookup"><span data-stu-id="8ab44-133">Machine Learning is a cloud service for training, scoring, deploying, and managing machine learning models at scale.</span></span> <span data-ttu-id="8ab44-134">Dans le contexte du scoring par lots, Machine Learning crée un cluster de machines virtuelles à la demande avec une option de mise à l’échelle automatique, où chaque nœud du cluster exécute un travail de scoring pour un capteur spécifique.</span><span class="sxs-lookup"><span data-stu-id="8ab44-134">In the context of batch scoring, Machine Learning creates a cluster of virtual machines on demand with an automatic scaling option, where each node in the cluster runs a scoring job for a specific sensor.</span></span> <span data-ttu-id="8ab44-135">Les travaux de scoring sont exécutés en parallèle sous forme d’étapes de script Python qui sont placés en file d’attente et gérés par Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="8ab44-135">The scoring jobs are executed in parallel as Python-script steps that are queued and managed by Machine Learning.</span></span> <span data-ttu-id="8ab44-136">Ces étapes font partie d’un pipeline Machine Learning qui est créé et publié, et dont l’exécution est planifiée à un intervalle de temps prédéfini.</span><span class="sxs-lookup"><span data-stu-id="8ab44-136">These steps are part of a Machine Learning pipeline that is created, published, and scheduled to run on a predefined interval of time.</span></span>

<span data-ttu-id="8ab44-137">[Stockage Blob Azure][storage].</span><span class="sxs-lookup"><span data-stu-id="8ab44-137">[Azure Blob Storage][storage].</span></span> <span data-ttu-id="8ab44-138">Les conteneurs d’objets blob sont utilisés pour stocker les modèles préentraînés, les données et les prédictions de sortie.</span><span class="sxs-lookup"><span data-stu-id="8ab44-138">Blob containers are used to store the pretrained models, the data, and the output predictions.</span></span> <span data-ttu-id="8ab44-139">Les modèles sont chargés sur Stockage Blob dans le notebook [01_create_resources.ipynb][create-resources].</span><span class="sxs-lookup"><span data-stu-id="8ab44-139">The models are uploaded to Blob storage in the [01_create_resources.ipynb][create-resources] notebook.</span></span> <span data-ttu-id="8ab44-140">Ces modèles [SVM à une classe][one-class-svm] sont entraînés sur des données qui représentent les valeurs de différents capteurs pour différents appareils.</span><span class="sxs-lookup"><span data-stu-id="8ab44-140">These [one-class SVM][one-class-svm] models are trained on data that represents values of different sensors for different devices.</span></span> <span data-ttu-id="8ab44-141">Cette solution part du principe que les valeurs de données sont agrégées sur un intervalle de temps fixe.</span><span class="sxs-lookup"><span data-stu-id="8ab44-141">This solution assumes that the data values are aggregated over a fixed interval of time.</span></span>

<span data-ttu-id="8ab44-142">[Azure Container Registry][acr].</span><span class="sxs-lookup"><span data-stu-id="8ab44-142">[Azure Container Registry][acr].</span></span> <span data-ttu-id="8ab44-143">Le [script][pyscript] Python de scoring s’exécute dans des conteneurs Docker qui sont créés sur chaque nœud du cluster, où il lit les données des capteurs appropriés, génère des prédictions et les stocke dans Stockage Blob.</span><span class="sxs-lookup"><span data-stu-id="8ab44-143">The scoring Python [script][pyscript] runs in Docker containers that are created on each node of the cluster, where it reads the relevant sensor data, generates predictions and stores them in Blob storage.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="8ab44-144">Considérations relatives aux performances</span><span class="sxs-lookup"><span data-stu-id="8ab44-144">Performance considerations</span></span>

<span data-ttu-id="8ab44-145">Pour les modèles Python standard, il est généralement admis que les processeurs sont suffisants pour gérer la charge de travail.</span><span class="sxs-lookup"><span data-stu-id="8ab44-145">For standard Python models, it's generally accepted that CPUs are sufficient to handle the workload.</span></span> <span data-ttu-id="8ab44-146">Cette architecture utilise des processeurs.</span><span class="sxs-lookup"><span data-stu-id="8ab44-146">This architecture uses CPUs.</span></span> <span data-ttu-id="8ab44-147">Toutefois, pour [charges de travail d’apprentissage approfondi][deep], GPU généralement plus performantes que les unités centrales par une quantité considérable &mdash; un cluster important d’UC est généralement nécessaire pour obtenir des performances comparables.</span><span class="sxs-lookup"><span data-stu-id="8ab44-147">However, for [deep learning workloads][deep], GPUs generally outperform CPUs by a considerable amount &mdash; a sizeable cluster of CPUs is usually needed to get comparable performance.</span></span>

### <a name="parallelizing-across-vms-versus-cores"></a><span data-ttu-id="8ab44-148">Parallélisation entre machines virtuelles par rapport aux cœurs</span><span class="sxs-lookup"><span data-stu-id="8ab44-148">Parallelizing across VMs versus cores</span></span>

<span data-ttu-id="8ab44-149">Lors de l’exécution des processus de scoring de nombreux modèles en mode Batch, le travail doit être mis en parallèle sur les machines virtuelles.</span><span class="sxs-lookup"><span data-stu-id="8ab44-149">When running scoring processes of many models in batch mode, the jobs need to be parallelized across VMs.</span></span> <span data-ttu-id="8ab44-150">Deux approches sont possibles :</span><span class="sxs-lookup"><span data-stu-id="8ab44-150">Two approaches are possible:</span></span>

* <span data-ttu-id="8ab44-151">Créer un cluster plus grand avec des machines virtuelles de faible coût.</span><span class="sxs-lookup"><span data-stu-id="8ab44-151">Create a larger cluster using low-cost VMs.</span></span>

* <span data-ttu-id="8ab44-152">Créer un cluster plus petit avec des machines virtuelles hautes performances et plus de cœurs disponibles sur chacune.</span><span class="sxs-lookup"><span data-stu-id="8ab44-152">Create a smaller cluster using high performing VMs with more cores available on each.</span></span>

<span data-ttu-id="8ab44-153">En général, le scoring des modèles Python standard n’est pas aussi exigeant que celui des modèles d’apprentissage profond, et un petit cluster doit être en mesure de gérer efficacement un grand nombre de modèles en file d’attente.</span><span class="sxs-lookup"><span data-stu-id="8ab44-153">In general, scoring of standard Python models is not as demanding as scoring of deep learning models, and a small cluster should be able to handle a large number of queued models efficiently.</span></span> <span data-ttu-id="8ab44-154">Vous pouvez accroître le nombre de nœuds de cluster à mesure que les tailles des jeux de données augmentent.</span><span class="sxs-lookup"><span data-stu-id="8ab44-154">You can increase the number of cluster nodes as the dataset sizes increase.</span></span>

<span data-ttu-id="8ab44-155">Pour des raisons pratiques, dans ce scénario, une seule tâche de scoring est envoyée dans une étape du pipeline Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="8ab44-155">For convenience in this scenario, one scoring task is submitted within a single Machine Learning pipeline step.</span></span> <span data-ttu-id="8ab44-156">Il peut cependant être plus efficace d’effectuer le scoring de plusieurs blocs de données dans la même étape de pipeline.</span><span class="sxs-lookup"><span data-stu-id="8ab44-156">However, it can be more efficient to score multiple data chunks within the same pipeline step.</span></span> <span data-ttu-id="8ab44-157">Dans ce cas, écrivez un code personnalisé pour lire dans plusieurs jeux de données et exécutez le script de scoring pour ceux-ci au cours d’une même étape.</span><span class="sxs-lookup"><span data-stu-id="8ab44-157">In those cases, write custom code to read in multiple datasets and execute the scoring script for those during a single-step execution.</span></span>

## <a name="management-considerations"></a><span data-ttu-id="8ab44-158">Considérations relatives à la gestion</span><span class="sxs-lookup"><span data-stu-id="8ab44-158">Management considerations</span></span>

- <span data-ttu-id="8ab44-159">**Superviser les travaux**.</span><span class="sxs-lookup"><span data-stu-id="8ab44-159">**Monitor jobs**.</span></span> <span data-ttu-id="8ab44-160">Il est important de superviser la progression de l’exécution de travaux, mais cela peut s’avérer ardu sur un cluster de nœuds actifs.</span><span class="sxs-lookup"><span data-stu-id="8ab44-160">It's important to monitor the progress of running jobs, but it can be a challenge to monitor across a cluster of active nodes.</span></span> <span data-ttu-id="8ab44-161">Pour examiner l’état des nœuds du cluster, utilisez le [portail Azure][portal] pour gérer l’[espace de travail Machine Learning][ml-workspace].</span><span class="sxs-lookup"><span data-stu-id="8ab44-161">To inspect the state of the nodes in the cluster, use the [Azure Portal][portal] to manage the [machine learning workspace][ml-workspace].</span></span> <span data-ttu-id="8ab44-162">Si un nœud est inactif ou si un travail a échoué, vous pouvez consulter les journaux d’erreurs enregistrés dans Stockage Blob. Ils sont également accessibles dans la section Pipelines.</span><span class="sxs-lookup"><span data-stu-id="8ab44-162">If a node is inactive or a job has failed, the error logs are saved to blob storage, and are also accessible in the Pipelines section.</span></span> <span data-ttu-id="8ab44-163">Pour une supervision approfondie, connectez les journaux à [Application Insights][app-insights], ou exécutez des processus distincts pour interroger l’état du cluster et de ses travaux.</span><span class="sxs-lookup"><span data-stu-id="8ab44-163">For richer monitoring, connect logs to [Application Insights][app-insights], or run separate processes to poll for the state of the cluster and its jobs.</span></span>
-   <span data-ttu-id="8ab44-164">**Journalisation**.</span><span class="sxs-lookup"><span data-stu-id="8ab44-164">**Logging**.</span></span> <span data-ttu-id="8ab44-165">Machine Learning Service journalise tous les stdout/stderr dans le compte de stockage Azure associé.</span><span class="sxs-lookup"><span data-stu-id="8ab44-165">Machine Learning Service logs all stdout/stderr to the associated Azure Storage account.</span></span> <span data-ttu-id="8ab44-166">Pour consulter facilement les fichiers journaux, utilisez un outil de navigation dans le stockage comme [Explorateur Stockage Azure][explorer].</span><span class="sxs-lookup"><span data-stu-id="8ab44-166">To easily view the log files, use a storage navigation tool such as [Azure Storage Explorer][explorer].</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="8ab44-167">Considérations relatives au coût</span><span class="sxs-lookup"><span data-stu-id="8ab44-167">Cost considerations</span></span>

<span data-ttu-id="8ab44-168">Les composants les plus coûteux utilisés dans cette architecture de référence sont les ressources de calcul.</span><span class="sxs-lookup"><span data-stu-id="8ab44-168">The most expensive components used in this reference architecture are the compute resources.</span></span> <span data-ttu-id="8ab44-169">La taille du cluster de calcul peut faire l’objet d’un scale-up ou d’un scale-down en fonction des travaux présents dans la file d’attente.</span><span class="sxs-lookup"><span data-stu-id="8ab44-169">The compute cluster size scales up and down depending on the jobs in the queue.</span></span> <span data-ttu-id="8ab44-170">Activez la mise à l’échelle automatique programmatiquement via le SDK Python en modifiant la configuration du provisionnement de la capacité de calcul.</span><span class="sxs-lookup"><span data-stu-id="8ab44-170">Enable automatic scaling programmatically through the Python SDK by modifying the compute’s provisioning configuration.</span></span> <span data-ttu-id="8ab44-171">Vous pouvez aussi utiliser [Azure CLI][cli] pour définir les paramètres de mise à l’échelle automatique du cluster.</span><span class="sxs-lookup"><span data-stu-id="8ab44-171">Or use the [Azure CLI][cli] to set the automatic scaling parameters of the cluster.</span></span>

<span data-ttu-id="8ab44-172">Pour les tâches qui ne nécessitent pas un traitement immédiat, configurez la formule de mise à l’échelle automatique de sorte que l’état par défaut (minimum) soit un cluster sans nœud.</span><span class="sxs-lookup"><span data-stu-id="8ab44-172">For work that doesn't require immediate processing, configure the automatic scaling formula so the default state (minimum) is a cluster of zero nodes.</span></span> <span data-ttu-id="8ab44-173">Avec cette configuration, le cluster démarre sans nœud et ne monte en puissance que s’il détecte des tâches dans la file d’attente.</span><span class="sxs-lookup"><span data-stu-id="8ab44-173">With this configuration, the cluster starts with zero nodes and only scales up when it detects jobs in the queue.</span></span> <span data-ttu-id="8ab44-174">Si le processus de scoring par lots ne se produit que quelques fois par jour ou moins, ce paramètre permet de réaliser des économies significatives.</span><span class="sxs-lookup"><span data-stu-id="8ab44-174">If the batch scoring process happens only a few times a day or less, this setting enables significant cost savings.</span></span>

<span data-ttu-id="8ab44-175">La mise à l’échelle automatique peut ne pas convenir pour les traitements par lots trop rapprochés les uns des autres.</span><span class="sxs-lookup"><span data-stu-id="8ab44-175">Automatic scaling may not be appropriate for batch jobs that happen too close to each other.</span></span> <span data-ttu-id="8ab44-176">Le temps nécessaire au lancement et à l’arrêt d’un cluster a aussi un coût. De ce fait, si une charge de travail par lots commence seulement quelques minutes après la fin du travail précédent, il peut être plus rentable de laisser le cluster en fonctionnement entre les travaux.</span><span class="sxs-lookup"><span data-stu-id="8ab44-176">The time that it takes for a cluster to spin up and spin down also incurs a cost, so if a batch workload begins only a few minutes after the previous job ends, it might be more cost effective to keep the cluster running between jobs.</span></span> <span data-ttu-id="8ab44-177">Cela dépend si les processus de scoring sont planifiés pour s’exécuter très fréquemment (toutes les heures, par exemple) ou moins fréquemment (une fois par mois, par exemple).</span><span class="sxs-lookup"><span data-stu-id="8ab44-177">That depends on whether scoring processes are scheduled to run at a high frequency (every hour, for example), or less frequently (once a month, for example).</span></span>


## <a name="deployment"></a><span data-ttu-id="8ab44-178">Déploiement</span><span class="sxs-lookup"><span data-stu-id="8ab44-178">Deployment</span></span>

<span data-ttu-id="8ab44-179">Pour déployer cette architecture de référence, suivez les étapes décrites dans le [dépôt GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="8ab44-179">To deploy this reference architecture, follow the steps described in the [GitHub repo][github].</span></span>

[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[automatic-scaling]: /azure/batch/batch-automatic-scaling
[azure-files]: /azure/storage/files/storage-files-introduction
[cli]: /cli/azure
[create-resources]: https://github.com/Microsoft/AMLBatchScoringPipeline/blob/master/01_create_resources.ipynb
[deep]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[event-hubs]: /azure/event-hubs/event-hubs-geo-dr
[explorer]: https://azure.microsoft.com/en-us/features/storage-explorer/
[github]: https://github.com/Microsoft/AMLBatchScoringPipeline
[one-class-svm]: http://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html
[portal]: https://portal.azure.com
[ml-workspace]: /azure/machine-learning/studio/create-workspace
[python-script]: https://github.com/Azure/BatchAIAnomalyDetection/blob/master/batchai/predict.py
[pyscript]: https://github.com/Microsoft/AMLBatchScoringPipeline/blob/master/scripts/predict.py
[storage]: /azure/storage/blobs/storage-blobs-overview
[stream-analytics]: /azure/stream-analytics/
[sql-database]: /azure/sql-database/
[app-insights]: /azure/application-insights/app-insights-overview
