---
title: Scoring en temps réel des modèles Machine Learning R
description: Implémentez un service de prédiction en temps réel en R en exécutant Machine Learning Server dans Azure Kubernetes Service (AKS).
author: njray
ms.date: 12/12/2018
ms.custom: azcat-ai
ms.openlocfilehash: 6f3447d1dcab801ccdaf4cf88611725cc00eb68d
ms.sourcegitcommit: 1f4cdb08fe73b1956e164ad692f792f9f635b409
ms.translationtype: HT
ms.contentlocale: fr-FR
ms.lasthandoff: 01/08/2019
ms.locfileid: "54112275"
---
# <a name="real-time-scoring-of-r-machine-learning-models"></a><span data-ttu-id="538bf-103">Scoring en temps réel des modèles Machine Learning R</span><span class="sxs-lookup"><span data-stu-id="538bf-103">Real-time scoring of R machine learning models</span></span>

<span data-ttu-id="538bf-104">Cette architecture de référence montre comment implémenter un service de prédiction (synchrone) en temps réel en R à l’aide de Microsoft Machine Learning Server exécuté dans Azure Kubernetes Service (AKS).</span><span class="sxs-lookup"><span data-stu-id="538bf-104">This reference architecture shows how to implement a real-time (synchronous) prediction service in R using Microsoft Machine Learning Server running in Azure Kubernetes Service (AKS).</span></span> <span data-ttu-id="538bf-105">Cette architecture est conçue pour être générique et pour s’adapter à n’importe quel modèle prédictif créé en R que vous souhaitez déployer en tant que service en temps réel.</span><span class="sxs-lookup"><span data-stu-id="538bf-105">This architecture is intended to be generic and suited for any predictive model built in R that you want to deploy as a real-time service.</span></span> <span data-ttu-id="538bf-106">**[Déployez cette solution][github]**.</span><span class="sxs-lookup"><span data-stu-id="538bf-106">**[Deploy this solution][github]**.</span></span>

## <a name="architecture"></a><span data-ttu-id="538bf-107">Architecture</span><span class="sxs-lookup"><span data-stu-id="538bf-107">Architecture</span></span>

![Scoring en temps réel des modèles Machine Learning R sur Azure][0]

<span data-ttu-id="538bf-109">Cette architecture de référence adopte une approche basée sur le conteneur.</span><span class="sxs-lookup"><span data-stu-id="538bf-109">This reference architecture takes a container-based approach.</span></span> <span data-ttu-id="538bf-110">Une image Docker est générée contenant R, ainsi que les divers artefacts nécessaires pour scorer les nouvelles données.</span><span class="sxs-lookup"><span data-stu-id="538bf-110">A Docker image is built containing R, as well as the various artifacts needed to score new data.</span></span> <span data-ttu-id="538bf-111">Ces derniers incluent l’objet de modèle lui-même et un script de scoring.</span><span class="sxs-lookup"><span data-stu-id="538bf-111">These include the model object itself and a scoring script.</span></span> <span data-ttu-id="538bf-112">Cette image est envoyée (push) à un registre Docker hébergé dans Azure, puis déployée sur un cluster Kubernetes, également dans Azure.</span><span class="sxs-lookup"><span data-stu-id="538bf-112">This image is pushed to a Docker registry hosted in Azure, and then deployed to a Kubernetes cluster, also in Azure.</span></span>

<span data-ttu-id="538bf-113">L’architecture de ce workflow inclut les composants suivants.</span><span class="sxs-lookup"><span data-stu-id="538bf-113">The architecture of this workflow includes the following components.</span></span>

- <span data-ttu-id="538bf-114">**[Azure Container Registry][acr]** est utilisé pour stocker les images de ce workflow.</span><span class="sxs-lookup"><span data-stu-id="538bf-114">**[Azure Container Registry][acr]** is used to store the images for this workflow.</span></span> <span data-ttu-id="538bf-115">Les registres créés avec Container Registry peuvent être gérés par le biais du client et de l’[API Docker Registry V2][docker] standard.</span><span class="sxs-lookup"><span data-stu-id="538bf-115">Registries created with Container Registry can be managed via the standard [Docker Registry V2 API][docker] and client.</span></span>

- <span data-ttu-id="538bf-116">**[Azure Kubernetes Service][aks]** est utilisé pour héberger le déploiement et le service.</span><span class="sxs-lookup"><span data-stu-id="538bf-116">**[Azure Kubernetes Service][aks]** is used to host the deployment and service.</span></span> <span data-ttu-id="538bf-117">Les clusters créés avec AKS peuvent être gérés à l’aide du client et de l’[API Kubernetes][k-api] (kubectl) standard.</span><span class="sxs-lookup"><span data-stu-id="538bf-117">Clusters created with AKS can be managed using the standard [Kubernetes API][k-api] and client (kubectl).</span></span>

- <span data-ttu-id="538bf-118">**[Microsoft Machine Learning Server][mmls]** est utilisé pour définir l’API REST du service et inclut l’[opérationnalisation du modèle][operationalization].</span><span class="sxs-lookup"><span data-stu-id="538bf-118">**[Microsoft Machine Learning Server][mmls]** is used to define the REST API for the service and includes [Model Operationalization][operationalization].</span></span> <span data-ttu-id="538bf-119">Ce processus de serveur web orienté service écoute les demandes, qui sont ensuite remises à d’autres processus en arrière-plan qui exécutent le code R réel pour générer les résultats.</span><span class="sxs-lookup"><span data-stu-id="538bf-119">This service-oriented web server process listens for requests, which are then handed off to other background processes that run the actual R code to generate the results.</span></span> <span data-ttu-id="538bf-120">Tous ces processus s’exécutent sur un seul nœud dans cette configuration, laquelle est wrappée dans un conteneur.</span><span class="sxs-lookup"><span data-stu-id="538bf-120">All these processes run on a single node in this configuration, which is wrapped in a container.</span></span> <span data-ttu-id="538bf-121">Pour plus d’informations sur l’utilisation de ce service en dehors d’un environnement de test ou de développement, contactez votre représentant Microsoft.</span><span class="sxs-lookup"><span data-stu-id="538bf-121">For details about using this service outside a dev or test environment, contact your Microsoft representative.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="538bf-122">Considérations relatives aux performances</span><span class="sxs-lookup"><span data-stu-id="538bf-122">Performance considerations</span></span>

<span data-ttu-id="538bf-123">Les charges de travail de machine learning ont tendance à utiliser beaucoup de ressources, à la fois lors de l’entraînement et du scoring de nouvelles données.</span><span class="sxs-lookup"><span data-stu-id="538bf-123">Machine learning workloads tend to be compute-intensive, both when training and when scoring new data.</span></span> <span data-ttu-id="538bf-124">En règle générale, évitez d’exécuter plusieurs processus de scoring par cœur.</span><span class="sxs-lookup"><span data-stu-id="538bf-124">As a rule of thumb, try not to run more than one scoring process per core.</span></span> <span data-ttu-id="538bf-125">Machine Learning Server vous permet de définir le nombre de processus R s’exécutant dans chaque conteneur.</span><span class="sxs-lookup"><span data-stu-id="538bf-125">Machine Learning Server lets you define the number of R processes running in each container.</span></span> <span data-ttu-id="538bf-126">La valeur par défaut s’élève à cinq processus.</span><span class="sxs-lookup"><span data-stu-id="538bf-126">The default is five processes.</span></span> <span data-ttu-id="538bf-127">Lors de la création d’un modèle relativement simple, comme une régression linéaire avec un petit nombre de variables ou un petit arbre de décision, vous pouvez augmenter le nombre de processus.</span><span class="sxs-lookup"><span data-stu-id="538bf-127">When creating a relatively simple model, such as a linear regression with a small number of variables, or a small decision tree, you can increase the number of processes.</span></span> <span data-ttu-id="538bf-128">Supervisez la charge du processeur sur vos nœuds de cluster pour déterminer la limite appropriée du nombre de conteneurs.</span><span class="sxs-lookup"><span data-stu-id="538bf-128">Monitor the CPU load on your cluster nodes to determine the appropriate limit on the number of containers.</span></span>

<span data-ttu-id="538bf-129">Un cluster compatible GPU peut accélérer certains types de charges de travail, en particulier les modèles d’apprentissage profond.</span><span class="sxs-lookup"><span data-stu-id="538bf-129">A GPU-enabled cluster can speed up some types of workloads, and deep learning models in particular.</span></span> <span data-ttu-id="538bf-130">Toutes les charges de travail ne peuvent pas exploiter les GPU &mdash; uniquement celles qui font une utilisation intensive de l’algèbre de la matrice.</span><span class="sxs-lookup"><span data-stu-id="538bf-130">Not all workloads can take advantage of GPUs &mdash; only those that make heavy use of matrix algebra.</span></span> <span data-ttu-id="538bf-131">Par exemple, les modèles basés sur une arborescence, notamment les forêts aléatoires et les modèles de boosting, ne dérivent généralement aucun avantage des GPU.</span><span class="sxs-lookup"><span data-stu-id="538bf-131">For example, tree-based models, including random forests and boosting models, generally derive no advantage from GPUs.</span></span>

<span data-ttu-id="538bf-132">Certains types de modèles comme les forêts aléatoires sont massivement parallélisables sur des CPU.</span><span class="sxs-lookup"><span data-stu-id="538bf-132">Some model types such as random forests are massively parallelizable on CPUs.</span></span> <span data-ttu-id="538bf-133">Le cas échéant, accélérez le scoring d’une seule demande en distribuant la charge de travail sur plusieurs cœurs.</span><span class="sxs-lookup"><span data-stu-id="538bf-133">In these cases, speed up the scoring of a single request by distributing the workload across multiple cores.</span></span> <span data-ttu-id="538bf-134">Toutefois, cette opération réduit votre capacité à traiter plusieurs demandes de scoring étant en fonction d’une taille fixe de cluster.</span><span class="sxs-lookup"><span data-stu-id="538bf-134">However, doing so reduces your capacity to handle multiple scoring requests given a fixed cluster size.</span></span>

<span data-ttu-id="538bf-135">En général, les modèles R open source stockent toutes leurs données en mémoire. Veillez donc à ce que vos nœuds disposent de suffisamment de mémoire pour prendre en charge les processus que vous envisagez d’exécuter simultanément.</span><span class="sxs-lookup"><span data-stu-id="538bf-135">In general, open-source R models store all their data in memory, so ensure that your nodes have enough memory to accommodate the processes you plan to run concurrently.</span></span> <span data-ttu-id="538bf-136">Si vous utilisez Machine Learning Server pour ajuster vos modèles, utilisez les bibliothèques capables de traiter des données sur le disque, plutôt que de tout lire dans la mémoire.</span><span class="sxs-lookup"><span data-stu-id="538bf-136">If you are using Machine Learning Server to fit your models, use the libraries that can process data on disk, rather than reading it all into memory.</span></span> <span data-ttu-id="538bf-137">Les besoins en mémoire peuvent ainsi s’en retrouver considérablement réduits.</span><span class="sxs-lookup"><span data-stu-id="538bf-137">This can help reduce memory requirements significantly.</span></span> <span data-ttu-id="538bf-138">Que vous utilisiez Machine Learning Server ou R open source, supervisez vos nœuds pour vous assurer que vos processus de scoring ne sont pas sous-alimentés en mémoire.</span><span class="sxs-lookup"><span data-stu-id="538bf-138">Regardless of whether you use Machine Learning Server or open-source R, monitor your nodes to ensure that your scoring processes are not memory-starved.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="538bf-139">Considérations relatives à la sécurité</span><span class="sxs-lookup"><span data-stu-id="538bf-139">Security considerations</span></span>

### <a name="network-encryption"></a><span data-ttu-id="538bf-140">Chiffrement réseau</span><span class="sxs-lookup"><span data-stu-id="538bf-140">Network encryption</span></span>

<span data-ttu-id="538bf-141">Dans cette architecture de référence, HTTPS est activé pour la communication avec le cluster et un certificat intermédiaire [Let’s Encrypt][encrypt] est utilisé.</span><span class="sxs-lookup"><span data-stu-id="538bf-141">In this reference architecture, HTTPS is enabled for communication with the cluster, and a staging certificate from [Let’s Encrypt][encrypt] is used.</span></span> <span data-ttu-id="538bf-142">À des fins de production, remplacez-le par votre propre certificat issu d’une autorité de signature appropriée.</span><span class="sxs-lookup"><span data-stu-id="538bf-142">For production purposes, substitute your own certificate from an appropriate signing authority.</span></span>

### <a name="authentication-and-authorization"></a><span data-ttu-id="538bf-143">Authentification et autorisation</span><span class="sxs-lookup"><span data-stu-id="538bf-143">Authentication and authorization</span></span>

<span data-ttu-id="538bf-144">L’[opérationnalisation du modèle][operationalization] Machine Learning Server nécessite l’authentification des demandes de scoring.</span><span class="sxs-lookup"><span data-stu-id="538bf-144">Machine Learning Server [Model Operationalization][operationalization] requires scoring requests to be authenticated.</span></span> <span data-ttu-id="538bf-145">Dans ce déploiement, un nom d’utilisateur et un mot de passe sont utilisés.</span><span class="sxs-lookup"><span data-stu-id="538bf-145">In this deployment, a username and password are used.</span></span> <span data-ttu-id="538bf-146">Dans un environnement d’entreprise, vous pouvez activer l’authentification avec [Azure Active Directory][AAD] ou créer un front-end distinct avec [Gestion des API Azure][API].</span><span class="sxs-lookup"><span data-stu-id="538bf-146">In an enterprise setting, you can enable authentication using [Azure Active Directory][AAD] or create a separate front end using [Azure API Management][API].</span></span>

<span data-ttu-id="538bf-147">Pour que l’opérationnalisation du modèle fonctionne correctement avec Machine Learning Server sur des conteneurs, vous devez installer un certificat JSON Web Token (JWT).</span><span class="sxs-lookup"><span data-stu-id="538bf-147">For Model Operationalization to work correctly with Machine Learning Server on containers, you must install a JSON Web Token (JWT) certificate.</span></span> <span data-ttu-id="538bf-148">Ce déploiement utilise un certificat fourni par Microsoft.</span><span class="sxs-lookup"><span data-stu-id="538bf-148">This deployment uses a certificate supplied by Microsoft.</span></span> <span data-ttu-id="538bf-149">Dans un environnement de production, fournissez le vôtre.</span><span class="sxs-lookup"><span data-stu-id="538bf-149">In a production setting, supply your own.</span></span>

<span data-ttu-id="538bf-150">Pour le trafic entre Container Registry et AKS, envisagez d’activer le [contrôle d’accès en fonction du rôle][rbac] (RBAC) pour limiter les privilèges d’accès à ceux qui sont nécessaires.</span><span class="sxs-lookup"><span data-stu-id="538bf-150">For traffic between Container Registry and AKS, consider enabling [role-based access control][rbac] (RBAC) to limit access privileges to only those needed.</span></span>

### <a name="separate-storage"></a><span data-ttu-id="538bf-151">Stockage distinct</span><span class="sxs-lookup"><span data-stu-id="538bf-151">Separate storage</span></span>

<span data-ttu-id="538bf-152">Cette architecture de référence regroupe l’application (R) et les données (objet de modèle et script de scoring) dans une seule image.</span><span class="sxs-lookup"><span data-stu-id="538bf-152">This reference architecture bundles the application (R) and the data (model object and scoring script) into a single image.</span></span> <span data-ttu-id="538bf-153">Dans certains cas, il peut être plus judicieux de les séparer.</span><span class="sxs-lookup"><span data-stu-id="538bf-153">In some cases, it may be beneficial to separate these.</span></span> <span data-ttu-id="538bf-154">Vous pouvez placer les données du modèle et le code dans un [stockage][storage] d’objet blob ou de fichier Azure, puis les récupérer au moment de l’initialisation du conteneur.</span><span class="sxs-lookup"><span data-stu-id="538bf-154">You can place the model data and code into Azure blob or file [storage][storage], and retrieve them at container initialization.</span></span> <span data-ttu-id="538bf-155">Dans ce cas, veillez à ce que le compte de stockage soit défini pour autoriser uniquement un accès authentifié et exiger HTTPS.</span><span class="sxs-lookup"><span data-stu-id="538bf-155">In this case, ensure that the storage account is set to allow authenticated access only and require HTTPS.</span></span>

## <a name="monitoring-and-logging-considerations"></a><span data-ttu-id="538bf-156">Supervision et enregistrement des considérations</span><span class="sxs-lookup"><span data-stu-id="538bf-156">Monitoring and logging considerations</span></span>

<span data-ttu-id="538bf-157">Utilisez le [tableau de bord Kubernetes][dashboard] pour superviser l’état général de votre cluster AKS.</span><span class="sxs-lookup"><span data-stu-id="538bf-157">Use the [Kubernetes dashboard][dashboard] to monitor the overall status of your AKS cluster.</span></span> <span data-ttu-id="538bf-158">Consultez le panneau de présentation du cluster dans le portail Azure pour plus d’informations.</span><span class="sxs-lookup"><span data-stu-id="538bf-158">See the cluster’s overview blade in Azure portal for more details.</span></span> <span data-ttu-id="538bf-159">Les ressources [GitHub][github] montrent également comment afficher le tableau de bord à partir de R.</span><span class="sxs-lookup"><span data-stu-id="538bf-159">The [GitHub][github] resources also show how to bring up the dashboard from R.</span></span>

<span data-ttu-id="538bf-160">Bien que le tableau de bord vous donne un aperçu de l’intégrité globale de votre cluster, il est également important de suivre l’état des conteneurs individuels.</span><span class="sxs-lookup"><span data-stu-id="538bf-160">Although the dashboard gives you a view of the overall health of your cluster, it’s also important to track the status of individual containers.</span></span> <span data-ttu-id="538bf-161">Pour cela, activez [Azure Monitor Insights][monitor] à partir du panneau de présentation du cluster dans le portail Azure ou consultez [Azure Monitor pour les conteneurs][monitor-containers] (en préversion).</span><span class="sxs-lookup"><span data-stu-id="538bf-161">To do this, enable [Azure Monitor Insights][monitor] from the cluster overview blade in Azure portal, or see [Azure Monitor for containers][monitor-containers] (in preview).</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="538bf-162">Considérations relatives au coût</span><span class="sxs-lookup"><span data-stu-id="538bf-162">Cost considerations</span></span>

<span data-ttu-id="538bf-163">Machine Learning Server est concédé sous licence par cœur et tous les cœurs inclus dans le cluster qui exécutera Machine Learning Server sont comptabilisés.</span><span class="sxs-lookup"><span data-stu-id="538bf-163">Machine Learning Server is licensed on a per-core basis, and all the cores in the cluster that will run Machine Learning  Server count towards this.</span></span> <span data-ttu-id="538bf-164">Si vous êtes client Machine Learning Server ou Microsoft SQL Server professionnel, contactez votre représentant Microsoft pour plus d’informations tarifaires.</span><span class="sxs-lookup"><span data-stu-id="538bf-164">If you are an enterprise Machine Learning Server or Microsoft SQL Server customer, contact your Microsoft representative for pricing details.</span></span>

<span data-ttu-id="538bf-165">Une alternative open source à Machine Learning Server est [Plumber][plumber], un package R qui transforme votre code en API REST.</span><span class="sxs-lookup"><span data-stu-id="538bf-165">An open-source alternative to Machine Learning Server is [Plumber][plumber], an R package that turns your code into a REST API.</span></span> <span data-ttu-id="538bf-166">Plumber est moins complet que Machine Learning Server.</span><span class="sxs-lookup"><span data-stu-id="538bf-166">Plumber is less fully featured than Machine Learning Server.</span></span> <span data-ttu-id="538bf-167">Par exemple, par défaut, il n’inclut pas de fonctionnalités pour l’authentification des demandes.</span><span class="sxs-lookup"><span data-stu-id="538bf-167">For example, by default it doesn't include any features that provide request authentication.</span></span> <span data-ttu-id="538bf-168">Si vous utilisez Plumber, il est recommandé d’activer [Gestion des API Azure][API] pour gérer les détails de l’authentification.</span><span class="sxs-lookup"><span data-stu-id="538bf-168">If you use Plumber, it’s recommended that you enable [Azure API Management][API] to handle authentication details.</span></span>

<span data-ttu-id="538bf-169">En plus des licences, la principale considération en matière de coûts est liée aux ressources de calcul du cluster Kubernetes.</span><span class="sxs-lookup"><span data-stu-id="538bf-169">Besides licensing, the main cost consideration is the Kubernetes cluster's compute resources.</span></span> <span data-ttu-id="538bf-170">Le cluster doit être suffisamment grand pour gérer le volume de demandes attendu aux heures de pointe, mais cette approche laisse les ressources inactives aux autres moments.</span><span class="sxs-lookup"><span data-stu-id="538bf-170">The cluster must be large enough to handle the expected request volume at peak times, but this approach leaves resources idle at other times.</span></span> <span data-ttu-id="538bf-171">Pour limiter l’impact des ressources inactives, activez la [mise à l’échelle automatique horizontale][autoscaler] pour le cluster à l’aide de l’outil kubectl.</span><span class="sxs-lookup"><span data-stu-id="538bf-171">To limit the impact of idle resources, enable the [horizontal autoscaler][autoscaler] for the cluster using the kubectl tool.</span></span> <span data-ttu-id="538bf-172">Ou utilisez la [mise à l’échelle automatique du cluster][cluster-autoscaler] AKS.</span><span class="sxs-lookup"><span data-stu-id="538bf-172">Or use the AKS [cluster autoscaler][cluster-autoscaler].</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="538bf-173">Déployer la solution</span><span class="sxs-lookup"><span data-stu-id="538bf-173">Deploy the solution</span></span>

<span data-ttu-id="538bf-174">L’implémentation de référence de cette architecture est disponible sur [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="538bf-174">The reference implementation of this architecture is available on [GitHub][github].</span></span> <span data-ttu-id="538bf-175">Suivez les étapes qui y sont décrites pour déployer un modèle prédictif simple en tant que service.</span><span class="sxs-lookup"><span data-stu-id="538bf-175">Follow the steps described there to deploy a simple predictive model as a service.</span></span>

<!-- links -->
[AAD]: /azure/active-directory/fundamentals/active-directory-whatis
[API]: /azure/api-management/api-management-key-concepts
[ACR]: /azure/container-registry/container-registry-intro
[AKS]: /azure/aks/intro-kubernetes
[autoscaler]: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
[cluster-autoscaler]: /azure/aks/autoscaler
[monitor]: /azure/monitoring/monitoring-container-insights-overview
[dashboard]: /azure/aks/kubernetes-dashboard
[docker]: https://docs.docker.com/registry/spec/api/
[encrypt]: https://letsencrypt.org/
[gitHub]: https://github.com/Azure/RealtimeRDeployment
[K-API]: https://kubernetes.io/docs/reference/
[MMLS]: /machine-learning-server/what-is-machine-learning-server
[monitor-containers]: /azure/azure-monitor/insights/container-insights-overview
[operationalization]: /machine-learning-server/what-is-operationalization
[plumber]: https://www.rplumber.io
[RBAC]: /azure/role-based-access-control/overview
[storage]: /azure/storage/common/storage-introduction
[0]: ./_images/realtime-scoring-r.png
