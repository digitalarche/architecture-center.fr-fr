---
title: Entraînement distribué de modèles Deep Learning sur Azure
description: Cette architecture de référence montre comment procéder à un entraînement distribué de modèles Deep Learning (apprentissage profond) sur plusieurs clusters de machines virtuelles compatibles GPU à l’aide d’Azure Batch AI.
author: njray
ms.date: 01/14/19
ms.custom: azcat-ai
ms.openlocfilehash: 800defeb851f5a31dc730038c3699e1a3d54b923
ms.sourcegitcommit: d5ea427c25f9f7799cc859b99f328739ca2d8c1c
ms.translationtype: HT
ms.contentlocale: fr-FR
ms.lasthandoff: 01/15/2019
ms.locfileid: "54307756"
---
# <a name="distributed-training-of-deep-learning-models-on-azure"></a><span data-ttu-id="dcc2d-103">Entraînement distribué de modèles Deep Learning sur Azure</span><span class="sxs-lookup"><span data-stu-id="dcc2d-103">Distributed training of deep learning models on Azure</span></span>

<span data-ttu-id="dcc2d-104">Cette architecture de référence montre comment effectué un entraînement distribué de modèles Deep Learning sur plusieurs clusters de machines virtuelles compatibles GPU.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-104">This reference architecture shows how to conduct distributed training of deep learning models across clusters of GPU-enabled VMs.</span></span> <span data-ttu-id="dcc2d-105">Le scénario est une classification d’images, mais la solution peut être généralisée à d’autres scénarios de deep learning, tels que la segmentation et la détection d’objet.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-105">The scenario is image classification, but the solution can be generalized for other deep learning scenarios such as segmentation and object detection.</span></span>

<span data-ttu-id="dcc2d-106">Une implémentation de référence pour cette architecture est disponible sur [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="dcc2d-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Architecture du deep learning distribué][0]

<span data-ttu-id="dcc2d-108">**Scénario** : La classification d’images est une technique largement appliquée dans la vision par ordinateur et souvent traitée par l’entraînement d’un réseau neuronal convolutif (CNN).</span><span class="sxs-lookup"><span data-stu-id="dcc2d-108">**Scenario**: Image classification is a widely applied technique in computer vision, often tackled by training a convolutional neural network (CNN).</span></span> <span data-ttu-id="dcc2d-109">Pour les modèles particulièrement grands avec des jeux de données volumineux, le processus d’entraînement peut prendre plusieurs semaines ou mois sur un seul GPU.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-109">For particularly large models with large datasets, the training process can take weeks or months on a single GPU.</span></span> <span data-ttu-id="dcc2d-110">Dans certains cas, les modèles sont tellement grands qu’il n’est pas possible d’ajuster des tailles de lot raisonnables sur le GPU.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-110">In some situations, the models are so large that it's not possible to fit reasonable batch sizes onto the GPU.</span></span> <span data-ttu-id="dcc2d-111">L’utilisation de l’entraînement distribué peut alors raccourcir la durée d’entraînement.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-111">Using distributed training in these situations can shorten the training time.</span></span>

<span data-ttu-id="dcc2d-112">Dans ce scénario précis, un [modèle CNN ResNet50][resnet] est entraîné avec [Horovod][horovod] sur le [jeu de données Imagenet][imagenet] et des données synthétiques.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-112">In this specific scenario, a [ResNet50 CNN model][resnet] is trained using [Horovod][horovod] on the [Imagenet dataset][imagenet] and on synthetic data.</span></span> <span data-ttu-id="dcc2d-113">L’implémentation de référence montre comment accomplir cette tâche en utilisant trois des frameworks de deep learning les plus connus : TensorFlow, Keras et PyTorch.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-113">The reference implementation shows how to accomplish this task using three of the most popular deep learning frameworks: TensorFlow, Keras, and PyTorch.</span></span>

<span data-ttu-id="dcc2d-114">Il existe plusieurs façons d’entraîner un modèle Deep Learning de façon distribuée, notamment les approches à parallélisme de données et à parallélisme de modèle s’appuyant sur des mises à jour synchrones ou asynchrones.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-114">There are several ways to train a deep learning model in a distributed fashion, including data-parallel and model-parallel approaches based on synchronous or asynchronous updates.</span></span> <span data-ttu-id="dcc2d-115">Actuellement, le scénario le plus courant est le parallélisme de données avec mises à jour synchrones.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-115">Currently the most common scenario is data parallel with synchronous updates.</span></span> <span data-ttu-id="dcc2d-116">Cette approche est la plus facile à implémenter et est suffisante pour la plupart des cas d’usage.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-116">This approach is the easiest to implement and is sufficient for most use cases.</span></span>

<span data-ttu-id="dcc2d-117">Dans l’entraînement distribué à parallélisme de données avec mises à jour synchrones, le modèle est répliqué sur *n* appareils.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-117">In data-parallel distributed training with synchronous updates, the model is replicated across *n* hardware devices.</span></span> <span data-ttu-id="dcc2d-118">Un mini-lot d’exemples d’entraînement est divisé en *n* micro-lots.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-118">A mini-batch of training samples is divided into *n* micro-batches.</span></span> <span data-ttu-id="dcc2d-119">Chaque appareil effectue les propagations vers l’avant et vers l’arrière pour un micro-lot.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-119">Each device performs the forward and backward passes for a micro-batch.</span></span> <span data-ttu-id="dcc2d-120">Quand un appareil a terminé le traitement, il partage les mises à jour avec les autres appareils.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-120">When a device finishes the process, it shares the updates with the other devices.</span></span> <span data-ttu-id="dcc2d-121">Ces valeurs sont utilisées pour calculer les pondérations mises à jour de tout le mini-lot, et ces pondérations sont synchronisées entre les modèles.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-121">These values are used to calculate the updated weights of the entire mini-batch, and the weights are synchronized across the models.</span></span> <span data-ttu-id="dcc2d-122">Ce scénario est décrit dans le dépôt [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="dcc2d-122">This scenario is covered in the [GitHub][github] repository.</span></span>

![Entraînement distribué à parallélisme de données][1]

<span data-ttu-id="dcc2d-124">Cette architecture peut également servir pour le parallélisme de modèle et les mises à jour asynchrones.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-124">This architecture can also be used for model-parallel and asynchronous updates.</span></span> <span data-ttu-id="dcc2d-125">Dans l’entraînement distribué à parallélisme de modèle, le modèle est divisé entre *n* appareils, chaque appareil détenant une partie du modèle.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-125">In model-parallel distributed training, the model is divided across *n* hardware devices, with each device holding a part of the model.</span></span> <span data-ttu-id="dcc2d-126">Dans l’implémentation la plus simple, chaque appareil peut contenir une couche du réseau, et les informations sont transmises entre les appareils pendant la propagation vers l’avant et vers l’arrière.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-126">In the simplest implementation, each device may hold a layer of the network, and information is passed between devices during the forward and backwards pass.</span></span> <span data-ttu-id="dcc2d-127">Les réseaux neuronaux plus grands peuvent être entraînés de cette façon, mais au détriment des performances, car les appareils s’attendent les uns les autres continuellement pour effectuer la propagation vers l’avant ou vers l’arrière.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-127">Larger neural networks can be trained this way, but at the cost of performance, since devices are constantly waiting for each other to complete either the forward or backwards pass.</span></span> <span data-ttu-id="dcc2d-128">Certaines techniques avancées tentent de pallier partiellement ce problème au moyen de gradients synthétiques.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-128">Some advanced techniques try to partially alleviate this issue by using synthetic gradients.</span></span>

<span data-ttu-id="dcc2d-129">Les étapes de l’entraînement sont les suivantes :</span><span class="sxs-lookup"><span data-stu-id="dcc2d-129">The steps for training are:</span></span>

1. <span data-ttu-id="dcc2d-130">Créez des scripts prévus pour s’exécuter sur le cluster et entraîner votre modèle, puis transférez-les sur le stockage de fichiers.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-130">Create scripts that will run on the cluster and train your model, then transfer them to file storage.</span></span>

1. <span data-ttu-id="dcc2d-131">Écrivez les données dans le stockage Blob.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-131">Write the data to Blob Storage.</span></span>

1. <span data-ttu-id="dcc2d-132">Créez un serveur de fichiers Batch AI et téléchargez les données sur ce serveur depuis le stockage Blob.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-132">Create a Batch AI file server and download the data from Blob Storage onto it.</span></span>

1. <span data-ttu-id="dcc2d-133">Créez les conteneurs Docker pour chaque framework de deep learning et transférez-les sur un registre de conteneurs (Docker Hub).</span><span class="sxs-lookup"><span data-stu-id="dcc2d-133">Create the Docker containers for each deep learning framework and transfer them to a container registry (Docker Hub).</span></span>

1. <span data-ttu-id="dcc2d-134">Créez un pool Batch AI qui monte également le serveur de fichiers Batch AI.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-134">Create a Batch AI pool that also mounts the Batch AI file server.</span></span>

1. <span data-ttu-id="dcc2d-135">Envoyer des travaux.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-135">Submit jobs.</span></span> <span data-ttu-id="dcc2d-136">Chacun extrait l’image Docker et les scripts appropriés.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-136">Each pulls in the appropriate Docker image and scripts.</span></span>

1. <span data-ttu-id="dcc2d-137">Une fois le travail terminé, écrivez tous les résultats dans le stockage Fichier.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-137">Once the job is completed, write all the results to Files storage.</span></span>

## <a name="architecture"></a><span data-ttu-id="dcc2d-138">Architecture</span><span class="sxs-lookup"><span data-stu-id="dcc2d-138">Architecture</span></span>

<span data-ttu-id="dcc2d-139">Cette architecture est constituée des composants suivants.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-139">This architecture consists of the following components.</span></span>

<span data-ttu-id="dcc2d-140">**[Azure Batch AI][batch-ai]** joue le rôle central dans cette architecture en effectuant des opérations de scale-up et des scale-down sur les ressources en fonction des besoins.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-140">**[Azure Batch AI][batch-ai]** plays the central role in this architecture by scaling resources up and down according to need.</span></span> <span data-ttu-id="dcc2d-141">Batch AI est un service qui permet de provisionner et de gérer des clusters de machines virtuelles, de planifier des travaux, de collecter des résultats, de mettre à l’échelle des ressources, de gérer les défaillances et de créer le stockage approprié.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-141">Batch AI is a service that helps provision and manage clusters of VMs, schedule jobs, gather results, scale resources, handle failures, and create appropriate storage.</span></span> <span data-ttu-id="dcc2d-142">Il prend en charge les machines virtuelles compatibles GPU pour les charges de travail de Deep Learning.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-142">It supports GPU-enabled VMs for deep learning workloads.</span></span> <span data-ttu-id="dcc2d-143">Un kit SDK Python et une interface de ligne de commande (CLI) sont disponibles pour Batch AI.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-143">A Python SDK and a command-line interface (CLI) are available for Batch AI.</span></span>

> [!NOTE]
> <span data-ttu-id="dcc2d-144">La date du retrait du service Azure Batch AI est fixée au mois de mars 2019 ; ses capacités d’entraînement et de scoring à grande échelle sont désormais disponibles dans [Azure Machine Learning service][amls].</span><span class="sxs-lookup"><span data-stu-id="dcc2d-144">The Azure Batch AI service is retiring March 2019, and its at-scale training and scoring capabilities are now available in [Azure Machine Learning Service][amls].</span></span> <span data-ttu-id="dcc2d-145">Cette architecture de référence sera bientôt actualisée pour utiliser Machine Learning qui offre une cible de calcul managée appelée [Capacité de calcul Azure Machine Learning][aml-compute] pour l’entraînement, le déploiement et le scoring de modèles Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-145">This reference architecture will be updated soon to use Machine Learning, which offers a managed compute target called [Azure Machine Learning Compute][aml-compute] for training, deploying, and scoring machine learning models.</span></span>

<span data-ttu-id="dcc2d-146">Le **[stockage Blob][azure-blob]** sert à stocker les données.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-146">**[Blob storage][azure-blob]** is used to stage the data.</span></span> <span data-ttu-id="dcc2d-147">Ces données sont téléchargées sur un serveur de fichiers Batch AI pendant l’entraînement.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-147">This data is downloaded to a Batch AI file server during training.</span></span>

<span data-ttu-id="dcc2d-148">Le service **[Azure Files][files]** est utilisé pour stocker les scripts, journaux et résultats finaux provenant de l’entraînement.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-148">**[Azure Files][files]** is used to store the scripts, logs, and the final results from the training.</span></span> <span data-ttu-id="dcc2d-149">Le stockage Fichier fonctionne bien pour le stockage des journaux et des scripts, mais il n’est pas aussi performant que le stockage Blob et ne doit donc pas être utilisé pour les tâches gourmandes en données.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-149">File storage works well for storing logs and scripts, but is not as performant as Blob Storage, so it shouldn't be used for data-intensive tasks.</span></span>

<span data-ttu-id="dcc2d-150">Le **[serveur de fichiers Batch AI][batch-ai-files]** est un partage NFS à un seul nœud servant à stocker les données d’entraînement dans cette architecture.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-150">**[Batch AI file server][batch-ai-files]** is a single-node NFS share used in this architecture to store the training data.</span></span> <span data-ttu-id="dcc2d-151">Batch AI crée un partage NFS et le monte sur le cluster.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-151">Batch AI creates an NFS share and mounts it on the cluster.</span></span> <span data-ttu-id="dcc2d-152">Les serveurs de fichiers Batch AI sont le moyen recommandé pour délivrer des données sur le cluster avec le débit nécessaire.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-152">Batch AI file servers are the recommended way to serve data to the cluster with the necessary throughput.</span></span>

<span data-ttu-id="dcc2d-153">**[Docker Hub][docker]** est utilisé pour stocker l’image Docker que Batch AI utilise pour exécuter l’entraînement.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-153">**[Docker Hub][docker]** is used to store the Docker image that Batch AI uses to run the training.</span></span> <span data-ttu-id="dcc2d-154">DockerHub a été choisi pour cette architecture, car il est simple d’utilisation et constitue le référentiel d’images par défaut des utilisateurs de Docker.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-154">Docker Hub was chosen for this architecture because it's easy to use and is the default image repository for Docker users.</span></span> <span data-ttu-id="dcc2d-155">[Azure Container Registry][acr] peut aussi être utilisé.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-155">[Azure Container Registry][acr] can also be used.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="dcc2d-156">Considérations relatives aux performances</span><span class="sxs-lookup"><span data-stu-id="dcc2d-156">Performance considerations</span></span>

<span data-ttu-id="dcc2d-157">Azure fournit quatre [types de machines virtuelles compatibles GPU][gpu] qui conviennent pour l’entraînement des modèles Deep Learning.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-157">Azure provides four [GPU-enabled VM types][gpu] suitable for training deep learning models.</span></span> <span data-ttu-id="dcc2d-158">En termes de prix et de vitesse, elles varient de la plus faible à la plus élevée comme suit :</span><span class="sxs-lookup"><span data-stu-id="dcc2d-158">They range in price and speed from low to high as follows:</span></span>

| <span data-ttu-id="dcc2d-159">**Série Machines virtuelles Azure**</span><span class="sxs-lookup"><span data-stu-id="dcc2d-159">**Azure VM series**</span></span> | <span data-ttu-id="dcc2d-160">**GPU NVIDIA**</span><span class="sxs-lookup"><span data-stu-id="dcc2d-160">**NVIDIA GPU**</span></span> |
|---------------------|----------------|
| <span data-ttu-id="dcc2d-161">NC</span><span class="sxs-lookup"><span data-stu-id="dcc2d-161">NC</span></span>                  | <span data-ttu-id="dcc2d-162">K80</span><span class="sxs-lookup"><span data-stu-id="dcc2d-162">K80</span></span>            |
| <span data-ttu-id="dcc2d-163">ND</span><span class="sxs-lookup"><span data-stu-id="dcc2d-163">ND</span></span>                  | <span data-ttu-id="dcc2d-164">P40</span><span class="sxs-lookup"><span data-stu-id="dcc2d-164">P40</span></span>            |
| <span data-ttu-id="dcc2d-165">NCv2</span><span class="sxs-lookup"><span data-stu-id="dcc2d-165">NCv2</span></span>                | <span data-ttu-id="dcc2d-166">P100</span><span class="sxs-lookup"><span data-stu-id="dcc2d-166">P100</span></span>           |
| <span data-ttu-id="dcc2d-167">NCv3</span><span class="sxs-lookup"><span data-stu-id="dcc2d-167">NCv3</span></span>                | <span data-ttu-id="dcc2d-168">V100</span><span class="sxs-lookup"><span data-stu-id="dcc2d-168">V100</span></span>           |

<span data-ttu-id="dcc2d-169">Nous recommandons d’effectuer un scaling-up de votre entraînement avant de procéder à un scaling-out. Par exemple, essayez un seul V100 avant d’opter pour un cluster de K80.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-169">We recommended scaling up your training before scaling out. For example, try a single V100 before trying a cluster of K80s.</span></span>

<span data-ttu-id="dcc2d-170">Le graphique suivant montre les différences de performance entre différents types de GPU, selon les [tests d’évaluation][benchmark] effectués avec TensorFlow et Horovod sur Batch AI.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-170">The following graph shows the performance differences for different GPU types based on [benchmarking tests][benchmark] carried out using TensorFlow and Horovod on Batch AI.</span></span> <span data-ttu-id="dcc2d-171">Le graphique renseigne sur le débit de 32 clusters GPU, dans divers modèles, sur des versions MPI et des types de GPU différents.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-171">The graph shows throughput of 32 GPU clusters across various models, on different GPU types and MPI versions.</span></span> <span data-ttu-id="dcc2d-172">Les modèles ont été implémentés dans TensorFlow 1.9</span><span class="sxs-lookup"><span data-stu-id="dcc2d-172">Models were implemented in TensorFlow 1.9</span></span>

![Débits des modèles TensorFlow sur les clusters GPU][2]

<span data-ttu-id="dcc2d-174">Chaque série de machines virtuelles affichée dans le précédent tableau comprend une configuration avec InfiniBand.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-174">Each VM series shown in the previous table includes a configuration with InfiniBand.</span></span> <span data-ttu-id="dcc2d-175">Utilisez les configurations InfiniBand lors de l’exécution de l’entraînement distribué pour accélérer la communication entre les nœuds.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-175">Use the InfiniBand configurations when you run distributed training, for faster communication between nodes.</span></span> <span data-ttu-id="dcc2d-176">InfiniBand augmente également l’efficacité de la mise à l’échelle de l’entraînement pour les frameworks qui peuvent en tirer parti.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-176">InfiniBand also increases the scaling efficiency of the training for the frameworks that can take advantage of it.</span></span> <span data-ttu-id="dcc2d-177">Pour plus d’informations, consultez la [comparaison des tests d’évaluation][benchmark] Infiniband.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-177">For details, see the Infiniband [benchmark comparison][benchmark].</span></span>

<span data-ttu-id="dcc2d-178">Même si Batch AI peut monter le stockage Blob à l’aide de l’adaptateur [blobfuse][blobfuse], nous ne recommandons pas cette utilisation du stockage Blob pour l’entraînement distribué, car les performances ne sont pas suffisantes pour gérer le débit nécessaire.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-178">Although Batch AI can mount Blob storage using the [blobfuse][blobfuse] adapter, we don't recommend using Blob Storage this way for distributed training, because the performance isn't good enough to handle the necessary throughput.</span></span> <span data-ttu-id="dcc2d-179">Déplacez plutôt les données sur un serveur de fichiers Batch AI, comme indiqué dans le schéma de l’architecture.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-179">Move the data to a Batch AI file server instead, as shown in the architecture diagram.</span></span>

## <a name="scalability-considerations"></a><span data-ttu-id="dcc2d-180">Considérations relatives à l’extensibilité</span><span class="sxs-lookup"><span data-stu-id="dcc2d-180">Scalability considerations</span></span>

<span data-ttu-id="dcc2d-181">L’efficacité de la mise à l’échelle de l’entraînement distribué est toujours inférieure à 100 % en raison de la charge réseau ; la synchronisation de l’ensemble du modèle entre les appareils se transforme en goulot d’étranglement.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-181">The scaling efficiency of distributed training is always less than 100 percent due to network overhead &mdash; syncing the entire model between devices becomes a bottleneck.</span></span> <span data-ttu-id="dcc2d-182">Ainsi, l’entraînement distribué est la solution la mieux adaptée pour les grands modèles qui ne peuvent pas être entraînés avec une taille de lot appropriée sur un GPU, ou pour les problèmes qui ne peuvent pas être résolus en distribuant le modèle de manière simple et parallèle.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-182">Therefore, distributed training is most suited for large models that cannot be trained using a reasonable batch size on a single GPU, or for problems that cannot be addressed by distributing the model in a simple, parallel way.</span></span>

<span data-ttu-id="dcc2d-183">L’entraînement distribué n’est pas recommandé pour effectuer des recherches d’hyperparamètres.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-183">Distributed training is not recommended for running hyperparameter searches.</span></span> <span data-ttu-id="dcc2d-184">L’efficacité de la mise à l’échelle a une incidence sur les performances, et rend l’approche distribuée moins efficace que l’entraînement de plusieurs configurations de modèle séparément.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-184">The scaling efficiency affects performance and makes a distributed approach less efficient than training multiple model configurations separately.</span></span>

<span data-ttu-id="dcc2d-185">Une solution permettant d’augmenter l’efficacité de la mise à l’échelle consiste à accroître la taille de lot.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-185">One way to increase scaling efficiency is to increase the batch size.</span></span> <span data-ttu-id="dcc2d-186">Cette opération doit, toutefois, être effectuée avec précaution, car l’augmentation de la taille de lot sans ajuster les autres paramètres peut nuire aux performances finales du modèle.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-186">That must be done carefully, however, because increasing the batch size without adjusting the other parameters can hurt the model's final performance.</span></span>

## <a name="storage-considerations"></a><span data-ttu-id="dcc2d-187">Considérations relatives au stockage</span><span class="sxs-lookup"><span data-stu-id="dcc2d-187">Storage considerations</span></span>

<span data-ttu-id="dcc2d-188">Dans l’entraînement de modèles Deep Learning, un aspect souvent négligé est l’endroit où sont stockées les données.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-188">When training deep learning models, an often-overlooked aspect is where the data is stored.</span></span> <span data-ttu-id="dcc2d-189">Si le stockage est trop lent pour répondre aux exigences des GPU, les performances d’entraînement peuvent se détériorer.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-189">If the storage is too slow to keep up with the demands of the GPUs, training performance can degrade.</span></span>

<span data-ttu-id="dcc2d-190">Batch AI prend en charge de nombreuses solutions de stockage.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-190">Batch AI supports many storage solutions.</span></span> <span data-ttu-id="dcc2d-191">Cette architecture utilise un serveur de fichiers Batch AI parce qu’il offre le meilleur compromis entre la facilité d’utilisation et les performances.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-191">This architecture uses a Batch AI file server, because it provides the best tradeoff between ease of use and performance.</span></span> <span data-ttu-id="dcc2d-192">Pour de meilleures performances, chargez les données localement.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-192">For best performance, load the data locally.</span></span> <span data-ttu-id="dcc2d-193">Cette opération peut toutefois s’avérer fastidieuse, car tous les nœuds doivent télécharger les données depuis le stockage Blob, et avec le jeu de données ImageNet, cette opération peut prendre des heures.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-193">However, this can be cumbersome, because all the nodes must download the data from Blob Storage, and with the ImageNet dataset, this can take hours.</span></span> <span data-ttu-id="dcc2d-194">Le [Stockage Blob Azure Premium][blob] (préversion publique limitée) est une autre bonne solution à prendre en compte.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-194">[Azure Premium Blob Storage][blob] (limited public preview) is another good option to consider.</span></span>

<span data-ttu-id="dcc2d-195">Ne montez pas le stockage Blob ni le stockage Fichier en tant que magasins de données pour l’entraînement distribué.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-195">Do not mount Blob and File storage as data stores for distributed training.</span></span> <span data-ttu-id="dcc2d-196">Ils sont trop lents et gêneront les performances de l’entraînement.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-196">They are too slow and will hinder training performance.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="dcc2d-197">Considérations relatives à la sécurité</span><span class="sxs-lookup"><span data-stu-id="dcc2d-197">Security considerations</span></span>

### <a name="restrict-access-to-azure-blob-storage"></a><span data-ttu-id="dcc2d-198">Restreindre l’accès au stockage Blob Azure</span><span class="sxs-lookup"><span data-stu-id="dcc2d-198">Restrict access to Azure Blob Storage</span></span>

<span data-ttu-id="dcc2d-199">Cette architecture utilise des [clés de compte de stockage][security-guide] pour accéder au stockage Blob.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-199">This architecture uses [storage account keys][security-guide] to access the Blob storage.</span></span> <span data-ttu-id="dcc2d-200">Pour une protection et un contrôle accrus, envisagez d’utiliser une signature d’accès partagé (SAP).</span><span class="sxs-lookup"><span data-stu-id="dcc2d-200">For further control and protection, consider using a shared access signature (SAS) instead.</span></span> <span data-ttu-id="dcc2d-201">Celle-ci octroie un accès limité aux objets contenus dans le stockage, sans qu’il soit nécessaire de coder en dur les clés de compte ou de les enregistrer en texte clair.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-201">This grants limited access to objects in storage, without needing to hard-code the account keys or save them in plaintext.</span></span> <span data-ttu-id="dcc2d-202">L’utilisation d’une signature SAS permet aussi de s’assurer que le compte de stockage obéit à une gouvernance appropriée, et que l’accès est octroyé uniquement aux personnes censées en bénéficier.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-202">Using a SAS also helps to ensure that the storage account has proper governance, and that access is granted only to the people intended to have it.</span></span>

<span data-ttu-id="dcc2d-203">Dans les scénarios faisant intervenir des données plus sensibles, veillez à ce que toutes vos clés de stockage soient protégées, car elles octroient un accès complet à toutes les données d’entrée et de sortie de la charge de travail.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-203">For scenarios with more sensitive data, make sure that all of your storage keys are protected, because these keys grant full access to all input and output data from the workload.</span></span>

### <a name="encrypt-data-at-rest-and-in-motion"></a><span data-ttu-id="dcc2d-204">Chiffrer les données au repos ou en déplacement</span><span class="sxs-lookup"><span data-stu-id="dcc2d-204">Encrypt data at rest and in motion</span></span>

<span data-ttu-id="dcc2d-205">Dans les scénarios qui utilisent des données sensibles, chiffrez les données au repos, autrement dit les données présentes dans le stockage.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-205">In scenarios that use sensitive data, encrypt the data at rest &mdash; that is, the data in storage.</span></span> <span data-ttu-id="dcc2d-206">Chaque fois que des données se déplacent d’un emplacement à l’autre, utilisez SSL pour sécuriser le transfert des données.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-206">Each time data moves from one location to the next, use SSL to secure the data transfer.</span></span> <span data-ttu-id="dcc2d-207">Pour plus d’informations, consultez le [guide de sécurité du stockage Azure][security-guide].</span><span class="sxs-lookup"><span data-stu-id="dcc2d-207">For more information, see the [Azure Storage security guide][security-guide].</span></span>

### <a name="secure-data-in-a-virtual-network"></a><span data-ttu-id="dcc2d-208">Protéger les données dans un réseau virtuel</span><span class="sxs-lookup"><span data-stu-id="dcc2d-208">Secure data in a virtual network</span></span>

<span data-ttu-id="dcc2d-209">Pour les déploiements de production, envisagez de déployer le cluster Batch AI dans un sous-réseau du réseau virtuel que vous spécifiez.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-209">For production deployments, consider deploying the Batch AI cluster into a subnet of a virtual network that you specify.</span></span> <span data-ttu-id="dcc2d-210">Les nœuds de calcul du cluster peuvent ainsi communiquer de façon sécurisée avec d’autres machines virtuelles ou avec un réseau local.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-210">This allows the compute nodes in the cluster to communicate securely with other virtual machines or with an on-premises network.</span></span> <span data-ttu-id="dcc2d-211">Vous pouvez aussi utiliser des [points de terminaison de service][endpoints] avec le stockage Blob pour octroyer un accès à partir d’un réseau virtuel, ou utiliser un système NFS à un seul nœud à l’intérieur du réseau virtuel avec Batch AI.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-211">You can also use [service endpoints][endpoints] with blob storage to grant access from a virtual network or use a single-node NFS inside the virtual network with Batch AI.</span></span>

## <a name="monitoring-considerations"></a><span data-ttu-id="dcc2d-212">Surveillance - Éléments à prendre en compte</span><span class="sxs-lookup"><span data-stu-id="dcc2d-212">Monitoring considerations</span></span>

<span data-ttu-id="dcc2d-213">Pendant que vous exécutez votre tâche, il est important de superviser la progression et de vérifier que tout fonctionne comme prévu.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-213">While running your job, it's important to monitor the progress and make sure that things are working as expected.</span></span> <span data-ttu-id="dcc2d-214">Cependant, superviser un cluster de nœuds actifs peut s’avérer ardu.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-214">However, it can be a challenge to monitor across a cluster of active nodes.</span></span>

<span data-ttu-id="dcc2d-215">Les serveurs de fichiers Batch AI peuvent être gérés via le portail Azure ou par le biais de l’interface [Azure CLI][cli] et du kit SDK Python.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-215">The Batch AI file servers can be managed through the Azure portal or though the [Azure CLI][cli] and Python SDK.</span></span> <span data-ttu-id="dcc2d-216">Pour vous faire une idée de l’état général du cluster, accédez à **Batch AI** dans le portail Azure pour inspecter l’état des nœuds du cluster.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-216">To get a sense of the overall state of the cluster, navigate to **Batch AI** in the Azure portal to inspect the state of the cluster nodes.</span></span> <span data-ttu-id="dcc2d-217">Si un nœud est inactif ou si une tâche échoue, les journaux d’erreurs sont enregistrés dans le stockage Blob ; ils sont aussi accessibles dans le portail Azure, sous **Tâches**.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-217">If a node is inactive or a job fails, the error logs are saved to blob storage, and are also accessible in the Azure Portal under **Jobs**.</span></span>

<span data-ttu-id="dcc2d-218">Enrichissez la supervision en connectant les journaux à [Azure Application Insights][ai] ou en exécutant des processus distincts qui demandent l’état du cluster Batch AI et de ses tâches.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-218">Enrich monitoring by connecting logs to [Azure Application Insights][ai] or by running separate processes that poll for the state of the Batch AI cluster and its jobs.</span></span>

<span data-ttu-id="dcc2d-219">Batch AI journalise automatiquement tous les stdout/stderr dans le compte du stockage Blob associé.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-219">Batch AI automatically logs all stdout/stderr to the associate Blob storage account.</span></span> <span data-ttu-id="dcc2d-220">Utilisez un outil de navigation de stockage, comme l’[Explorateur Stockage Azure][storage-explorer], pour faciliter l’expérience de navigation dans les fichiers journaux.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-220">Use a storage navigation tool such as [Azure Storage Explorer][storage-explorer] for an easier experience when navigating log files.</span></span>

<span data-ttu-id="dcc2d-221">Il est également possible de diffuser en continu les journaux pour chaque tâche.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-221">It is also possible to stream the logs for each job.</span></span> <span data-ttu-id="dcc2d-222">Pour plus d’informations sur cette option, consultez les étapes de développement sur [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="dcc2d-222">For details about this option, see the development steps on [GitHub][github].</span></span>

## <a name="deployment"></a><span data-ttu-id="dcc2d-223">Déploiement</span><span class="sxs-lookup"><span data-stu-id="dcc2d-223">Deployment</span></span>

<span data-ttu-id="dcc2d-224">L’implémentation de référence de cette architecture est disponible sur [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="dcc2d-224">The reference implementation of this architecture is available on [GitHub][github].</span></span> <span data-ttu-id="dcc2d-225">Suivez les étapes qui y sont décrites pour effectuer un entraînement distribué de modèles Deep Learning sur les clusters de machines virtuelles compatibles GPU.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-225">Follow the steps described there to conduct distributed training of deep learning models across clusters of GPU-enabled VMs.</span></span>

## <a name="next-steps"></a><span data-ttu-id="dcc2d-226">Étapes suivantes</span><span class="sxs-lookup"><span data-stu-id="dcc2d-226">Next steps</span></span>

<span data-ttu-id="dcc2d-227">La sortie de cette architecture est un modèle entraîné qui est enregistré dans le stockage d’objets blob.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-227">The output from this architecture is a trained model that is saved to blob storage.</span></span> <span data-ttu-id="dcc2d-228">Vous pouvez faire fonctionner ce modèle pour le scoring en temps réel ou le scoring par lots.</span><span class="sxs-lookup"><span data-stu-id="dcc2d-228">You can operationalize this model for either real-time scoring or batch scoring.</span></span> <span data-ttu-id="dcc2d-229">Pour en savoir plus, consultez les architectures de référence suivantes :</span><span class="sxs-lookup"><span data-stu-id="dcc2d-229">For more information, see the following reference architectures:</span></span>

- <span data-ttu-id="dcc2d-230">[Scoring en temps réel des modèles Python Scikit-Learn et des modèles Deep Learning sur Azure][real-time-scoring]</span><span class="sxs-lookup"><span data-stu-id="dcc2d-230">[Real-time scoring of Python Scikit-Learn and deep learning models on Azure][real-time-scoring]</span></span>
- <span data-ttu-id="dcc2d-231">[Scoring par lots dans Azure pour les modèles Deep Learning][batch-scoring]</span><span class="sxs-lookup"><span data-stu-id="dcc2d-231">[Batch scoring on Azure for deep learning models][batch-scoring]</span></span>

[0]: ./_images/distributed_dl_architecture.png
[1]: ./_images/distributed_dl_flow.png
[2]: ./_images/distributed_dl_tests.png
[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[azure-blob]: /azure/storage/blobs/storage-blobs-introduction
[batch-ai]: /azure/batch-ai/overview
[batch-ai-files]: /azure/batch-ai/resource-concepts#file-server
[batch-scoring]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[benchmark]: https://github.com/msalvaris/BatchAIHorovodBenchmark
[blob]: https://azure.microsoft.com/en-gb/blog/introducing-azure-premium-blob-storage-limited-public-preview/
[blobfuse]: https://github.com/Azure/azure-storage-fuse
[cli]: https://github.com/Azure/BatchAI/blob/master/documentation/using-azure-cli-20.md
[docker]: https://hub.docker.com/
[endpoints]: /azure/storage/common/storage-network-security?toc=%2fazure%2fvirtual-network%2ftoc.json#grant-access-from-a-virtual-network
[files]: /azure/storage/files/storage-files-introduction
[github]: https://github.com/Azure/DistributedDeepLearning/
[gpu]: /azure/virtual-machines/windows/sizes-gpu
[horovod]: https://github.com/uber/horovod
[imagenet]: http://www.image-net.org/
[real-time-scoring]: /azure/architecture/reference-architectures/ai/realtime-scoring-python
[resnet]: https://arxiv.org/abs/1512.03385
[security-guide]: /azure/storage/common/storage-security-guide
[storage-explorer]: /azure/vs-azure-tools-storage-manage-with-storage-explorer?tabs=windows
[tutorial]: https://github.com/Azure/DistributedDeepLearning