---
title: ETL hybride avec des instances SSIS locales existantes et Azure Data Factory
description: ETL hybride avec des déploiements de SQL Server Integration Services (SSIS) locaux existants et Azure Data Factory
author: alhieng
ms.date: 9/20/2018
ms.openlocfilehash: c4c0cfd63ef1d6c620eb36e16622ad9ffb7b5d80
ms.sourcegitcommit: 16bc6a91b6b9565ca3bcc72d6eb27c2c4ae935e4
ms.translationtype: HT
ms.contentlocale: fr-FR
ms.lasthandoff: 11/28/2018
ms.locfileid: "52579461"
---
# <a name="hybrid-etl-with-existing-on-premises-ssis-and-azure-data-factory"></a><span data-ttu-id="1e9bc-103">ETL hybride avec des instances SSIS locales existantes et Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="1e9bc-103">Hybrid ETL with existing on-premises SSIS and Azure Data Factory</span></span>

<span data-ttu-id="1e9bc-104">Les organisations qui migrent leurs bases de données SQL Server vers le cloud peuvent réaliser des économies considérables, augmenter les performances, gagner en flexibilité et améliorer la scalabilité.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-104">Organizations that migrate their SQL Server databases to the cloud can realize tremendous cost savings, performance gains, added flexibility, and greater scalability.</span></span> <span data-ttu-id="1e9bc-105">Toutefois, le fait de retravailler des processus ETL (extraire, transformer et charger) existants conçus avec SQL Server Integration Services (SSIS) peut être un obstacle pour la migration.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-105">However, reworking existing extract, transform, and load (ETL) processes built with SQL Server Integration Services (SSIS) can be a migration roadblock.</span></span> <span data-ttu-id="1e9bc-106">Dans d’autres cas, le processus de chargement de données nécessite une logique complexe et/ou des composants d’outil de données spécifiques qui ne sont pas encore pris en charge par Azure Data Factory v2 (ADF).</span><span class="sxs-lookup"><span data-stu-id="1e9bc-106">In other cases, the data load process requires complex logic and/or specific data tool components that are not yet supported by Azure Data Factory v2 (ADF).</span></span> <span data-ttu-id="1e9bc-107">Les fonctionnalités SSIS couramment utilisées comprennent des transformations Recherche floue et Regroupement probable, la capture des changements de données (CDC), les dimensions à variation lente (SCD) et Data Quality Services (DQS).</span><span class="sxs-lookup"><span data-stu-id="1e9bc-107">Commonly used SSIS capabilities include Fuzzy Lookup and Fuzzy Grouping transformations, Change Data Capture (CDC), Slowly Changing Dimensions (SCD), and Data Quality Services (DQS).</span></span>

<span data-ttu-id="1e9bc-108">L’approche ETL hybride peut être l’option la plus adaptée pour faciliter une migration lift-and-shift d’une base de données SQL existante.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-108">To facilitate a lift-and-shift migration of an existing SQL database, a hybrid ETL approach may be the most suitable option.</span></span> <span data-ttu-id="1e9bc-109">Une approche hybride utilise ADF comme moteur d’orchestration principal, mais continue à tirer parti des packages SSIS existants pour nettoyer les données et utiliser les ressources locales.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-109">A hybrid approach uses ADF as the primary orchestration engine, but continues to leverage existing SSIS packages to clean data and work with on-premise resources.</span></span> <span data-ttu-id="1e9bc-110">Cette approche utilise SQL Server Integrated Runtime (IR) d’ADF pour effectuer un lift-and-shift des bases de données existantes dans le cloud, tout en utilisant le code existant et les packages SSIS.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-110">This approach uses the ADF SQL Server Integrated Runtime (IR) to enable a lift-and-shift of existing databases into the cloud, while using existing code and SSIS packages.</span></span>

<span data-ttu-id="1e9bc-111">Cet exemple de scénario s’applique aux organisations qui migrent des bases de données vers le cloud et envisagent d’utiliser ADF comme moteur ETL principal dans le cloud tout en incorporant des packages SSIS existants dans leur nouveau workflow de données cloud.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-111">This example scenario is relevant to organizations that are moving databases to the cloud and are considering using ADF as their primary cloud-based ETL engine while incorporating existing SSIS packages into their new cloud data workflow.</span></span> <span data-ttu-id="1e9bc-112">De nombreuses organisations ont beaucoup investi dans le développement de packages SSIS ETL pour des tâches de données spécifiques.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-112">Many organizations have significant invested in developing SSIS ETL packages for specific data tasks.</span></span> <span data-ttu-id="1e9bc-113">La réécriture de ces packages peut être décourageante.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-113">Rewriting these packages can be daunting.</span></span> <span data-ttu-id="1e9bc-114">Par ailleurs, de nombreux packages de code existants ont des dépendances sur des ressources locales qui empêchent la migration vers le cloud.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-114">Also, many existing code packages have dependencies on local resources, preventing migration to the cloud.</span></span>

<span data-ttu-id="1e9bc-115">ADF permet aux clients de tirer parti de leurs packages ETL existants sans investir outre mesure dans le développement ETL local.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-115">ADF lets customers take advantage of their existing ETL packages while limiting further investment in on-premises ETL development.</span></span> <span data-ttu-id="1e9bc-116">Cet exemple présente des cas d’usage potentiels pour tirer parti des packages SSIS existants dans le cadre d’un nouveau workflow de données cloud à l’aide d’Azure Data Factory v2.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-116">This example discusses potential use cases for leveraging existing SSIS packages as part of a new cloud data workflow using Azure Data Factory v2.</span></span>

## <a name="potential-use-cases"></a><span data-ttu-id="1e9bc-117">Cas d’usage potentiels</span><span class="sxs-lookup"><span data-stu-id="1e9bc-117">Potential use cases</span></span>

<span data-ttu-id="1e9bc-118">À l’origine, SSIS était l’outil ETL de choix pour de nombreux professionnels des données SQL Server dans le cadre de la transformation de données et du chargement.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-118">Traditionally, SSIS has been the ETL tool of choice for many SQL Server data professionals for data transformation and loading.</span></span> <span data-ttu-id="1e9bc-119">Parfois, des fonctionnalités SSIS spécifiques ou des composants enfichables tiers étaient utilisés pour accélérer les efforts de développement.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-119">Sometimes, specific SSIS features or third-party plugging components have been used to accelerate the development effort.</span></span> <span data-ttu-id="1e9bc-120">Le remplacement ou le redéveloppement de ces packages n’est pas toujours possible et empêche les clients de migrer leurs bases de données vers le cloud.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-120">Replacement or redevelopment of these packages may not be an option, which prevents customers from migrating their databases to the cloud.</span></span> <span data-ttu-id="1e9bc-121">Les clients cherchent une approche qui leur permette de migrer leurs bases de données existantes dans le cloud et de tirer parti de leurs packages SSIS existants avec le moins d’impact possible.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-121">Customers are looking for low impact approaches to migrating their existing databases to the cloud and taking advantage of their existing SSIS packages.</span></span>

<span data-ttu-id="1e9bc-122">Plusieurs cas d’usage locaux potentiels sont listés ci-dessous :</span><span class="sxs-lookup"><span data-stu-id="1e9bc-122">Several potential on-premises use cases are listed below:</span></span>

* <span data-ttu-id="1e9bc-123">Chargement des journaux de routeur réseau dans une base de données pour analyse.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-123">Loading network router logs to a database for analysis.</span></span>
* <span data-ttu-id="1e9bc-124">Préparation des données d’emploi des ressources humaines pour les rapports analytiques.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-124">Preparing human resources employment data for analytical reporting.</span></span>
* <span data-ttu-id="1e9bc-125">Chargement des données de produit et de ventes dans un entrepôt de données pour la prévision des ventes.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-125">Loading product and sales data into a data warehouse for sales forecasting.</span></span>
* <span data-ttu-id="1e9bc-126">Automatisation du chargement ou magasin de données opérationnels ou entrepôts de données pour la finance et la comptabilité.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-126">Automating loading or operational data stores or data warehouses for finance and accounting.</span></span>

## <a name="architecture"></a><span data-ttu-id="1e9bc-127">Architecture</span><span class="sxs-lookup"><span data-stu-id="1e9bc-127">Architecture</span></span>

![Vue d’ensemble de l’architecture d’un processus ETL hybride avec Azure Data Factory][architecture-diagram]

1. <span data-ttu-id="1e9bc-129">Les données proviennent d’un stockage Blob dans Data Factory.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-129">Data is sourced from Blob storage into Data Factory.</span></span>
2. <span data-ttu-id="1e9bc-130">Le pipeline Data Factory appelle une procédure stockée pour exécuter un travail SSIS hébergé localement via Integrated Runtime.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-130">The Data Factory pipeline invokes a stored procedure to execute an SSIS job hosted on-premises via the Integrated Runtime.</span></span>
3. <span data-ttu-id="1e9bc-131">Les travaux de nettoyage de données sont exécutés pour préparer les données à la consommation en aval.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-131">The data cleansing jobs are executed to prepare the data for downstream consumption.</span></span>
4. <span data-ttu-id="1e9bc-132">Une fois effectuée la tâche de nettoyage des données, une tâche de copie est exécutée pour charger les données propres dans Azure.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-132">Once the data cleansing task completes successfully, a copy task is executed to load the clean data into Azure.</span></span>
5. <span data-ttu-id="1e9bc-133">Les données propres sont ensuite chargées dans des tables dans SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-133">The clean data is then loaded into tables in the SQL Data Warehouse.</span></span>

### <a name="components"></a><span data-ttu-id="1e9bc-134">Composants</span><span class="sxs-lookup"><span data-stu-id="1e9bc-134">Components</span></span>

* <span data-ttu-id="1e9bc-135">Le [Stockage Blob][docs-blob-storage] est utilisé pour stocker des fichiers et comme source de Data Factory pour récupérer des données.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-135">[Blob storage][docs-blob-storage] is used to store files and as a source for Data Factory to retrieve data.</span></span>
* <span data-ttu-id="1e9bc-136">[SQL Server Integration Services][docs-ssis] contient les packages ETL locaux utilisés pour exécuter les charges de travail propres à la tâche.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-136">[SQL Server Integration Services][docs-ssis] contains the on-premises ETL packages used to execute task-specific workloads.</span></span>
* <span data-ttu-id="1e9bc-137">[Azure Data Factory][docs-data-factory] est le moteur d’orchestration cloud qui prend des données de plusieurs sources, et les combine, les orchestre et les charge dans un entrepôt de données.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-137">[Azure Data Factory][docs-data-factory] is the cloud orchestration engine that takes data from multiple sources and combines, orchestrates, and loads the data into a data warehouse.</span></span>
* <span data-ttu-id="1e9bc-138">[SQL Data Warehouse][docs-sql-data-warehouse] centralise les données dans le cloud pour pouvoir y accéder facilement à l’aide de requêtes SQL ANSI standard.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-138">[SQL Data Warehouse][docs-sql-data-warehouse] centralizes data in the cloud for easy access using standard ANSI SQL queries.</span></span>

### <a name="alternatives"></a><span data-ttu-id="1e9bc-139">Autres solutions</span><span class="sxs-lookup"><span data-stu-id="1e9bc-139">Alternatives</span></span>

<span data-ttu-id="1e9bc-140">Data Factory peut appeler des procédures de nettoyage de données implémentées à l’aide d’autres technologies, comme un notebook Databricks, un script Python ou une instance SSIS s’exécutant sur une machine virtuelle.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-140">Data Factory could invoke data cleansing procedures implemented using other technologies, such as a Databricks notebook, Python script, or SSIS instance running in a virtual machine.</span></span> <span data-ttu-id="1e9bc-141">[L’installation d’une version payante ou sous licence des composants personnalisés pour le runtime d’intégration Azure-SSIS](/azure/data-factory/how-to-develop-azure-ssis-ir-licensed-components) peut être une alternative viable à l’approche hybride.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-141">[Installing paid or licensed custom components for the Azure-SSIS integration runtime](/azure/data-factory/how-to-develop-azure-ssis-ir-licensed-components) may be a viable alternative to the hybrid approach.</span></span>

## <a name="considerations"></a><span data-ttu-id="1e9bc-142">Considérations</span><span class="sxs-lookup"><span data-stu-id="1e9bc-142">Considerations</span></span>

<span data-ttu-id="1e9bc-143">Le runtime intégré (IR) prend en charge deux modèles : IR auto-hébergé ou IR hébergé par Azure.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-143">The Integrated Runtime (IR) supports two models: self-hosted IR or Azure-hosted IR.</span></span> <span data-ttu-id="1e9bc-144">Vous devez d’abord choisir l’une de ces deux options.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-144">You first must decide between these two options.</span></span> <span data-ttu-id="1e9bc-145">L’auto-hébergement est plus économique, mais représente davantage de gestion et de maintenance.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-145">Self-hosting is more cost effective but has more overhead for maintenance and management.</span></span> <span data-ttu-id="1e9bc-146">Pour plus d'informations, consultez [IR auto-hébergé](/azure/data-factory/concepts-integration-runtime#self-hosted-integration-runtime).</span><span class="sxs-lookup"><span data-stu-id="1e9bc-146">For more information, see [Self-hosted IR](/azure/data-factory/concepts-integration-runtime#self-hosted-integration-runtime).</span></span> <span data-ttu-id="1e9bc-147">Si vous avez besoin d’aide pour déterminer l’IR à utiliser, consultez [Choix du runtime d’intégration à utiliser](/azure/data-factory/concepts-integration-runtime#determining-which-ir-to-use).</span><span class="sxs-lookup"><span data-stu-id="1e9bc-147">If you need help determining which IR to use, see [Determining which IR to use](/azure/data-factory/concepts-integration-runtime#determining-which-ir-to-use).</span></span>

<span data-ttu-id="1e9bc-148">Pour l’approche d’hébergement sur Azure, vous devez choisir la quantité d’énergie nécessaire pour traiter vos données.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-148">For the Azure-hosted approach, you should decide how much power is required to process your data.</span></span> <span data-ttu-id="1e9bc-149">La configuration hébergée sur Azure vous permet de sélectionner la taille de machine virtuelle dans le cadre des étapes de configuration.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-149">The Azure-hosted configuration allows you to select the VM size as part of the configuration steps.</span></span> <span data-ttu-id="1e9bc-150">Pour en savoir plus sur la sélection des tailles de machine virtuelle, consultez [Considérations sur les performances de machine virtuelle](/azure/cloud-services/cloud-services-sizes-specs#performance-considerations).</span><span class="sxs-lookup"><span data-stu-id="1e9bc-150">To learn more about selecting VM sizes, see [VM performance considerations](/azure/cloud-services/cloud-services-sizes-specs#performance-considerations).</span></span>

<span data-ttu-id="1e9bc-151">Le choix est plus facile quand vous avez déjà des packages SSIS existants avec des dépendances locales comme des sources de données ou des fichiers qui ne sont pas accessibles à partir d’Azure.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-151">The decision is much easier when you already have existing SSIS packages that have on-premise dependencies such as data sources or files that are not accessible from Azure.</span></span> <span data-ttu-id="1e9bc-152">Dans ce scénario, votre seule option est l’IR auto-hébergé.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-152">In this scenario, your only option is the self-hosted IR.</span></span> <span data-ttu-id="1e9bc-153">Cette approche offre davantage de souplesse pour tirer parti du cloud comme moteur d’orchestration, sans avoir à réécrire les packages existants.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-153">This approach provides the most flexibility to leverage the cloud as the orchestration engine, without having to rewrite existing packages.</span></span>

<span data-ttu-id="1e9bc-154">L’objectif est de déplacer les données traitées dans le cloud pour les affiner ou les combiner avec d’autres données stockées dans le cloud.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-154">Ultimately, the intent is to move the processed data into the cloud for further refinement or combining with other data stored in the cloud.</span></span> <span data-ttu-id="1e9bc-155">Dans le cadre du processus de conception, effectuez le suivi du nombre d’activités utilisées dans les pipelines ADF.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-155">As part of the design process, keep track of the number of activities used in the ADF pipelines.</span></span> <span data-ttu-id="1e9bc-156">Pour plus d’informations, consultez [Pipelines et activités dans Azure Data Factory](/azure/data-factory/concepts-pipelines-activities).</span><span class="sxs-lookup"><span data-stu-id="1e9bc-156">For more information, see [Pipelines and activities in Azure Data Factory](/azure/data-factory/concepts-pipelines-activities).</span></span>

## <a name="pricing"></a><span data-ttu-id="1e9bc-157">Tarifs</span><span class="sxs-lookup"><span data-stu-id="1e9bc-157">Pricing</span></span>

<span data-ttu-id="1e9bc-158">Azure Data Factory est un moyen économique d’orchestrer le déplacement des données dans le cloud.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-158">Azure Data Factory is a cost-effective way to orchestrate data movement in the cloud.</span></span> <span data-ttu-id="1e9bc-159">Le coût dépend de plusieurs facteurs.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-159">The cost is based on the several factors.</span></span>

* <span data-ttu-id="1e9bc-160">Nombre d’exécutions de pipeline</span><span class="sxs-lookup"><span data-stu-id="1e9bc-160">Number of pipeline executions</span></span>
* <span data-ttu-id="1e9bc-161">Nombre d’entités/d’activités utilisées dans le pipeline</span><span class="sxs-lookup"><span data-stu-id="1e9bc-161">Number of entities/activities used within the pipeline</span></span>
* <span data-ttu-id="1e9bc-162">Nombre d’opérations de supervision</span><span class="sxs-lookup"><span data-stu-id="1e9bc-162">Number of monitoring operations</span></span>
* <span data-ttu-id="1e9bc-163">Nombre d’exécutions d’intégration (IR hébergé dans Azure ou IR auto-hébergé)</span><span class="sxs-lookup"><span data-stu-id="1e9bc-163">Number of Integration Runs (Azure-hosted IR or self-hosted IR)</span></span>

<span data-ttu-id="1e9bc-164">ADF utilise la facturation à l’utilisation.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-164">ADF uses consumption-based billing.</span></span> <span data-ttu-id="1e9bc-165">Par conséquent, les frais sont facturés uniquement pendant les exécutions de pipeline et la supervision.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-165">Therefore, cost is only incurred during pipeline executions and monitoring.</span></span> <span data-ttu-id="1e9bc-166">L’exécution d’un pipeline de base ne coûte pas plus de 50 cents et la supervision pas plus de 25 cents.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-166">The execution of a basic pipeline would cost as little as 50 cents and the monitoring as little as 25 cents.</span></span> <span data-ttu-id="1e9bc-167">Le [calculateur de coût Azure](https://azure.microsoft.com/pricing/calculator/) peut vous aider à élaborer une estimation plus précise en fonction de votre charge de travail spécifique.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-167">The [Azure cost calculator](https://azure.microsoft.com/pricing/calculator/) can be used to create a more accurate estimate based on your specific workload.</span></span>

<span data-ttu-id="1e9bc-168">Quand vous exécutez une charge de travail ETL hybride, vous devez tenir compte du coût de la machine virtuelle qui héberge vos packages SSIS.</span><span class="sxs-lookup"><span data-stu-id="1e9bc-168">When running a hybrid ETL workload, you must factor in the cost of the virtual machine used to host your SSIS packages.</span></span> <span data-ttu-id="1e9bc-169">Ce coût est basé sur la taille de la machine virtuelle : de D1v2 (1 cœur, 3,5 Go de RAM, disque de 50 Go) à E64V3 (64 cœurs, 432 Go de RAM, disque de 1 600 Go).</span><span class="sxs-lookup"><span data-stu-id="1e9bc-169">This cost is based on the size of the VM ranging from a D1v2 (1 core, 3.5 GB RAM, 50 GB Disk) to E64V3 (64 cores, 432 GB RAM, 1600 GB disk).</span></span>  <span data-ttu-id="1e9bc-170">Si vous avez besoin d’aide pour choisir la taille appropriée de la machine virtuelle, consultez [Considérations sur les performances de machine virtuelle](/azure/cloud-services/cloud-services-sizes-specs#performance-considerations).</span><span class="sxs-lookup"><span data-stu-id="1e9bc-170">If you need further guidance on selection the appropriate VM size, see [VM performance considerations](/azure/cloud-services/cloud-services-sizes-specs#performance-considerations).</span></span>

## <a name="next-steps"></a><span data-ttu-id="1e9bc-171">Étapes suivantes</span><span class="sxs-lookup"><span data-stu-id="1e9bc-171">Next Steps</span></span>

* <span data-ttu-id="1e9bc-172">Découvrez plus d’informations sur [Azure Data Factory](https://azure.microsoft.com/services/data-factory/).</span><span class="sxs-lookup"><span data-stu-id="1e9bc-172">Learn more about [Azure Data Factory](https://azure.microsoft.com/services/data-factory/).</span></span>
* <span data-ttu-id="1e9bc-173">Démarrez avec Azure Data Factory en suivant le [Tutoriel pas à pas](/azure/data-factory/#step-by-step-tutorials).</span><span class="sxs-lookup"><span data-stu-id="1e9bc-173">Get started with Azure Data Factory by following the [Step-by-step tutorial](/azure/data-factory/#step-by-step-tutorials).</span></span>
* <span data-ttu-id="1e9bc-174">[Provisionnez Azure-SSIS Integration Runtime dans Azure Data Factory](/azure/data-factory/tutorial-deploy-ssis-packages-azure).</span><span class="sxs-lookup"><span data-stu-id="1e9bc-174">[Provision the Azure-SSIS Integration Runtime in Azure Data Factory](/azure/data-factory/tutorial-deploy-ssis-packages-azure).</span></span>

<!-- links -->
[architecture-diagram]: ./media/architecture-diagram-hybrid-etl-with-adf.png
[small-pricing]: https://azure.com/e/
[medium-pricing]: https://azure.com/e/
[large-pricing]: https://azure.com/e/
[availability]: /azure/architecture/checklist/availability
[resource-groups]: /azure/azure-resource-manager/resource-group-overview
[resiliency]: /azure/architecture/resiliency/
[security]: /azure/security/
[scalability]: /azure/architecture/checklist/scalability
[docs-blob-storage]: /azure/storage/blobs/
[docs-data-factory]: /azure/data-factory/introduction
[docs-resource-groups]: /azure/azure-resource-manager/resource-group-overview
[docs-ssis]: /sql/integration-services/sql-server-integration-services
[docs-sql-data-warehouse]: /azure/sql-data-warehouse/sql-data-warehouse-overview-what-is