---
title: Enterprise BI avec SQL Data Warehouse
description: Utiliser Azure pour obtenir des analyses détaillées des données relationnelles stockées en local
author: MikeWasson
ms.date: 11/06/2018
ms.openlocfilehash: 2822cf6d2a75d521f182c267f4bf2bac462d2b7f
ms.sourcegitcommit: 877777094b554559dc9cb1f0d9214d6d38197439
ms.translationtype: HT
ms.contentlocale: fr-FR
ms.lasthandoff: 11/11/2018
ms.locfileid: "51527709"
---
# <a name="enterprise-bi-in-azure-with-sql-data-warehouse"></a><span data-ttu-id="166a7-103">Enterprise BI dans Azure avec SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="166a7-103">Enterprise BI in Azure with SQL Data Warehouse</span></span>

<span data-ttu-id="166a7-104">Cette architecture de référence implémente un pipeline [ELT](../../data-guide/relational-data/etl.md#extract-load-and-transform-elt) (extract-load-transform) qui déplace des données d’une base de données SQL Server vers SQL Data Warehouse et qui transforme les données pour les analyser.</span><span class="sxs-lookup"><span data-stu-id="166a7-104">This reference architecture implements an [ELT](../../data-guide/relational-data/etl.md#extract-load-and-transform-elt) (extract-load-transform) pipeline that moves data from an on-premises SQL Server database into SQL Data Warehouse and transforms the data for analysis.</span></span> 

<span data-ttu-id="166a7-105">Une implémentation de référence pour cette architecture est disponible sur [GitHub][github-folder]</span><span class="sxs-lookup"><span data-stu-id="166a7-105">A reference implementation for this architecture is available on [GitHub][github-folder]</span></span>

![](./images/enterprise-bi-sqldw.png)

<span data-ttu-id="166a7-106">**Scénario**: Une organisation dispose d’un jeu de données OLTP important stocké dans une base de données SQL Server locale.</span><span class="sxs-lookup"><span data-stu-id="166a7-106">**Scenario**: An organization has a large OLTP data set stored in a SQL Server database on premises.</span></span> <span data-ttu-id="166a7-107">L’organisation souhaite utiliser SQL Data Warehouse pour réaliser une analyse avec Power BI.</span><span class="sxs-lookup"><span data-stu-id="166a7-107">The organization wants to use SQL Data Warehouse to perform analysis using Power BI.</span></span> 

<span data-ttu-id="166a7-108">Cette architecture de référence est conçue pour des tâches uniques ou à la demande.</span><span class="sxs-lookup"><span data-stu-id="166a7-108">This reference architecture is designed for one-time or on-demand jobs.</span></span> <span data-ttu-id="166a7-109">Si vous devez déplacer des données continuellement (toutes les heures ou tous les jours), nous vous recommandons d’utiliser Azure Data Factory pour définir un flux de travail automatisé.</span><span class="sxs-lookup"><span data-stu-id="166a7-109">If you need to move data on a continuing basis (hourly or daily), we recommend using Azure Data Factory to define an automated workflow.</span></span> <span data-ttu-id="166a7-110">Pour accéder à une architecture de référence qui utilise Data Factory, consultez [BI d’entreprise automatisée avec SQL Data Warehouse et Azure Data Factory][adf-ra].</span><span class="sxs-lookup"><span data-stu-id="166a7-110">For a reference architecture that uses Data Factory, see [Automated enterprise BI with SQL Data Warehouse and Azure Data Factory][adf-ra].</span></span>

## <a name="architecture"></a><span data-ttu-id="166a7-111">Architecture</span><span class="sxs-lookup"><span data-stu-id="166a7-111">Architecture</span></span>

<span data-ttu-id="166a7-112">L’architecture est constituée des composants suivants.</span><span class="sxs-lookup"><span data-stu-id="166a7-112">The architecture consists of the following components.</span></span>

### <a name="data-source"></a><span data-ttu-id="166a7-113">Source de données</span><span class="sxs-lookup"><span data-stu-id="166a7-113">Data source</span></span>

<span data-ttu-id="166a7-114">**SQL Server**.</span><span class="sxs-lookup"><span data-stu-id="166a7-114">**SQL Server**.</span></span> <span data-ttu-id="166a7-115">Les données sources sont situées dans une base de données SQL Server locale.</span><span class="sxs-lookup"><span data-stu-id="166a7-115">The source data is located in a SQL Server database on premises.</span></span> <span data-ttu-id="166a7-116">Pour simuler l’environnement local, les scripts de déploiement de cette architecture approvisionnent une machine virtuelle dans Azure disposant de SQL Server.</span><span class="sxs-lookup"><span data-stu-id="166a7-116">To simulate the on-premises environment, the deployment scripts for this architecture provision a VM in Azure with SQL Server installed.</span></span> <span data-ttu-id="166a7-117">[L’exemple de base de données OLTP Wide World Importers][wwi] est utilisé comme base de données source.</span><span class="sxs-lookup"><span data-stu-id="166a7-117">The [Wide World Importers OLTP sample database][wwi] is used as the source data.</span></span>

### <a name="ingestion-and-data-storage"></a><span data-ttu-id="166a7-118">Ingestion et stockage de données</span><span class="sxs-lookup"><span data-stu-id="166a7-118">Ingestion and data storage</span></span>

<span data-ttu-id="166a7-119">**Stockage d'objets blob**.</span><span class="sxs-lookup"><span data-stu-id="166a7-119">**Blob Storage**.</span></span> <span data-ttu-id="166a7-120">Le stockage d’objets blob est utilisé comme zone de préparation à la copie des données, avant de les charger dans SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="166a7-120">Blob storage is used as a staging area to copy the data before loading it into SQL Data Warehouse.</span></span>

<span data-ttu-id="166a7-121">**Azure SQL Data Warehouse**.</span><span class="sxs-lookup"><span data-stu-id="166a7-121">**Azure SQL Data Warehouse**.</span></span> <span data-ttu-id="166a7-122">[SQL Data Warehouse](/azure/sql-data-warehouse/) est un système distribué conçu pour réaliser des analyses sur de grandes quantités de données.</span><span class="sxs-lookup"><span data-stu-id="166a7-122">[SQL Data Warehouse](/azure/sql-data-warehouse/) is a distributed system designed to perform analytics on large data.</span></span> <span data-ttu-id="166a7-123">Il prend en charge le traitement MPP (Massive Parallel Processing), le rendant ainsi adapté à l’exécution d’analyses hautes performances.</span><span class="sxs-lookup"><span data-stu-id="166a7-123">It supports massive parallel processing (MPP), which makes it suitable for running high-performance analytics.</span></span> 

### <a name="analysis-and-reporting"></a><span data-ttu-id="166a7-124">Analyse et rapports</span><span class="sxs-lookup"><span data-stu-id="166a7-124">Analysis and reporting</span></span>

<span data-ttu-id="166a7-125">**Azure Analysis Services**.</span><span class="sxs-lookup"><span data-stu-id="166a7-125">**Azure Analysis Services**.</span></span> <span data-ttu-id="166a7-126">[Analysis Services](/azure/analysis-services/) est un service entièrement géré qui fournit des capacités de modélisation des données.</span><span class="sxs-lookup"><span data-stu-id="166a7-126">[Analysis Services](/azure/analysis-services/) is a fully managed service that provides data modeling capabilities.</span></span> <span data-ttu-id="166a7-127">Utilisez Analysis Services pour créer un modèle sémantique que les utilisateurs peuvent demander.</span><span class="sxs-lookup"><span data-stu-id="166a7-127">Use Analysis Services to create a semantic model that users can query.</span></span> <span data-ttu-id="166a7-128">Analysis Services est particulièrement utile dans un scénario de tableau de bord BI.</span><span class="sxs-lookup"><span data-stu-id="166a7-128">Analysis Services is especially useful in a BI dashboard scenario.</span></span> <span data-ttu-id="166a7-129">Dans cette architecture, Analysis Services lit les données de l’entrepôt de données pour traiter le modèle sémantique, et délivrer efficacement les requêtes du tableau de bord.</span><span class="sxs-lookup"><span data-stu-id="166a7-129">In this architecture, Analysis Services reads data from the data warehouse to process the semantic model, and efficiently serves dashboard queries.</span></span> <span data-ttu-id="166a7-130">Il prend aussi en charge la concurrence élastique, en adaptant les réplicas en vue d’un traitement des requêtes plus rapide.</span><span class="sxs-lookup"><span data-stu-id="166a7-130">It also supports elastic concurrency, by scaling out replicas for faster query processing.</span></span>

<span data-ttu-id="166a7-131">À l’heure actuelle, Azure Analysis Services prend en charge les modèles tabulaires, mais pas les modèles multidimensionnels.</span><span class="sxs-lookup"><span data-stu-id="166a7-131">Currently, Azure Analysis Services supports tabular models but not multidimensional models.</span></span> <span data-ttu-id="166a7-132">Les modèles tabulaires utilisent des constructions de modélisation relationnelle (tables et colonnes), tandis que les modèles multidimensionnels utilisent des constructions de modélisation de traitement analytique en ligne (cubes, dimensions, et mesures).</span><span class="sxs-lookup"><span data-stu-id="166a7-132">Tabular models use relational modeling constructs (tables and columns), whereas multidimensional models use OLAP modeling constructs (cubes, dimensions, and measures).</span></span> <span data-ttu-id="166a7-133">Si vous avez besoin de modèles multidimensionnels, utilisez SQL Server Analysis Services (SSAS).</span><span class="sxs-lookup"><span data-stu-id="166a7-133">If you require multidimensional models, use SQL Server Analysis Services (SSAS).</span></span> <span data-ttu-id="166a7-134">Pour en savoir plus, consultez [Comparaison des solutions tabulaires et multidimensionnelles](/sql/analysis-services/comparing-tabular-and-multidimensional-solutions-ssas).</span><span class="sxs-lookup"><span data-stu-id="166a7-134">For more information, see [Comparing tabular and multidimensional solutions](/sql/analysis-services/comparing-tabular-and-multidimensional-solutions-ssas).</span></span>

<span data-ttu-id="166a7-135">**Power BI**.</span><span class="sxs-lookup"><span data-stu-id="166a7-135">**Power BI**.</span></span> <span data-ttu-id="166a7-136">Power BI est une suite d’outils d’analyse métier pour analyser les données et obtenir des informations métier.</span><span class="sxs-lookup"><span data-stu-id="166a7-136">Power BI is a suite of business analytics tools to analyze data for business insights.</span></span> <span data-ttu-id="166a7-137">Dans cette architecture, il demande le modèle sémantique stocké dans Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="166a7-137">In this architecture, it queries the semantic model stored in Analysis Services.</span></span>

### <a name="authentication"></a><span data-ttu-id="166a7-138">Authentification</span><span class="sxs-lookup"><span data-stu-id="166a7-138">Authentication</span></span>

<span data-ttu-id="166a7-139">**Azure Active Directory** (Azure AD) authentifie les utilisateurs qui se connectent au serveur Analysis Services via Power BI.</span><span class="sxs-lookup"><span data-stu-id="166a7-139">**Azure Active Directory** (Azure AD) authenticates users who connect to the Analysis Services server through Power BI.</span></span>

## <a name="data-pipeline"></a><span data-ttu-id="166a7-140">Pipeline de données</span><span class="sxs-lookup"><span data-stu-id="166a7-140">Data pipeline</span></span>
 
<span data-ttu-id="166a7-141">Cette architecture de référence utilise l’exemple de base de données [WorldWideImporters](/sql/sample/world-wide-importers/wide-world-importers-oltp-database) en tant que source de données.</span><span class="sxs-lookup"><span data-stu-id="166a7-141">This reference architecture uses the [WorldWideImporters](/sql/sample/world-wide-importers/wide-world-importers-oltp-database) sample database as a data source.</span></span> <span data-ttu-id="166a7-142">Le pipeline de données comporte les étapes suivantes :</span><span class="sxs-lookup"><span data-stu-id="166a7-142">The data pipeline has the following stages:</span></span>

1. <span data-ttu-id="166a7-143">Exportez les données de SQL Server vers des fichiers plats (utilitaire BCP).</span><span class="sxs-lookup"><span data-stu-id="166a7-143">Export the data from SQL Server to flat files (bcp utility).</span></span>
2. <span data-ttu-id="166a7-144">Copiez les fichiers plats dans le Stockage Blob Azure (AzCopy).</span><span class="sxs-lookup"><span data-stu-id="166a7-144">Copy the flat files to Azure Blob Storage (AzCopy).</span></span>
3. <span data-ttu-id="166a7-145">Chargez les données dans SQL Data Warehouse à (PolyBase).</span><span class="sxs-lookup"><span data-stu-id="166a7-145">Load the data into SQL Data Warehouse (PolyBase).</span></span>
4. <span data-ttu-id="166a7-146">Transformez les données en schéma en étoile (T-SQL).</span><span class="sxs-lookup"><span data-stu-id="166a7-146">Transform the data into a star schema (T-SQL).</span></span>
5. <span data-ttu-id="166a7-147">Chargez un modèle sémantique dans Analysis Services (SQL Server Data Tools).</span><span class="sxs-lookup"><span data-stu-id="166a7-147">Load a semantic model into Analysis Services (SQL Server Data Tools).</span></span>

![](./images/enterprise-bi-sqldw-pipeline.png)
 
> [!NOTE]
> <span data-ttu-id="166a7-148">Pour les étapes 1 &ndash; 3, préférez l’utilisation de Redgate Data Platform Studio.</span><span class="sxs-lookup"><span data-stu-id="166a7-148">For steps 1 &ndash; 3, consider using Redgate Data Platform Studio.</span></span> <span data-ttu-id="166a7-149">Data Platform Studio applique les correctifs de compatibilité et optimisations les plus appropriés. Il s’agit donc du moyen le plus rapide pour vous familiariser avec SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="166a7-149">Data Platform Studio applies the most appropriate compatibility fixes and optimizations, so it's the quickest way to get started with SQL Data Warehouse.</span></span> <span data-ttu-id="166a7-150">Pour en savoir plus, consultez [Chargement de données avec Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate).</span><span class="sxs-lookup"><span data-stu-id="166a7-150">For more information, see [Load data with Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate).</span></span> 

<span data-ttu-id="166a7-151">Les sections suivantes décrivent ces étapes plus en détail.</span><span class="sxs-lookup"><span data-stu-id="166a7-151">The next sections describe these stages in more detail.</span></span>

### <a name="export-data-from-sql-server"></a><span data-ttu-id="166a7-152">Exporter des données depuis SQL Server</span><span class="sxs-lookup"><span data-stu-id="166a7-152">Export data from SQL Server</span></span>

<span data-ttu-id="166a7-153">L’utilitaire [BCP](/sql/tools/bcp-utility) (programme de copie en bloc) constitue un moyen rapide de créer des fichiers texte plats à partir des tables SQL.</span><span class="sxs-lookup"><span data-stu-id="166a7-153">The [bcp](/sql/tools/bcp-utility) (bulk copy program) utility is a fast way to create flat text files from SQL tables.</span></span> <span data-ttu-id="166a7-154">Dans cette étape, vous sélectionnez les colonnes que vous souhaitez exporter, mais vous ne transformez pas les données.</span><span class="sxs-lookup"><span data-stu-id="166a7-154">In this step, you select the columns that you want to export, but don't transform the data.</span></span> <span data-ttu-id="166a7-155">Les transformations de données doivent se faire dans SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="166a7-155">Any data transformations should happen in SQL Data Warehouse.</span></span>

<span data-ttu-id="166a7-156">**Recommandations**</span><span class="sxs-lookup"><span data-stu-id="166a7-156">**Recommendations**</span></span>

<span data-ttu-id="166a7-157">Si possible, prévoyez l’extraction des données lors des heures creuses afin de minimiser la contention des ressources dans l’environnement de production.</span><span class="sxs-lookup"><span data-stu-id="166a7-157">If possible, schedule data extraction during off-peak hours, to minimize resource contention in the production environment.</span></span> 

<span data-ttu-id="166a7-158">N’exécutez pas l’utilitaire BCP sur le serveur de base de données.</span><span class="sxs-lookup"><span data-stu-id="166a7-158">Avoid running bcp on the database server.</span></span> <span data-ttu-id="166a7-159">À la place, exécutez-le depuis une autre machine.</span><span class="sxs-lookup"><span data-stu-id="166a7-159">Instead, run it from another machine.</span></span> <span data-ttu-id="166a7-160">Écrivez les fichiers sur un disque local.</span><span class="sxs-lookup"><span data-stu-id="166a7-160">Write the files to a local drive.</span></span> <span data-ttu-id="166a7-161">Veillez à disposer de suffisamment de ressources d’E/S pour gérer les écritures simultanées.</span><span class="sxs-lookup"><span data-stu-id="166a7-161">Ensure that you have sufficient I/O resources to handle the concurrent writes.</span></span> <span data-ttu-id="166a7-162">Pour de meilleures performances, exportez les fichiers vers des disques de stockage rapides dédiés.</span><span class="sxs-lookup"><span data-stu-id="166a7-162">For best performance, export the files to dedicated fast storage drives.</span></span>

<span data-ttu-id="166a7-163">Vous pouvez accélérer le transfert réseau en enregistrant les données exportées dans un format compressé Gzip.</span><span class="sxs-lookup"><span data-stu-id="166a7-163">You can speed up the network transfer by saving the exported data in Gzip compressed format.</span></span> <span data-ttu-id="166a7-164">Toutefois, le chargement de fichiers compressés dans l’entrepôt est plus long qu’un chargement de fichiers décompressés. Il faut donc choisir entre un transfert réseau rapide et un chargement rapide.</span><span class="sxs-lookup"><span data-stu-id="166a7-164">However, loading compressed files into the warehouse is slower than loading uncompressed files, so there is a tradeoff between faster network transfer versus faster loading.</span></span> <span data-ttu-id="166a7-165">Si vous choisissez d’utiliser la compression Gzip, ne créez pas qu’un seul fichier Gzip.</span><span class="sxs-lookup"><span data-stu-id="166a7-165">If you decide to use Gzip compression, don't create a single Gzip file.</span></span> <span data-ttu-id="166a7-166">À la place, divisez les données en plusieurs fichiers compressés.</span><span class="sxs-lookup"><span data-stu-id="166a7-166">Instead, split the data into multiple compressed files.</span></span>

### <a name="copy-flat-files-into-blob-storage"></a><span data-ttu-id="166a7-167">Copier des fichiers plats dans le stockage d’objets blob</span><span class="sxs-lookup"><span data-stu-id="166a7-167">Copy flat files into blob storage</span></span>

<span data-ttu-id="166a7-168">L’utilitaire [AzCopy](/azure/storage/common/storage-use-azcopy) est conçu pour la copie hautes performances des données dans le Stockage Blob Azure.</span><span class="sxs-lookup"><span data-stu-id="166a7-168">The [AzCopy](/azure/storage/common/storage-use-azcopy) utility is designed for high-performance copying of data into Azure blob storage.</span></span>

<span data-ttu-id="166a7-169">**Recommandations**</span><span class="sxs-lookup"><span data-stu-id="166a7-169">**Recommendations**</span></span>

<span data-ttu-id="166a7-170">Créez un compte de stockage dans une région proche de l’emplacement des données source.</span><span class="sxs-lookup"><span data-stu-id="166a7-170">Create the storage account in a region near the location of the source data.</span></span> <span data-ttu-id="166a7-171">Déployez le compte de stockage et l’instance SQL Data Warehouse dans la même région.</span><span class="sxs-lookup"><span data-stu-id="166a7-171">Deploy the storage account and the SQL Data Warehouse instance in the same region.</span></span> 

<span data-ttu-id="166a7-172">N’exécutez pas AzCopy sur la machine qui exécute vos charges de travail de production, car l’unité centrale et la consommation d’E/S peuvent interférer avec elles.</span><span class="sxs-lookup"><span data-stu-id="166a7-172">Don't run AzCopy on the same machine that runs your production workloads, because the CPU and I/O consumption can interfere with the production workload.</span></span> 

<span data-ttu-id="166a7-173">Testez le chargement afin de déterminer la vitesse.</span><span class="sxs-lookup"><span data-stu-id="166a7-173">Test the upload first to see what the upload speed is like.</span></span> <span data-ttu-id="166a7-174">Vous pouvez utiliser l’option /NC dans AzCopy pour spécifier le nombre d’opérations de copie simultanées.</span><span class="sxs-lookup"><span data-stu-id="166a7-174">You can use the /NC option in AzCopy to specify the number of concurrent copy operations.</span></span> <span data-ttu-id="166a7-175">Commencez par la valeur par défaut, puis expérimentez avec ce paramètre pour ajuster les performances.</span><span class="sxs-lookup"><span data-stu-id="166a7-175">Start with the default value, then experiment with this setting to tune the performance.</span></span> <span data-ttu-id="166a7-176">Remarque : un trop grand nombre d’opérations simultanées dans un environnement à faible bande passante peut surcharger la connexion réseau et entraver la réussite des opérations.</span><span class="sxs-lookup"><span data-stu-id="166a7-176">In a low-bandwidth environment, too many concurrent operations can overwhelm the network connection and prevent the operations from completing successfully.</span></span>  

<span data-ttu-id="166a7-177">AzCopy déplace les données vers le stockage via l’Internet public.</span><span class="sxs-lookup"><span data-stu-id="166a7-177">AzCopy moves data to storage over the public internet.</span></span> <span data-ttu-id="166a7-178">Si ce n’est pas assez rapide, envisagez la configuration d’un circuit [ExpressRoute](/azure/expressroute/).</span><span class="sxs-lookup"><span data-stu-id="166a7-178">If this isn't fast enough, consider setting up an [ExpressRoute](/azure/expressroute/) circuit.</span></span> <span data-ttu-id="166a7-179">ExpressRoute est un service qui achemine vos données via une connexion privée dédiée vers Azure.</span><span class="sxs-lookup"><span data-stu-id="166a7-179">ExpressRoute is a service that routes your data through a dedicated private connection to Azure.</span></span> <span data-ttu-id="166a7-180">Si votre connexion réseau est trop lente, une autre option consiste à envoyer les données physiquement sur disque vers un centre de données Azure.</span><span class="sxs-lookup"><span data-stu-id="166a7-180">Another option, if your network connection is too slow, is to physically ship the data on disk to an Azure datacenter.</span></span> <span data-ttu-id="166a7-181">Pour plus d’informations, consultez l’article [Transférer des données vers et à partir d’Azure](/azure/architecture/data-guide/scenarios/data-transfer).</span><span class="sxs-lookup"><span data-stu-id="166a7-181">For more information, see [Transferring data to and from Azure](/azure/architecture/data-guide/scenarios/data-transfer).</span></span>

<span data-ttu-id="166a7-182">Lors d’une opération de copie, AzCopy crée un fichier journal temporaire, qui permet à AzCopy de redémarrer l’opération si elle est interrompue (à cause d’une erreur réseau, par exemple).</span><span class="sxs-lookup"><span data-stu-id="166a7-182">During a copy operation, AzCopy creates a temporary journal file, which enables AzCopy to restart the operation if it gets interrupted (for example, due to a network error).</span></span> <span data-ttu-id="166a7-183">Veillez à disposer de suffisamment d’espace disque pour stocker les fichiers journaux.</span><span class="sxs-lookup"><span data-stu-id="166a7-183">Make sure there is enough disk space to store the journal files.</span></span> <span data-ttu-id="166a7-184">Vous pouvez utiliser l’option /Z pour spécifier où sont écrits les fichiers journaux.</span><span class="sxs-lookup"><span data-stu-id="166a7-184">You can use the /Z option to specify where the journal files are written.</span></span>

### <a name="load-data-into-sql-data-warehouse"></a><span data-ttu-id="166a7-185">Chargement de données dans SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="166a7-185">Load data into SQL Data Warehouse</span></span>

<span data-ttu-id="166a7-186">Utilisez [PolyBase](/sql/relational-databases/polybase/polybase-guide) pour charger des fichiers du stockage d’objets blob vers l’entrepôt de données.</span><span class="sxs-lookup"><span data-stu-id="166a7-186">Use [PolyBase](/sql/relational-databases/polybase/polybase-guide) to load the files from blob storage into the data warehouse.</span></span> <span data-ttu-id="166a7-187">PolyBase est conçu pour tirer parti de l’architecture MPP (Massively Parallel Processing) de SQL Data Warehouse, ce qui en fait le moyen le plus rapide pour y charger des données.</span><span class="sxs-lookup"><span data-stu-id="166a7-187">PolyBase is designed to leverage the MPP (Massively Parallel Processing) architecture of SQL Data Warehouse, which makes it the fastest way to load data into SQL Data Warehouse.</span></span> 

<span data-ttu-id="166a7-188">Le chargement des données est un processus en deux étapes :</span><span class="sxs-lookup"><span data-stu-id="166a7-188">Loading the data is a two-step process:</span></span>

1. <span data-ttu-id="166a7-189">Créez un ensemble de tables externes pour les données.</span><span class="sxs-lookup"><span data-stu-id="166a7-189">Create a set of external tables for the data.</span></span> <span data-ttu-id="166a7-190">Une table externe est une définition de table qui pointe vers des données stockées à l’extérieur de l’entrepôt &mdash;. Dans notre cas, il s’agit des fichiers plats dans le stockage d’objets blob.</span><span class="sxs-lookup"><span data-stu-id="166a7-190">An external table is a table definition that points to data stored outside of the warehouse &mdash; in this case, the flat files in blob storage.</span></span> <span data-ttu-id="166a7-191">Cette étape ne déplace aucune donnée dans l’entrepôt.</span><span class="sxs-lookup"><span data-stu-id="166a7-191">This step does not move any data into the warehouse.</span></span>
2. <span data-ttu-id="166a7-192">Créez des tables de mise en lots, et chargez-y les données.</span><span class="sxs-lookup"><span data-stu-id="166a7-192">Create staging tables, and load the data into the staging tables.</span></span> <span data-ttu-id="166a7-193">Cette étape copie les données dans l’entrepôt.</span><span class="sxs-lookup"><span data-stu-id="166a7-193">This step copies the data into the warehouse.</span></span>

<span data-ttu-id="166a7-194">**Recommandations**</span><span class="sxs-lookup"><span data-stu-id="166a7-194">**Recommendations**</span></span>

<span data-ttu-id="166a7-195">Préférez utiliser SQL Data Warehouse lorsque vous disposez d’une importante quantité de données (supérieure à 1 To) et que vous exécutez une charge de travail d’analyse qui profiterait de ce parallélisme.</span><span class="sxs-lookup"><span data-stu-id="166a7-195">Consider SQL Data Warehouse when you have large amounts of data (more than 1 TB) and are running an analytics workload that will benefit from parallelism.</span></span> <span data-ttu-id="166a7-196">SQL Data Warehouse ne convient pas à des charges de travail OLTP ni à des jeux de données moins importants (inférieurs à 250 Go).</span><span class="sxs-lookup"><span data-stu-id="166a7-196">SQL Data Warehouse is not a good fit for OLTP workloads or smaller data sets (< 250GB).</span></span> <span data-ttu-id="166a7-197">Pour les jeux de données inférieurs à 250 Go, préférez utiliser Azure SQL Database ou SQL Server.</span><span class="sxs-lookup"><span data-stu-id="166a7-197">For data sets less than 250GB, consider Azure SQL Database or SQL Server.</span></span> <span data-ttu-id="166a7-198">Pour plus d’informations, consultez la page [Entreposage des données](../../data-guide/relational-data/data-warehousing.md).</span><span class="sxs-lookup"><span data-stu-id="166a7-198">For more information, see [Data warehousing](../../data-guide/relational-data/data-warehousing.md).</span></span>

<span data-ttu-id="166a7-199">Créez les tables de mise en lots comme tables de segments de mémoire, qui ne sont pas indexées.</span><span class="sxs-lookup"><span data-stu-id="166a7-199">Create the staging tables as heap tables, which are not indexed.</span></span> <span data-ttu-id="166a7-200">Les requêtes qui créent les tables de production créeront une analyse de table complète. Il n’y a donc aucune raison d’indexer les tables de mise en lots.</span><span class="sxs-lookup"><span data-stu-id="166a7-200">The queries that create the production tables will result in a full table scan, so there is no reason to index the staging tables.</span></span>

<span data-ttu-id="166a7-201">PolyBase tire automatiquement parti du parallélisme dans l’entrepôt.</span><span class="sxs-lookup"><span data-stu-id="166a7-201">PolyBase automatically takes advantage of parallelism in the warehouse.</span></span> <span data-ttu-id="166a7-202">Les performances de chargement s’adaptent à mesure que vous augmentez les DWU (Data Warehouse Units).</span><span class="sxs-lookup"><span data-stu-id="166a7-202">The load performance scales as you increase DWUs.</span></span> <span data-ttu-id="166a7-203">Pour de meilleures performances, utilisez une seule opération de chargement.</span><span class="sxs-lookup"><span data-stu-id="166a7-203">For best performance, use a single load operation.</span></span> <span data-ttu-id="166a7-204">Il n’y a pas d’améliorations de performances pour diviser les données entrantes et exécuter plusieurs chargements simultanés.</span><span class="sxs-lookup"><span data-stu-id="166a7-204">There is no performance benefit to breaking the input data into chunks and running multiple concurrent loads.</span></span>

<span data-ttu-id="166a7-205">PolyBase peut lire les fichiers compressés au format Gzip.</span><span class="sxs-lookup"><span data-stu-id="166a7-205">PolyBase can read Gzip compressed files.</span></span> <span data-ttu-id="166a7-206">Toutefois, seul un lecteur unique est utilisé par fichier compressé, car la décompression du fichier est une opération à un seul thread.</span><span class="sxs-lookup"><span data-stu-id="166a7-206">However, only a single reader is used per compressed file, because uncompressing the file is a single-threaded operation.</span></span> <span data-ttu-id="166a7-207">Évitez donc de charger un seul gros fichier compressé.</span><span class="sxs-lookup"><span data-stu-id="166a7-207">Therefore, avoid loading a single large compressed file.</span></span> <span data-ttu-id="166a7-208">À la place, divisez les données en plusieurs fichiers compressés, afin de tirer parti du parallélisme.</span><span class="sxs-lookup"><span data-stu-id="166a7-208">Instead, split the data into multiple compressed files, in order to take advantage of parallelism.</span></span> 

<span data-ttu-id="166a7-209">Notez les limitations suivantes :</span><span class="sxs-lookup"><span data-stu-id="166a7-209">Be aware of the following limitations:</span></span>

- <span data-ttu-id="166a7-210">PolyBase prend en charge une taille de colonne maximale de `varchar(8000)`, `nvarchar(4000)` ou `varbinary(8000)`.</span><span class="sxs-lookup"><span data-stu-id="166a7-210">PolyBase supports a maximum column size of `varchar(8000)`, `nvarchar(4000)`, or `varbinary(8000)`.</span></span> <span data-ttu-id="166a7-211">Si vos données dépassent ces limites, une option consiste à les diviser au moment de les exporter, puis de les réassembler après les avoir importées.</span><span class="sxs-lookup"><span data-stu-id="166a7-211">If you have data that exceeds these limits, one option is to break the data up into chunks when you export it, and then reassemble the chunks after import.</span></span> 

- <span data-ttu-id="166a7-212">PolyBase utilise un terminateur de ligne fixe \n ou un renvoi à la ligne.</span><span class="sxs-lookup"><span data-stu-id="166a7-212">PolyBase uses a fixed row terminator of \n or newline.</span></span> <span data-ttu-id="166a7-213">Cela peut entraîner des problèmes si les caractères de renvoi à la ligne apparaissent dans les données source.</span><span class="sxs-lookup"><span data-stu-id="166a7-213">This can cause problems if newline characters appear in the source data.</span></span>

- <span data-ttu-id="166a7-214">Votre schéma des données source peut contenir des types de données qui ne sont pas pris en charge dans SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="166a7-214">Your source data schema might contain data types that are not supported in SQL Data Warehouse.</span></span>

<span data-ttu-id="166a7-215">Pour contourner ces limitations, vous pouvez créer une procédure stockée qui réalise les conversions nécessaires.</span><span class="sxs-lookup"><span data-stu-id="166a7-215">To work around these limitations, you can create a stored procedure that performs the necessary conversions.</span></span> <span data-ttu-id="166a7-216">Référencez cette procédure stockée lorsque vous exécutez l’utilitaire BCP.</span><span class="sxs-lookup"><span data-stu-id="166a7-216">Reference this stored procedure when you run bcp.</span></span> <span data-ttu-id="166a7-217">Autrement, [Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate) convertit automatiquement les types de données qui ne sont pas pris en charge dans SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="166a7-217">Alternatively, [Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate) automatically converts data types that aren’t supported in SQL Data Warehouse.</span></span>

<span data-ttu-id="166a7-218">Pour plus d’informations, consultez les articles suivants :</span><span class="sxs-lookup"><span data-stu-id="166a7-218">For more information, see the following articles:</span></span>

- <span data-ttu-id="166a7-219">[Meilleures pratiques de chargement de données dans Azure SQL Data Warehouse](/azure/sql-data-warehouse/guidance-for-loading-data).</span><span class="sxs-lookup"><span data-stu-id="166a7-219">[Best practices for loading data into Azure SQL Data Warehouse](/azure/sql-data-warehouse/guidance-for-loading-data).</span></span>
- [<span data-ttu-id="166a7-220">Migration de votre schéma vers SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="166a7-220">Migrate your schemas to SQL Data Warehouse</span></span>](/azure/sql-data-warehouse/sql-data-warehouse-migrate-schema)
- [<span data-ttu-id="166a7-221">Conseils relatifs à la définition des types de données pour tables dans SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="166a7-221">Guidance for defining data types for tables in SQL Data Warehouse</span></span>](/azure/sql-data-warehouse/sql-data-warehouse-tables-data-types)

### <a name="transform-the-data"></a><span data-ttu-id="166a7-222">Transformer les données</span><span class="sxs-lookup"><span data-stu-id="166a7-222">Transform the data</span></span>

<span data-ttu-id="166a7-223">Transformez les données et les déplacer dans des tables de production.</span><span class="sxs-lookup"><span data-stu-id="166a7-223">Transform the data and move it into production tables.</span></span> <span data-ttu-id="166a7-224">Dans cette étape, les données sont transformées en schéma en étoile avec des tables de dimension et de faits, adaptées à la modélisation sémantique.</span><span class="sxs-lookup"><span data-stu-id="166a7-224">In this step, the data is transformed into a star schema with dimension tables and fact tables, suitable for semantic modeling.</span></span>

<span data-ttu-id="166a7-225">Créez les tables de production avec des index columstore en cluster, ce qui offre les meilleures performances globales de requête.</span><span class="sxs-lookup"><span data-stu-id="166a7-225">Create the production tables with clustered columnstore indexes, which offer the best overall query performance.</span></span> <span data-ttu-id="166a7-226">Les index columnstore sont optimisés pour les requêtes qui analysent de nombreux enregistrements.</span><span class="sxs-lookup"><span data-stu-id="166a7-226">Columnstore indexes are optimized for queries that scan many records.</span></span> <span data-ttu-id="166a7-227">Les index columnstore ne sont pas aussi efficaces pour les recherches singleton (rechercher une seule ligne).</span><span class="sxs-lookup"><span data-stu-id="166a7-227">Columnstore indexes don't perform as well for singleton lookups (that is, looking up a single row).</span></span> <span data-ttu-id="166a7-228">Si vous avez besoin d’effectuer fréquemment des recherches singleton, vous pouvez ajouter un index non cluster à une table.</span><span class="sxs-lookup"><span data-stu-id="166a7-228">If you need to perform frequent singleton lookups, you can add a non-clustered index to a table.</span></span> <span data-ttu-id="166a7-229">Les recherches singleton peuvent s’exécuter bien plus rapidement avec un index non cluster.</span><span class="sxs-lookup"><span data-stu-id="166a7-229">Singleton lookups can run significantly faster using a non-clustered index.</span></span> <span data-ttu-id="166a7-230">Toutefois, elles sont généralement moins fréquentes dans des scénarios d’entrepôt de données que des charges de travail OLTP.</span><span class="sxs-lookup"><span data-stu-id="166a7-230">However, singleton lookups are typically less common in data warehouse scenarios than OLTP workloads.</span></span> <span data-ttu-id="166a7-231">Pour plus d’informations, consultez [Indexage de tables dans SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-index).</span><span class="sxs-lookup"><span data-stu-id="166a7-231">For more information, see [Indexing tables in SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-index).</span></span>

> [!NOTE]
> <span data-ttu-id="166a7-232">Les tables columnstore cluster ne prennent pas en charge les types de données `varchar(max)`, `nvarchar(max)` ou `varbinary(max)`.</span><span class="sxs-lookup"><span data-stu-id="166a7-232">Clustered columnstore tables do not support `varchar(max)`, `nvarchar(max)`, or `varbinary(max)` data types.</span></span> <span data-ttu-id="166a7-233">Dans ces cas, préférez utiliser un segment de mémoire ou un index cluster.</span><span class="sxs-lookup"><span data-stu-id="166a7-233">In that case, consider a heap or clustered index.</span></span> <span data-ttu-id="166a7-234">Vous pouvez placer ces colonnes dans une table distincte.</span><span class="sxs-lookup"><span data-stu-id="166a7-234">You might put those columns into a separate table.</span></span>

<span data-ttu-id="166a7-235">Comme l’exemple de base de données n’est pas très important, nous avons créé des tables répliquées sans partition.</span><span class="sxs-lookup"><span data-stu-id="166a7-235">Because the sample database is not very large, we created replicated tables with no partitions.</span></span> <span data-ttu-id="166a7-236">Pour les charges de travail de production, l’utilisation de tables distribuées a des chances d’améliorer les performances de requête.</span><span class="sxs-lookup"><span data-stu-id="166a7-236">For production workloads, using distributed tables is likely to improve query performance.</span></span> <span data-ttu-id="166a7-237">Consultez le [Guide de conception des tables distribuées dans Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute).</span><span class="sxs-lookup"><span data-stu-id="166a7-237">See [Guidance for designing distributed tables in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute).</span></span> <span data-ttu-id="166a7-238">Nos exemples de scripts exécutent les requêtes avec une [classe de ressources](/azure/sql-data-warehouse/resource-classes-for-workload-management) statique.</span><span class="sxs-lookup"><span data-stu-id="166a7-238">Our example scripts run the queries using a static [resource class](/azure/sql-data-warehouse/resource-classes-for-workload-management).</span></span>

### <a name="load-the-semantic-model"></a><span data-ttu-id="166a7-239">Charger le modèle sémantique</span><span class="sxs-lookup"><span data-stu-id="166a7-239">Load the semantic model</span></span>

<span data-ttu-id="166a7-240">Chargez les données dans un modèle tabulaire dans Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="166a7-240">Load the data into a tabular model in Azure Analysis Services.</span></span> <span data-ttu-id="166a7-241">Dans cette étape, vous créez un modèle de données sémantique avec SQL Server Data Tools (SSDT).</span><span class="sxs-lookup"><span data-stu-id="166a7-241">In this step, you create a semantic data model by using SQL Server Data Tools (SSDT).</span></span> <span data-ttu-id="166a7-242">Vous pouvez aussi créer un modèle en l’important depuis un fichier Power BI Desktop.</span><span class="sxs-lookup"><span data-stu-id="166a7-242">You can also create a model by importing it from a Power BI Desktop file.</span></span> <span data-ttu-id="166a7-243">Comme SQL Data Warehouse ne prend pas en charge les clés étrangères, vous devez ajouter les relations au modèle sémantique afin de joindre les tables.</span><span class="sxs-lookup"><span data-stu-id="166a7-243">Because SQL Data Warehouse does not support foreign keys, you must add the relationships to the semantic model, so that you can join across tables.</span></span>

### <a name="use-power-bi-to-visualize-the-data"></a><span data-ttu-id="166a7-244">Utiliser Power BI pour visualiser les données</span><span class="sxs-lookup"><span data-stu-id="166a7-244">Use Power BI to visualize the data</span></span>

<span data-ttu-id="166a7-245">Power BI prend en charge deux options pour la connexion à Azure Analysis Services :</span><span class="sxs-lookup"><span data-stu-id="166a7-245">Power BI supports two options for connecting to Azure Analysis Services:</span></span>

- <span data-ttu-id="166a7-246">Importation.</span><span class="sxs-lookup"><span data-stu-id="166a7-246">Import.</span></span> <span data-ttu-id="166a7-247">Les données sont importées dans le modèle Power BI.</span><span class="sxs-lookup"><span data-stu-id="166a7-247">The data is imported into the Power BI model.</span></span>
- <span data-ttu-id="166a7-248">Connexion active.</span><span class="sxs-lookup"><span data-stu-id="166a7-248">Live Connection.</span></span> <span data-ttu-id="166a7-249">Les données sont extraites directement depuis Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="166a7-249">Data is pulled directly from Analysis Services.</span></span>

<span data-ttu-id="166a7-250">Nous vous recommandons l’option Connexion active car elle ne nécessite pas de copier des données dans le modèle Power BI.</span><span class="sxs-lookup"><span data-stu-id="166a7-250">We recommend Live Connection because it doesn't require copying data into the Power BI model.</span></span> <span data-ttu-id="166a7-251">De plus, DirectQuery veille à ce que les résultats soient toujours cohérents avec les données sources les plus récentes.</span><span class="sxs-lookup"><span data-stu-id="166a7-251">Also, using DirectQuery ensures that results are always consistent with the latest source data.</span></span> <span data-ttu-id="166a7-252">Pour plus d’informations, consultez [Connexion avec Power BI](/azure/analysis-services/analysis-services-connect-pbi).</span><span class="sxs-lookup"><span data-stu-id="166a7-252">For more information, see [Connect with Power BI](/azure/analysis-services/analysis-services-connect-pbi).</span></span>

<span data-ttu-id="166a7-253">**Recommandations**</span><span class="sxs-lookup"><span data-stu-id="166a7-253">**Recommendations**</span></span>

<span data-ttu-id="166a7-254">N’exécutez pas des requêtes de tableau de bord BI directement dans l’entrepôt de données.</span><span class="sxs-lookup"><span data-stu-id="166a7-254">Avoid running BI dashboard queries directly against the data warehouse.</span></span> <span data-ttu-id="166a7-255">Les tableaux de bord BI nécessitent des temps de réponse très lents. Les requêtes directes dans l’entrepôt de données peuvent ne pas être adaptées.</span><span class="sxs-lookup"><span data-stu-id="166a7-255">BI dashboards require very low response times, which direct queries against the warehouse may be unable to satisfy.</span></span> <span data-ttu-id="166a7-256">De plus, l’actualisation du tableau de bord comptera dans le nombre de requêtes simultanées, ce qui peut impacter les performances.</span><span class="sxs-lookup"><span data-stu-id="166a7-256">Also, refreshing the dashboard will count against the number of concurrent queries, which could impact performance.</span></span> 

<span data-ttu-id="166a7-257">Azure Analysis Services est conçu pour gérer les exigences de requête d’un tableau de bord BI. Il est donc recommandé d’effectuer des requêtes Analysis Services depuis Power BI.</span><span class="sxs-lookup"><span data-stu-id="166a7-257">Azure Analysis Services is designed to handle the query requirements of a BI dashboard, so the recommended practice is to query Analysis Services from Power BI.</span></span>

## <a name="scalability-considerations"></a><span data-ttu-id="166a7-258">Considérations relatives à l’extensibilité</span><span class="sxs-lookup"><span data-stu-id="166a7-258">Scalability considerations</span></span>

### <a name="sql-data-warehouse"></a><span data-ttu-id="166a7-259">SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="166a7-259">SQL Data Warehouse</span></span>

<span data-ttu-id="166a7-260">Avec SQL Data Warehouse, vous pouvez augmenter la taille de vos ressources de calcul à la demande.</span><span class="sxs-lookup"><span data-stu-id="166a7-260">With SQL Data Warehouse, you can scale out your compute resources on demand.</span></span> <span data-ttu-id="166a7-261">Le moteur de requête optimise les requêtes pour des traitements simultanés basés sur le nombre de nœuds de calcul, et déplace les données entre nœuds si nécessaire.</span><span class="sxs-lookup"><span data-stu-id="166a7-261">The query engine optimizes queries for parallel processing based on the number of compute nodes, and moves data between nodes as necessary.</span></span> <span data-ttu-id="166a7-262">Pour plus d’informations, consultez [Gérer le calcul dans Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-manage-compute-overview).</span><span class="sxs-lookup"><span data-stu-id="166a7-262">For more information, see [Manage compute in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-manage-compute-overview).</span></span>

### <a name="analysis-services"></a><span data-ttu-id="166a7-263">Analysis Services</span><span class="sxs-lookup"><span data-stu-id="166a7-263">Analysis Services</span></span>

<span data-ttu-id="166a7-264">Pour les charges de travail de production, nous recommandons le niveau Standard pour Azure Analysis Services, car il prend en charge le partitionnement et DirectQuery.</span><span class="sxs-lookup"><span data-stu-id="166a7-264">For production workloads, we recommend the Standard Tier for Azure Analysis Services, because it supports partitioning and DirectQuery.</span></span> <span data-ttu-id="166a7-265">Dans un niveau, la taille de l’instance détermine la mémoire et la puissance de traitement.</span><span class="sxs-lookup"><span data-stu-id="166a7-265">Within a tier, the instance size determines the memory and processing power.</span></span> <span data-ttu-id="166a7-266">La puissance de traitement se mesure en QPU (Unité de traitement des requêtes).</span><span class="sxs-lookup"><span data-stu-id="166a7-266">Processing power is measured in Query Processing Units (QPUs).</span></span> <span data-ttu-id="166a7-267">Surveillez votre utilisation QPU pour sélectionner la taille appropriée.</span><span class="sxs-lookup"><span data-stu-id="166a7-267">Monitor your QPU usage to select the appropriate size.</span></span> <span data-ttu-id="166a7-268">Pour plus d’informations, voir [Surveiller les mesures du serveur](/azure/analysis-services/analysis-services-monitor).</span><span class="sxs-lookup"><span data-stu-id="166a7-268">For more information, see [Monitor server metrics](/azure/analysis-services/analysis-services-monitor).</span></span>

<span data-ttu-id="166a7-269">Sous une charge importante, les performances de requête peuvent se dégrader en raison de la simultanéité des requêtes.</span><span class="sxs-lookup"><span data-stu-id="166a7-269">Under high load, query performance can become degraded due to query concurrency.</span></span> <span data-ttu-id="166a7-270">Vous pouvez augmenter la taille d’Analyse Services en créant un pool de réplicas pour traiter des requêtes, dans le but de pouvoir réaliser plus de requêtes simultanément.</span><span class="sxs-lookup"><span data-stu-id="166a7-270">You can scale out Analysis Services by creating a pool of replicas to process queries, so that more queries can be performed concurrently.</span></span> <span data-ttu-id="166a7-271">Le traitement du modèle des données se fait toujours sur le serveur principal.</span><span class="sxs-lookup"><span data-stu-id="166a7-271">The work of processing the data model always happens on the primary server.</span></span> <span data-ttu-id="166a7-272">Par défaut, le serveur principal gère aussi les requêtes.</span><span class="sxs-lookup"><span data-stu-id="166a7-272">By default, the primary server also handles queries.</span></span> <span data-ttu-id="166a7-273">Optionnellement, vous pouvez désigner le serveur principal pour qu’il n’exécute que le traitement, afin que le pool de requêtes gère toutes les requêtes.</span><span class="sxs-lookup"><span data-stu-id="166a7-273">Optionally, you can designate the primary server to run processing exclusively, so that the query pool handles all queries.</span></span> <span data-ttu-id="166a7-274">Si vous avez des exigences de traitement élevées, vous devriez séparer le traitement et le pool de requêtes.</span><span class="sxs-lookup"><span data-stu-id="166a7-274">If you have high processing requirements, you should separate the processing from the query pool.</span></span> <span data-ttu-id="166a7-275">Si vous avez des charges de requêtes importantes, et un traitement relativement léger, vous pouvez inclure le serveur principal dans le pool de requêtes.</span><span class="sxs-lookup"><span data-stu-id="166a7-275">If you have high query loads, and relatively light processing, you can include the primary server in the query pool.</span></span> <span data-ttu-id="166a7-276">Pour en savoir plus, consultez [Extensibilité d’Azure Analysis Services](/azure/analysis-services/analysis-services-scale-out).</span><span class="sxs-lookup"><span data-stu-id="166a7-276">For more information, see [Azure Analysis Services scale-out](/azure/analysis-services/analysis-services-scale-out).</span></span> 

<span data-ttu-id="166a7-277">Pour réduire la quantité de traitement inutile, préférez utiliser des partitions pour diviser le modèle tabulaire en plusieurs parties logiques.</span><span class="sxs-lookup"><span data-stu-id="166a7-277">To reduce the amount of unnecessary processing, consider using partitions to divide the tabular model into logical parts.</span></span> <span data-ttu-id="166a7-278">Chaque partition peut être traitée séparément.</span><span class="sxs-lookup"><span data-stu-id="166a7-278">Each partition can be processed separately.</span></span> <span data-ttu-id="166a7-279">Pour plus d'informations, consultez [Partitions](/sql/analysis-services/tabular-models/partitions-ssas-tabular).</span><span class="sxs-lookup"><span data-stu-id="166a7-279">For more information, see [Partitions](/sql/analysis-services/tabular-models/partitions-ssas-tabular).</span></span>

## <a name="security-considerations"></a><span data-ttu-id="166a7-280">Considérations relatives à la sécurité</span><span class="sxs-lookup"><span data-stu-id="166a7-280">Security considerations</span></span>

### <a name="ip-whitelisting-of-analysis-services-clients"></a><span data-ttu-id="166a7-281">Liste verte IP des clients Analysis Services</span><span class="sxs-lookup"><span data-stu-id="166a7-281">IP whitelisting of Analysis Services clients</span></span>

<span data-ttu-id="166a7-282">Utilisez la fonctionnalité de pare-feu Analysis Services pour mettre les adresses IP client sur liste verte.</span><span class="sxs-lookup"><span data-stu-id="166a7-282">Consider using the Analysis Services firewall feature to whitelist client IP addresses.</span></span> <span data-ttu-id="166a7-283">S’il est activé, le pare-feu bloque toutes les connexions clients autres que celles spécifiées dans les règles du pare-feu.</span><span class="sxs-lookup"><span data-stu-id="166a7-283">If enabled, the firewall blocks all client connections other than those specified in the firewall rules.</span></span> <span data-ttu-id="166a7-284">Les règles par défaut mettent le service Power BI sur liste verte, mais vous pouvez désactiver cette règle si vous le souhaitez.</span><span class="sxs-lookup"><span data-stu-id="166a7-284">The default rules whitelist the Power BI service, but you can disable this rule if desired.</span></span> <span data-ttu-id="166a7-285">Pour plus d’informations, consultez [Hardening Azure Analysis Services with the new firewall capability](https://azure.microsoft.com/blog/hardening-azure-analysis-services-with-the-new-firewall-capability/)(Consolidation d’Azure Analysis Services avec la nouvelle capacité de pare-feu).</span><span class="sxs-lookup"><span data-stu-id="166a7-285">For more information, see [Hardening Azure Analysis Services with the new firewall capability](https://azure.microsoft.com/blog/hardening-azure-analysis-services-with-the-new-firewall-capability/).</span></span>

### <a name="authorization"></a><span data-ttu-id="166a7-286">Authorization</span><span class="sxs-lookup"><span data-stu-id="166a7-286">Authorization</span></span>

<span data-ttu-id="166a7-287">Azure Analysis Services utilise Azure Active Directory (Azure AD) pour authentifier les utilisateurs qui se connectent à un serveur Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="166a7-287">Azure Analysis Services uses Azure Active Directory (Azure AD) to authenticate users who connect to an Analysis Services server.</span></span> <span data-ttu-id="166a7-288">Vous pouvez limiter les données qu’un utilisateur spécifique peut consulter en créant des rôles et en les assignant à des utilisateurs ou groupes Azure AD.</span><span class="sxs-lookup"><span data-stu-id="166a7-288">You can restrict what data a particular user is able to view, by creating roles and then assigning Azure AD users or groups to those roles.</span></span> <span data-ttu-id="166a7-289">Pour chaque rôle, vous pouvez :</span><span class="sxs-lookup"><span data-stu-id="166a7-289">For each role, you can:</span></span> 

- <span data-ttu-id="166a7-290">Protégez des tables ou des colonnes individuelles.</span><span class="sxs-lookup"><span data-stu-id="166a7-290">Protect tables or individual columns.</span></span> 
- <span data-ttu-id="166a7-291">Protégez des lignes individuelles basées sur des expressions filtrées.</span><span class="sxs-lookup"><span data-stu-id="166a7-291">Protect individual rows based on filter expressions.</span></span> 

<span data-ttu-id="166a7-292">Pour en savoir plus, consultez [Gérer les rôles et les utilisateurs de bases de données](/azure/analysis-services/analysis-services-database-users).</span><span class="sxs-lookup"><span data-stu-id="166a7-292">For more information, see [Manage database roles and users](/azure/analysis-services/analysis-services-database-users).</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="166a7-293">Déployer la solution</span><span class="sxs-lookup"><span data-stu-id="166a7-293">Deploy the solution</span></span>

<span data-ttu-id="166a7-294">Pour déployer et exécuter l’implémentation de référence, suivez les étapes du [fichier Readme de GitHub][github-folder].</span><span class="sxs-lookup"><span data-stu-id="166a7-294">To the deploy and run the reference implementation, follow the steps in the [GitHub readme][github-folder].</span></span> <span data-ttu-id="166a7-295">Il déploie les éléments suivants :</span><span class="sxs-lookup"><span data-stu-id="166a7-295">It deploys the following:</span></span>

  * <span data-ttu-id="166a7-296">Une machine virtuelle pour simuler un serveur de base de données local.</span><span class="sxs-lookup"><span data-stu-id="166a7-296">A Windows VM to simulate an on-premises database server.</span></span> <span data-ttu-id="166a7-297">Sont inclus SQL Server 2017 et les outils associés, et Power BI Desktop.</span><span class="sxs-lookup"><span data-stu-id="166a7-297">It includes SQL Server 2017 and related tools, along with Power BI Desktop.</span></span>
  * <span data-ttu-id="166a7-298">Un compte de stockage Azure qui fournit le stockage d’objets blob pour conserver des données exportées de la base de données SQL Server.</span><span class="sxs-lookup"><span data-stu-id="166a7-298">An Azure storage account that provides Blob storage to hold data exported from the SQL Server database.</span></span>
  * <span data-ttu-id="166a7-299">Une instance Azure SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="166a7-299">An Azure SQL Data Warehouse instance.</span></span>
  * <span data-ttu-id="166a7-300">Une instance Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="166a7-300">An Azure Analysis Services instance.</span></span>


## <a name="next-steps"></a><span data-ttu-id="166a7-301">Étapes suivantes</span><span class="sxs-lookup"><span data-stu-id="166a7-301">Next steps</span></span>

- <span data-ttu-id="166a7-302">Utilisez Azure Data Factory pour automatiser le pipeline ELT.</span><span class="sxs-lookup"><span data-stu-id="166a7-302">Use Azure Data Factory to automate the ELT pipeline.</span></span> <span data-ttu-id="166a7-303">Voir [BI d’entreprise automatisée avec SQL Data Warehouse et Azure Data Factory][adf-ra].</span><span class="sxs-lookup"><span data-stu-id="166a7-303">See [Automated enterprise BI with SQL Data Warehouse and Azure Data Factory][adf-ra].</span></span>

<!-- links -->

[adf-ra]: ./enterprise-bi-adf.md
[github-folder]: https://github.com/mspnp/reference-architectures/tree/master/data/enterprise_bi_sqldw
[wwi]: /sql/sample/world-wide-importers/wide-world-importers-oltp-database

