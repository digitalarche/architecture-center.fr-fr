---
title: Extraire, transformer et charger (ETL)
description: ''
author: zoinerTejada
ms.date: 02/12/2018
ms.topic: guide
ms.service: architecture-center
ms.subservice: cloud-fundamentals
ms.openlocfilehash: 1551736d8ef3d2b82eb0a2fdb626330798ec1c65
ms.sourcegitcommit: 1b50810208354577b00e89e5c031b774b02736e2
ms.translationtype: HT
ms.contentlocale: fr-FR
ms.lasthandoff: 01/23/2019
ms.locfileid: "54488025"
---
# <a name="extract-transform-and-load-etl"></a><span data-ttu-id="ce666-102">Extraire, transformer et charger (ETL)</span><span class="sxs-lookup"><span data-stu-id="ce666-102">Extract, transform, and load (ETL)</span></span>

<span data-ttu-id="ce666-103">Un problème courant auquel les organisations font face est le mode de collecte de données à partir de plusieurs sources, dans plusieurs formats, et le déplacement de ces données vers un ou plusieurs magasins de données.</span><span class="sxs-lookup"><span data-stu-id="ce666-103">A common problem that organizations face is how to gathering data from multiple sources, in multiple formats, and move it to one or more data stores.</span></span> <span data-ttu-id="ce666-104">La destination peut ne pas être le même type de magasin de données que la source, et souvent le format est différent, ou les données doivent être mises en forme ou nettoyées avant d’être chargées dans leur destination finale.</span><span class="sxs-lookup"><span data-stu-id="ce666-104">The destination may not be the same type of data store as the source, and often the format is different, or the data needs to be shaped or cleaned before loading it into its final destination.</span></span>

<span data-ttu-id="ce666-105">Au fil des années, différents outils, services et processus ont été développés pour relever ces défis.</span><span class="sxs-lookup"><span data-stu-id="ce666-105">Various tools, services, and processes have been developed over the years to help address these challenges.</span></span> <span data-ttu-id="ce666-106">Quel que soit le processus utilisé, il est nécessaire de coordonner le travail et d’appliquer un certain degré de transformation des données dans le pipeline de données.</span><span class="sxs-lookup"><span data-stu-id="ce666-106">No matter the process used, there is a common need to coordinate the work and apply some level of data transformation within the data pipeline.</span></span> <span data-ttu-id="ce666-107">Les sections suivantes illustrent les méthodes couramment utilisées pour effectuer ces tâches.</span><span class="sxs-lookup"><span data-stu-id="ce666-107">The following sections highlight the common methods used to perform these tasks.</span></span>

## <a name="extract-transform-and-load-etl-process"></a><span data-ttu-id="ce666-108">Processus ETL (extraction, transformation et chargement)</span><span class="sxs-lookup"><span data-stu-id="ce666-108">Extract, transform, and load (ETL) process</span></span>

<span data-ttu-id="ce666-109">ETL est un pipeline de données utilisé pour collecter des données provenant de différentes sources, transformer les données en fonction des règles métier et charger les données dans un magasin de données de destination.</span><span class="sxs-lookup"><span data-stu-id="ce666-109">Extract, transform, and load (ETL) is a data pipeline used to collect data from various sources, transform the data according to business rules, and load it into a destination data store.</span></span> <span data-ttu-id="ce666-110">Le travail de transformation dans ETL a lieu dans un moteur spécialisé et implique souvent l’utilisation de tables intermédiaires pour conserver temporairement les données lors de leur transformation et leur chargement final vers leur destination.</span><span class="sxs-lookup"><span data-stu-id="ce666-110">The transformation work in ETL takes place in a specialized engine, and often involves using staging tables to temporarily hold data as it is being transformed and ultimately loaded to its destination.</span></span>

<span data-ttu-id="ce666-111">La transformation des données qui a lieu implique généralement plusieurs opérations, comme le filtrage, le tri, l’agrégation, la jointure des données, le nettoyage des données, la déduplication et la validation des données.</span><span class="sxs-lookup"><span data-stu-id="ce666-111">The data transformation that takes place usually involves various operations, such as filtering, sorting, aggregating, joining data, cleaning data, deduplicating, and validating data.</span></span>

![Processus ETL (Extraire-transformer-charger)](../images/etl.png)

<span data-ttu-id="ce666-113">Souvent, les trois phases ETL sont exécutées en parallèle pour gagner du temps.</span><span class="sxs-lookup"><span data-stu-id="ce666-113">Often, the three ETL phases are run in parallel to save time.</span></span> <span data-ttu-id="ce666-114">Par exemple, tandis que les données sont extraites, un processus de transformation peut travailler sur les données déjà reçues et les préparer pour le chargement, et un processus de chargement peut commencer à travailler sur les données préparées, au lieu d’attendre la fin du processus d’extraction complet.</span><span class="sxs-lookup"><span data-stu-id="ce666-114">For example, while data is being extracted, a transformation process could be working on data already received and prepare it for loading, and a loading process can begin working on the prepared data, rather than waiting for the entire extraction process to complete.</span></span>

<span data-ttu-id="ce666-115">Service Azure approprié :</span><span class="sxs-lookup"><span data-stu-id="ce666-115">Relevant Azure service:</span></span>

- [<span data-ttu-id="ce666-116">Azure Data Factory v2</span><span class="sxs-lookup"><span data-stu-id="ce666-116">Azure Data Factory v2</span></span>](https://azure.microsoft.com/services/data-factory/)

<span data-ttu-id="ce666-117">Autres outils :</span><span class="sxs-lookup"><span data-stu-id="ce666-117">Other tools:</span></span>

- [<span data-ttu-id="ce666-118">SQL Server Integration Services (SSIS)</span><span class="sxs-lookup"><span data-stu-id="ce666-118">SQL Server Integration Services (SSIS)</span></span>](/sql/integration-services/sql-server-integration-services)

## <a name="extract-load-and-transform-elt"></a><span data-ttu-id="ce666-119">Extraire, charger et transformer (ELT)</span><span class="sxs-lookup"><span data-stu-id="ce666-119">Extract, load, and transform (ELT)</span></span>

<span data-ttu-id="ce666-120">Extraire, charger et transformer (ELT) diffère du processus ETL uniquement où la transformation a lieu.</span><span class="sxs-lookup"><span data-stu-id="ce666-120">Extract, load, and transform (ELT) differs from ETL solely in where the transformation takes place.</span></span> <span data-ttu-id="ce666-121">Dans le pipeline ELT, la transformation se produit dans le magasin de données cible.</span><span class="sxs-lookup"><span data-stu-id="ce666-121">In the ELT pipeline, the transformation occurs in the target data store.</span></span> <span data-ttu-id="ce666-122">Au lieu d’utiliser un moteur de transformation distinct, les fonctionnalités de traitement du magasin de données cible sont utilisées pour transformer les données.</span><span class="sxs-lookup"><span data-stu-id="ce666-122">Instead of using a separate transformation engine, the processing capabilities of the target data store are used to transform data.</span></span> <span data-ttu-id="ce666-123">Cela simplifie l’architecture en supprimant le moteur de transformation du pipeline.</span><span class="sxs-lookup"><span data-stu-id="ce666-123">This simplifies the architecture by removing the transformation engine from the pipeline.</span></span> <span data-ttu-id="ce666-124">Un autre avantage de cette approche est que la montée en puissance du magasin de données cible permet également la montée en puissance des performances du pipeline ELT.</span><span class="sxs-lookup"><span data-stu-id="ce666-124">Another benefit to this approach is that scaling the target data store also scales the ELT pipeline performance.</span></span> <span data-ttu-id="ce666-125">Toutefois, ELT fonctionne bien uniquement lorsque le système cible est suffisamment puissant pour transformer les données de manière efficace.</span><span class="sxs-lookup"><span data-stu-id="ce666-125">However, ELT only works well when the target system is powerful enough to transform the data efficiently.</span></span>

![Processus ELT (Extraire-charger-transformer)](../images/elt.png)

<span data-ttu-id="ce666-127">Les scénarios d’utilisation classiques d’ELT concernent le domaine du Big Data.</span><span class="sxs-lookup"><span data-stu-id="ce666-127">Typical use cases for ELT fall within the big data realm.</span></span> <span data-ttu-id="ce666-128">Par exemple, vous pouvez commencer par extraire toutes les données sources dans des fichiers plats dans un stockage évolutif comme le système de fichiers distribués (HDFS) Hadoop ou Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="ce666-128">For example, you might start by extracting all of the source data to flat files in scalable storage such as Hadoop distributed file system (HDFS) or Azure Data Lake Store.</span></span> <span data-ttu-id="ce666-129">Les technologies comme Spark, Hive ou PolyBase peuvent ensuite être utilisées pour interroger les données sources.</span><span class="sxs-lookup"><span data-stu-id="ce666-129">Technologies such as Spark, Hive, or PolyBase can then be used to query the source data.</span></span> <span data-ttu-id="ce666-130">Le point clé avec ELT est que le magasin de données utilisé pour effectuer la transformation est le même magasin de données que celui où les données sont finalement consommées.</span><span class="sxs-lookup"><span data-stu-id="ce666-130">The key point with ELT is that the data store used to perform the transformation is the same data store where the data is ultimately consumed.</span></span> <span data-ttu-id="ce666-131">Ce magasin de données lit directement à partir du stockage évolutif, au lieu de charger les données dans son propre stockage propriétaire.</span><span class="sxs-lookup"><span data-stu-id="ce666-131">This data store reads directly from the scalable storage, instead of loading the data into its own proprietary storage.</span></span> <span data-ttu-id="ce666-132">Cette approche ignore l’étape de copie des données présente dans ETL, qui peut être une opération longue pour les jeux de données volumineux.</span><span class="sxs-lookup"><span data-stu-id="ce666-132">This approach skips the data copy step present in ETL, which can be a time consuming operation for large data sets.</span></span>

<span data-ttu-id="ce666-133">Dans la pratique, le magasin de données cible est un [entrepôt de données](./data-warehousing.md) utilisant un cluster Hadoop (avec Hive ou Spark) ou un SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="ce666-133">In practice, the target data store is a [data warehouse](./data-warehousing.md) using either a Hadoop cluster (using Hive or Spark) or a SQL Data Warehouse.</span></span> <span data-ttu-id="ce666-134">En général, un schéma est placé sur les données de fichier plat au moment de la requête et stocké sous la forme d’une table, permettant l’interrogation des données comme toute autre table dans le magasin de données.</span><span class="sxs-lookup"><span data-stu-id="ce666-134">In general, a schema is overlaid on the flat file data at query time and stored as a table, enabling the data to be queried like any other table in the data store.</span></span> <span data-ttu-id="ce666-135">Celles-ci sont désignées comme des tables externes, car les données ne résident pas dans le stockage géré par le magasin de données lui-même, mais dans un stockage évolutif externe.</span><span class="sxs-lookup"><span data-stu-id="ce666-135">These are referred to as external tables because the data does not reside in storage managed by the data store itself, but on some external scalable storage.</span></span>

<span data-ttu-id="ce666-136">Le magasin de données gère uniquement le schéma des données et applique le schéma lors de la lecture.</span><span class="sxs-lookup"><span data-stu-id="ce666-136">The data store only manages the schema of the data and applies the schema on read.</span></span> <span data-ttu-id="ce666-137">Par exemple, un cluster Hadoop utilisant Hive décrit une table Hive où la source des données est en réalité un chemin d’accès à un ensemble de fichiers dans HDFS.</span><span class="sxs-lookup"><span data-stu-id="ce666-137">For example, a Hadoop cluster using Hive would describe a Hive table where the data source is effectively a path to a set of files in HDFS.</span></span> <span data-ttu-id="ce666-138">Dans SQL Data Warehouse, PolyBase peut obtenir le même résultat &mdash; créant une table sur des données stockées en externe à la base de données.</span><span class="sxs-lookup"><span data-stu-id="ce666-138">In SQL Data Warehouse, PolyBase can achieve the same result &mdash; creating a table against data stored externally to the database itself.</span></span> <span data-ttu-id="ce666-139">Une fois la source de données chargée, les données présentes dans les tables externes peuvent être traitées grâce aux fonctionnalités du magasin de données.</span><span class="sxs-lookup"><span data-stu-id="ce666-139">Once the source data is loaded, the data present in the external tables can be processed using the capabilities of the data store.</span></span> <span data-ttu-id="ce666-140">Dans les scénarios Big Data, cela signifie que le magasin de données doit être capable d’un traitement parallèle massif (MPP), qui fractionne les données en segments plus petits et distribue le traitement des segments sur plusieurs machines en parallèle.</span><span class="sxs-lookup"><span data-stu-id="ce666-140">In big data scenarios, this means the data store must be capable of massively parallel processing (MPP), which breaks the data into smaller chunks and distributes processing of the chunks across multiple machines in parallel.</span></span>

<span data-ttu-id="ce666-141">La dernière phase du pipeline ELT consiste généralement à transformer la source de données dans un format final plus efficace pour les types de requêtes qui doivent être pris en charge.</span><span class="sxs-lookup"><span data-stu-id="ce666-141">The final phase of the ELT pipeline is typically to transform the source data into a final format that is more efficient for the types of queries that need to be supported.</span></span> <span data-ttu-id="ce666-142">Par exemple, les données peuvent être partitionnées.</span><span class="sxs-lookup"><span data-stu-id="ce666-142">For example, the data may be partitioned.</span></span> <span data-ttu-id="ce666-143">En outre, ELT peut utiliser des formats de stockage optimisé comme Parquet, qui stocke les données orientées ligne dans un mode en colonnes et fournit une indexation optimisée.</span><span class="sxs-lookup"><span data-stu-id="ce666-143">Also, ELT might use optimized storage formats like Parquet, which stores row-oriented data in a columnar fashion and providess optimized indexing.</span></span>

<span data-ttu-id="ce666-144">Service Azure approprié :</span><span class="sxs-lookup"><span data-stu-id="ce666-144">Relevant Azure service:</span></span>

- [<span data-ttu-id="ce666-145">Azure SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="ce666-145">Azure SQL Data Warehouse</span></span>](/azure/sql-data-warehouse/sql-data-warehouse-overview-what-is)
- [<span data-ttu-id="ce666-146">HDInsight avec Hive</span><span class="sxs-lookup"><span data-stu-id="ce666-146">HDInsight with Hive</span></span>](/azure/hdinsight/hadoop/hdinsight-use-hive)
- [<span data-ttu-id="ce666-147">Azure Data Factory v2</span><span class="sxs-lookup"><span data-stu-id="ce666-147">Azure Data Factory v2</span></span>](https://azure.microsoft.com/services/data-factory/)
- [<span data-ttu-id="ce666-148">Oozie sur HDInsight</span><span class="sxs-lookup"><span data-stu-id="ce666-148">Oozie on HDInsight</span></span>](/azure/hdinsight/hdinsight-use-oozie-linux-mac)

<span data-ttu-id="ce666-149">Autres outils :</span><span class="sxs-lookup"><span data-stu-id="ce666-149">Other tools:</span></span>

- [<span data-ttu-id="ce666-150">SQL Server Integration Services (SSIS)</span><span class="sxs-lookup"><span data-stu-id="ce666-150">SQL Server Integration Services (SSIS)</span></span>](/sql/integration-services/sql-server-integration-services)

## <a name="data-flow-and-control-flow"></a><span data-ttu-id="ce666-151">Flux de données et flux de contrôle</span><span class="sxs-lookup"><span data-stu-id="ce666-151">Data flow and control flow</span></span>

<span data-ttu-id="ce666-152">Dans le contexte de pipelines de données, le flux de contrôle garantit le traitement de façon ordonnée d’un ensemble de tâches.</span><span class="sxs-lookup"><span data-stu-id="ce666-152">In the context of data pipelines, the control flow ensures orderly processing of a set of tasks.</span></span> <span data-ttu-id="ce666-153">Pour appliquer l’ordre de traitement correct de ces tâches, des contraintes de priorité sont utilisées.</span><span class="sxs-lookup"><span data-stu-id="ce666-153">To enforce the correct processing order of these tasks, precedence constraints are used.</span></span> <span data-ttu-id="ce666-154">Vous pouvez comparer ces contraintes à des connecteurs dans un diagramme de flux de travail, comme indiqué dans l’image ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="ce666-154">You can think of these constraints as connectors in a workflow diagram, as shown in the image below.</span></span> <span data-ttu-id="ce666-155">Chaque tâche a un résultat, comme la réussite, l’échec ou l’achèvement.</span><span class="sxs-lookup"><span data-stu-id="ce666-155">Each task has an outcome, such as success, failure, or completion.</span></span> <span data-ttu-id="ce666-156">Le traitement de la tâche suivante n’est lancé que lorsque la tâche précédente est terminée avec l’un de ces résultats.</span><span class="sxs-lookup"><span data-stu-id="ce666-156">Any subsequent task does not initiate processing until its predecessor has completed with one of these outcomes.</span></span>

<span data-ttu-id="ce666-157">Les flux de contrôle exécutent les flux de données en tant que tâche.</span><span class="sxs-lookup"><span data-stu-id="ce666-157">Control flows execute data flows as a task.</span></span> <span data-ttu-id="ce666-158">Dans une tâche de flux de données, les données sont extraites d’une source, transformées ou chargées dans un magasin de données.</span><span class="sxs-lookup"><span data-stu-id="ce666-158">In a data flow task, data is extracted from a source, transformed, or loaded into a data store.</span></span> <span data-ttu-id="ce666-159">La sortie d’une tâche de flux de données peut correspondre à l’entrée de la prochaine tâche de flux de données et les flux de données peuvent s’exécuter en parallèle.</span><span class="sxs-lookup"><span data-stu-id="ce666-159">The output of one data flow task can be the input to the next data flow task, and data flowss can run in parallel.</span></span> <span data-ttu-id="ce666-160">Contrairement aux flux de contrôle, vous ne pouvez pas ajouter de contraintes entre les tâches d’un flux de données.</span><span class="sxs-lookup"><span data-stu-id="ce666-160">Unlike control flows, you cannot add constraints between tasks in a data flow.</span></span> <span data-ttu-id="ce666-161">Toutefois, vous pouvez ajouter une visionneuse de données afin d’observer les données lorsqu’elles sont traitées par chaque tâche.</span><span class="sxs-lookup"><span data-stu-id="ce666-161">You can, however, add a data viewer to observe the data as it is processed by each task.</span></span>

![Flux de données exécuté en tant que tâche dans un flux de contrôle](../images/control-flow-data-flow.png)

<span data-ttu-id="ce666-163">Dans le schéma ci-dessus, le flux de contrôle comporte plusieurs tâches, notamment une tâche de flux de données.</span><span class="sxs-lookup"><span data-stu-id="ce666-163">In the diagram above, there are several tasks within the control flow, one of which is a data flow task.</span></span> <span data-ttu-id="ce666-164">L’une des tâches est imbriquée dans un conteneur.</span><span class="sxs-lookup"><span data-stu-id="ce666-164">One of the tasks is nested within a container.</span></span> <span data-ttu-id="ce666-165">Les conteneurs peuvent être utilisés pour donner une structure aux tâches, fournissant une unité de travail.</span><span class="sxs-lookup"><span data-stu-id="ce666-165">Containers can be used to provide structure to tasks, providing a unit of work.</span></span> <span data-ttu-id="ce666-166">La répétition d’éléments dans une collection, comme des fichiers dans un dossier ou des instructions dans une base de données, en est un exemple.</span><span class="sxs-lookup"><span data-stu-id="ce666-166">One such example is for repeating elements within a collection, such as files in a folder or database statements.</span></span>

<span data-ttu-id="ce666-167">Service Azure approprié :</span><span class="sxs-lookup"><span data-stu-id="ce666-167">Relevant Azure service:</span></span>

- [<span data-ttu-id="ce666-168">Azure Data Factory v2</span><span class="sxs-lookup"><span data-stu-id="ce666-168">Azure Data Factory v2</span></span>](https://azure.microsoft.com/services/data-factory/)

<span data-ttu-id="ce666-169">Autres outils :</span><span class="sxs-lookup"><span data-stu-id="ce666-169">Other tools:</span></span>

- [<span data-ttu-id="ce666-170">SQL Server Integration Services (SSIS)</span><span class="sxs-lookup"><span data-stu-id="ce666-170">SQL Server Integration Services (SSIS)</span></span>](/sql/integration-services/sql-server-integration-services)

## <a name="technology-choices"></a><span data-ttu-id="ce666-171">Choix de technologie</span><span class="sxs-lookup"><span data-stu-id="ce666-171">Technology choices</span></span>

- [<span data-ttu-id="ce666-172">Magasins de données de traitement transactionnel en ligne (OLTP)</span><span class="sxs-lookup"><span data-stu-id="ce666-172">Online Transaction Processing (OLTP) data stores</span></span>](./online-transaction-processing.md#oltp-in-azure)
- [<span data-ttu-id="ce666-173">Magasins de données de traitement analytique en ligne (OLAP)</span><span class="sxs-lookup"><span data-stu-id="ce666-173">Online Analytical Processing (OLAP) data stores</span></span>](./online-analytical-processing.md#olap-in-azure)
- [<span data-ttu-id="ce666-174">Entrepôts de données</span><span class="sxs-lookup"><span data-stu-id="ce666-174">Data warehouses</span></span>](./data-warehousing.md)
- [<span data-ttu-id="ce666-175">Orchestration de pipeline</span><span class="sxs-lookup"><span data-stu-id="ce666-175">Pipeline orchestration</span></span>](../technology-choices/pipeline-orchestration-data-movement.md)

## <a name="next-steps"></a><span data-ttu-id="ce666-176">Étapes suivantes</span><span class="sxs-lookup"><span data-stu-id="ce666-176">Next steps</span></span>

<span data-ttu-id="ce666-177">Les architectures de référence suivantes présentent des pipelines ELT de bout en bout sur Azure :</span><span class="sxs-lookup"><span data-stu-id="ce666-177">The following reference architectures show end-to-end ELT pipelines on Azure:</span></span>

- [<span data-ttu-id="ce666-178">BI d’entreprise dans Azure avec SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="ce666-178">Enterprise BI in Azure with SQL Data Warehouse</span></span>](../../reference-architectures/data/enterprise-bi-sqldw.md)
- [<span data-ttu-id="ce666-179">BI d’entreprise automatisée avec SQL Data Warehouse et Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="ce666-179">Automated enterprise BI with SQL Data Warehouse and Azure Data Factory</span></span>](../../reference-architectures/data/enterprise-bi-adf.md)